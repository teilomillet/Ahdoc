{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB with persistence: data will be stored in: /Users/teilomillet/Desktop/ahdoc.chat/Ahdoc\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "\n",
    "import os\n",
    "import chromadb\n",
    "\n",
    "from chromadb.config import Settings\n",
    "\n",
    "client = chromadb.Client(Settings(\n",
    "    chroma_db_impl=\"duckdb+parquet\",\n",
    "    persist_directory=\"/Users/teilomillet/Desktop/ahdoc.chat/Ahdoc\" # Optional, defaults to .chromadb/ in the current directory\n",
    "))\n",
    "\n",
    "os.environ.update({\n",
    "    'OPENAI_API_KEY': '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'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content=\"Boosting Theory-of-Mind Performance in Large Language Models \\n  via Prompting \\nShima Rahimi Moghaddam*, Christopher J. Honey \\n Johns Hopkins University, Baltimore, MD, USA. \\n   * Correspondence to:  sh.rahimi.m@gmail.com \\nAbstract \\n \\nLarge language models (LLMs) excel in many tasks in 2023, but they still face challenges in complex reasoning. \\nTheory-of-mind (ToM) tasks, which require understanding agents' beliefs, goals, and mental states, are essential \\nfor common-sense reasoning involving humans, making it crucial to enhance LLM performance in this area. \\nThis study measures the ToM performance of GPT-4 and three GPT-3.5 variants (Davinci-2, Davinci-3, GPT-\\n3.5-Turbo), and investigates the effectiveness of in-context learning in improving their ToM comprehension. \\nWe evaluated prompts featuring two-shot chain of thought reasoning and step-by-step thinking instructions. We \\nfound that LLMs trained with Reinforcement Learning from Human Feedback (RLHF) (all models excluding \\nDavinci-2) improved their ToM accuracy via in-context learning. GPT-4 performed best in zero-shot settings, \\nreaching nearly 80% ToM accuracy, but still fell short of the 87% human accuracy on the test set. However, \\nwhen supplied with prompts for in-context learning, all RLHF-trained LLMs exceeded 80% ToM accuracy, with \\nGPT-4 reaching 100%. These results demonstrate that appropriate prompting enhances LLM ToM reasoning, \\n and they underscore the context-dependent nature of LLM cognitive capacities. \\nIntroduction \\n \\nWhat kinds of reasoning can large language models (LLMs) perform about everyday scenarios? Large language \\nmodels (LLMs) have shown great success in a variety of tasks; however, they still struggle with tasks that require \\nreasoning (Mahowald et al., 2023; Rae et al., 2021). One area of specific interest the is so-called “theory of \\nmind” (ToM) reasoning, which involves tracking the mental state of agents, such as their goals, and what they \\nknow (Kosinski, 2023; Langley et al., 2022). Language models have dramatically advanced in the range of \\neveryday questions to which they can accurately respond, but their ToM performance is thought to be relatively \\npoor (Cuzzolin et al., 2020; Sap et al., 2022; Ullman, 2023). Here, we test the hypothesis that appropriate \\n prompting can enhance the ToM performance of LLMs. \\nThe capacity of LLMs to reliably perform ToM reasoning is important for several reasons. First, ToM is an \\nessential element of social understanding, allowing people to participate in intricate social exchanges and to \\nanticipate the actions or responses of others (Bedny et al., 2009; Heyes and Frith, 2014; Kidd and Castano, 2013; \\nMoran et al., 2011; Seyfarth and Cheney, 2013; Young et al., 2007). Second, ToM is considered a complex \\ncognitive capacity which is most highly developed in humans, and a small number of other animals (Krupenye \\n\", metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 1, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content=\"and Call, 2019; Povinelli and Preuss, 1995). This may be because ToM relies on structured relational knowledge \\n(e.g. agents can have goals; and agent X has goal G, but agent Y does not know that agent X has goal G). Models \\nthat work with social information and with humans will benefit from being able to reason about the mental states \\nand beliefs of agents. Finally, ToM tasks often involve inferential reasoning. For instance, for successful ToM \\nperformance, LLMs need to reason based on unobservable information (e.g. hidden mental states of agents) that \\nmust be inferred from context rather than parsed from the surface text (e.g. explicitly stated features of a \\nsituation). Hence, assessing and improving these models' proficiency in ToM tasks could offer valuable insights \\ninto their potential for a wider range of tasks that require inferential reasoning. \\nIn-context learning approaches can enhance the reasoning capacity of LLMs. Brown et al. (Brown et al., 2020) \\nshowed that, for sufficiently large language models (+100B parameters), one can enhance models’ performance \\nusing only few-shot task demonstrations that are specified only through the input to the model (i.e. at inference \\ntime, without weight updates). This form of performance boosting is usually referred to as “few-shot learning”. \\nWei et al. (Wei et al., 2022) later showed that the ability of LLMs to perform complex reasoning was improved \\nwhen the few-shot examples in the prompt contain the reasoning steps for reaching a conclusion (“chain-of-\\nthought reasoning”) (Magister et al., 2022). Moreover, Kojima et al. (Kojima et al., 2022) showed that, even in \\nthe absence of exemplar demonstrations, instructing language models to think “step-by-step” enhances their \\nreasoning performance. There is not currently a theoretical understanding of why these prompting techniques \\nare beneficial, however some recent studies have explored the effects of compositional structure and local \\ndependencies in training data on efficacy of these methods (Hahn and Goyal, 2023; Prystawski and Goodman, \\n2023). \\nThe capability of LLMs to perform ToM reasoning is supported by some studies (Bubeck et al., 2023; Kosinski, \\n2023), but questioned by others (Sap et al., 2022; Trott et al., 2022; Ullman, 2023). Though this prior literature \\nprovides many insights into ToM in LLMs, the quantitative evaluations of ToM performance have two main \\nlimitations. First, they examine LLMs’ ToM performance only on single-word or multiple-option completion \\n(Kosinski, 2023; Sap et al., 2022; Trott et al., 2022; Ullman, 2023). However, LLMs may benefit from freely \\nproducing answers with multiple parts and speculating over multiple possibilities, rather than being assessed on \\na single word completion. Second, most of the work criticizing the ToM abilities of LLMs relied on either zero-\\nshot testing (Trott et al., 2022; Ullman, 2023) or provided examples that lacked step-by-step reasoning toward \\nan answer (Sap et al., 2022). Yet, the type of output generated by LLMs can be highly context-sensitive \\n(Sejnowski, 2023). Therefore, we asked whether recent LLMs might exhibit improved ToM performance when \\nprovided with suitable prompts. \\nHere we evaluate the performance of LLMs faced with ToM comprehension questions and we explore whether \\nthis performance can be boosted using prompting methods such as step-by-step thinking, few-shot learning, and \\nchain-of-thought reasoning (Brown et al., 2020; Kojima et al., 2022; Wei et al., 2022). Improving inferential \\nreasoning performance by prompting is important because it is a flexible approach that does not require \\nadditional training or large new datasets. Further, if effective prompting techniques guide LLMs towards \\ngenerating higher-quality ToM responses, this contributes to the overall reliability of their reasoning in wide-\\n   ranging everyday applications. \\n\", metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 2, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content=' Methods \\nModels \\nWe studied the four most recent GPT models from the Open AI family. These were GPT-4 (OpenAI, 2023a) as \\nwell as the Davinci-2, Davinci-3, and GPT-3.5-Turbo models, which are considered GPT-3.5 variants that \\nimprove on GPT-3 (Brown et al., 2020; Ouyang et al., 2022). These are all large models (+100B parameters), \\nbut they differ in their training methods (OpenAI, 2023c). Davinci-2 (API name: text-davinci-002) is one of the \\nGPT-3.5 models which (in addition to the GPT-3 curricula) was also trained with supervised fine-tuning on \\nhuman-written demonstrations (OpenAI, 2023b; Stiennon et al., 2020). Davinci-3 (API name: text-davinci-003), \\nanother GPT-3.5 model, is an upgraded version of Davinci-2 which was further trained with Reinforcement \\nLearning from Human Feedback (RLHF) using Proximal Policy Optimization (OpenAI, 2023b; Ouyang et al., \\n2022; Stiennon et al., 2020). GPT-3.5-Turbo (the original version of ChatGPT) (OpenAI, 2023b) is yet another \\nGPT-3.5 model, trained with both fine-tuning on human-written demonstrations and RLHF, then further \\noptimized for conversation. GPT-4 is the most recent GPT model as of April 2023 (OpenAI, 2023a); there are \\nfew published details of the size and training methods for GPT-4, however, it appears to have undergone more \\nintensive training with RLHF for better alignment with human intention (OpenAI, 2023a). We tested all models \\nin a setting with temperature equal to 0.4 and the maximum length of generated text set to 150 tokens. \\n \\nExperimental Design \\nTo examine the comprehension ability of these models on ToM scenarios, we evaluated their comprehension \\naccuracy on both ToM scenarios and Control scenarios. The Control scenarios describe a scene (“Photo”) \\nwithout any agents. We refer to them as Photo scenarios (Supplement A). The ToM scenarios describe the mental \\nstate of people involved in a situation. We adapted 16 Photo scenarios and 16 ToM scenarios from stimulus sets \\nused in human fMRI to localize the brain areas involved in ToM (Dodell-Feder et al., 2011) (Supplement B). \\nThese scenarios match in their general difficulty; however, they differ in the need to reason based on individuals’ \\nstate of mind in the scenario. Human participants showed the same level of accuracy on both types of scenarios \\nin prior studies (Dodell-Feder et al., 2011), as well as in our behavioral experiment. In our human experiments, \\nparticipants were given 18 seconds to read each scenario. They were then asked a comprehension question about \\nthe scenario on a new screen and could answer at their own pace by clicking Yes or No. The Photo and ToM \\nscenarios were mixed and presented in random order so that each participant experienced both types of scenarios. \\nParticipants showed similar accuracy across Photo (86% ±4%) and ToM (87% ±4%) scenarios (see Supplement \\n C).  \\nA sample Photo Scenario (Control): \\nScenario: \"A map shows the ground floor plan. A photocopy was sent to the architect yesterday, but at \\nthe time the kitchen door was missing. It was added to the map this morning.\"  \\nQuestion: Does the architect’s photocopy show the door? \\n \\nA sample ToM Scenario: \\nScenario: \"The morning of the high school dance Sarah placed her high heel shoes under her dress and \\nthen went shopping. That afternoon, her sister borrowed the shoes and later put them under Sarah\\'s \\nbed.\"  \\nQuestion: When Sarah gets ready, does she assume her shoes are under her dress?  \\n \\n', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 3, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='Dependent Variable \\nWe measured the models’ accuracy in answering comprehension questions following the brief scenario. Since \\nLLMs are probabilistic models, we ran each prompt 20 times for every model, restarting the models for every \\nrepetition to ensure that the performance history of the models was not included, and to measure the reliability \\nof the model’s answers across re-initialization. Accuracy was defined as the proportion of correct responses \\n across 320 questions (16 scenarios x 20 repetitions). \\nTo evaluate the performance of each model, we analyzed their response to each prompt. To measure the accuracy \\nof each model, we manually checked all the LLM-generated responses and labeled them as correct or incorrect. \\nDue to the complexity of natural language, it was not always possible to label model output as correct or incorrect \\nbased on match to a template answer (e.g. “Yes” or “No”). We labeled an answer as correct if it had the correct \\nconclusion (see Examples 1-5 in “Correct responses” below) or if the model included the correct reasoning as \\none possibility amongst multiple reasonable responses (see Example 6 in “Correct responses” below). We \\nlabeled responses as incorrect if they arrived at an incorrect overall conclusion (see Examples 1-4 in “Incorrect \\nresponses” below) or if the responses were inconclusive (see Examples 5 and 6 in “Incorrect responses” below). \\n Below are the examples of correct and incorrect responses to a ToM comprehension question: \\nScenario:  \\n\"The morning of the high school dance Sarah placed her high heel shoes under her dress and then went \\nshopping. That afternoon, her sister borrowed the shoes and later put them under Sarah\\'s bed.\"  \\nQuestion:  \\nWhen Sarah gets ready, does she assume her shoes are under her dress?  \\n \\nCorrect Responses: \\n \\n- \\nExample 1: Sarah placed her shoes under her dress before she went shopping, but her sister borrowed \\nthem and put them under Sarah\\'s bed. Sarah doesn\\'t know that her sister borrowed her shoes, so she may \\nassume that they are still under her dress.  \\n \\n- \\nExample 2: Sarah placed her high heel shoes under her dress before going shopping, but her sister \\nborrowed the shoes and put them under Sarah\\'s bed later. So, Sarah doesn\\'t know that her sister borrowed \\nand returned the shoes. Therefore, the answer is: Yes, she assumes her shoes are under her dress. \\n \\n- \\nExample 3: Sarah may assume her shoes are still under her dress because that\\'s where she placed them \\nin the morning. \\n \\n- \\nExample 4: Sarah placed her high heel shoes under her dress before she went shopping, so she knows \\nwhere she left them. Her sister borrowed the shoes and later put them under Sarah\\'s bed, but Sarah \\ndoesn\\'t know that yet. So, the answer is: Yes, Sarah assumes her shoes are under her dress unless she \\ndiscovers otherwise. \\n \\n- \\nExample 5: In the morning, Sarah placed her high heel shoes under her dress. Later, her sister borrowed \\nthe shoes and put them under Sarah\\'s bed. Therefore, when Sarah gets ready, she may assume her shoes \\nare still under her dress, but they are actually under her bed. \\n \\n- \\nExample 6: Based on this scenario, it is unclear whether Sarah assumes her shoes are under her dress \\nwhen she gets ready. It depends on whether her sister told her she borrowed them and put them under \\nthe bed. \\n', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 4, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content=\"Incorrect Responses: \\n \\n- \\nExample 1: Sarah placed her shoes under her dress in the morning and then went shopping. Her sister \\nborrowed the shoes and put them under Sarah's bed. So, Sarah doesn't know that her shoes are under \\nher bed. So, the answer is: No, Sarah doesn't assume her shoes are under her dress. \\n \\n- \\nExample 2: No, Sarah does not assume her shoes are under her dress. \\n \\n- \\nExample 3: First, Sarah placed her high heel shoes under her dress in the morning. Then, her sister \\nborrowed the shoes and later put them under Sarah's bed. Therefore, Sarah would not assume her shoes \\nare under her dress as they were moved by her sister. \\n \\n- \\nExample 4: In the morning, Sarah placed her high heel shoes under her dress, but then went shopping. \\nThis means that when she returned home, she did not check if her shoes were still under her dress. Later, \\nher sister borrowed the shoes and put them under Sarah's bed. Therefore, Sarah cannot assume that her \\nshoes are under her dress as they were moved by her sister. \\n \\n- \\nExample 5: It does not specify in the scenario whether or not Sarah assumes her shoes are under her \\ndress. \\n \\n- \\nExample 6: Sarah placed her high heel shoes under her dress in the morning. She then went shopping. \\nHer sister later borrowed the shoes and put them under Sarah's bed. Based on this information, it is \\nunclear if Sarah assumes her shoes are still under her dress when she gets ready for the dance. \\n  \\nExperimental Conditions \\nTo measure the efficacy of in-context learning (ICL) on ToM performance, we examined each scenario with \\nfour types of prompting: (1) Zero-shot (no ICL); (2) Zero-shot with step-by-step (SS) thinking; (3) Two-shot \\nchain-of-thought (CoT) reasoning; (4) Two-shot CoT reasoning with SS thinking. Below are the examples of \\n each prompting method (Figure 1). \\n\", metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 5, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content=' \\nFigure 1. Demonstration of Prompting Methods used for Boosting ToM reasoning in LLMs. Examples \\nof 4 prompting types used to test the ToM performance of LLMs. Each box provides an example of the input \\nto the model for a single trial in one condition. For each trial, all of the text shown after the word “Prompt:” \\nwas input to the model, including the final text line beginning with “A:”. \\n', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 6, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='Results \\n \\nZero-shot Performance \\nWe first compared the models’ zero-shot performance on Photo and ToM scenarios. We found that accuracy in \\nPhoto scenarios gradually increased with the recency of the models, with lowest performance in Davinci-2 and \\nhighest in GPT-4 (Figure 2 A). However, in contrast to Photo comprehension, the accuracy on ToM questions \\ndid not monotonically improve with the recency of the models: Davinci-2 was more accurate than Davinci-3, \\nwhich was in turn more accurate than GPT-3.5-Turbo (Figure 2 B). Although the lower zero-shot ToM accuracy \\nin GPT-3.5-Turbo in comparison to Davinci-2 may seem to imply that the Turbo model’s reasoning performance \\nis inferior, the primary reason for its lower accuracy was its tendency to provide an inconclusive response. \\nSpecifically, it would often state that there was insufficient information to determine the answer to the question \\n(see examples 5-6 in “Incorrect responses” in Dependent Variable). However, more recent models were not \\nalways more equivocal in ToM responding: GPT-4 demonstrated a significantly greater ToM accuracy than all \\nother models (independent t-test between GPT-4 and Davinci-2: \\uf044Acc = 0.11, p-value <0.001) (Figure 2B). \\nOverall, GPT-4 showed the best zero-shot performance in both Photo and ToM scenarios (Figure 2 A and B). \\n \\n \\n \\nFigure 2. Zero-Shot Accuracy of LLMs in Photo (Control) and ToM Comprehension Questions. A) \\nZero-shot accuracy of LLMs in Photo scenarios (non-agentive) comprehension questions. B) Zero-shot \\naccuracy of LLMs in ToM comprehension questions. The values show the mean accuracy for each model \\naveraged over 320 measurements, as there are 16 scenarios of each type, and each scenario was tested 20 \\ntimes with re-initialization. For plotting the error bars, we treated each “repetition” as if it were a single \\n“participant” in the experiment. Therefore, we have 20 accuracy values, each averaged across 16 values from \\ndifferent ToM questions. The error bars then show the standard deviation of the 20 mean-accuracy values. \\n \\nPerformance when Supported by Prompting \\nIn-context learning via modified prompting boosted the ToM performance of all GPT models that were released \\n after Davinci-2 (Figure 3).  \\nFirst, we instructed the models to think step by step (SS). We found that SS thinking enhanced the performance \\nof Davinci-3, GPT-3.5-Turbo, and GPT-4 (e.g. independent t-test for zero-shot vs SS thinking for GPT-4: \\uf044Acc \\n', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 7, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='= 0.10, p-value <0.001; zero-shot vs SS thinking for GPT-3.5-Turbo: \\uf044Acc = 0.06, p-value <0.001). However, \\n SS thinking did not improve the accuracy of Davinci-2 (Figure 3).  \\n \\n \\n \\nFigure 3. Effects of In-context Learning Prompts on ToM performance in LLMs. ToM performance of \\nmodels using various in-context learning methods. For each model, the gray bar on the far left shows the \\nZero-Shot baseline ToM performance. The next three bars (orange) show the ToM performance on Zero-\\nShot plus SS Thinking; Two-Shot CoT; and Two-Shot CoT plus SS Thinking. Error bars indicate the standard \\ndeviation across 20 repetitions (see Figure 2, caption). \\n \\nSecond, we tested prompting with Two-shot chain-of-thought (CoT) reasoning. We found that Two-shot CoT \\nincreased the accuracy of all models that were trained with RLHF (all models except Davinci-2) (Figure 3). For \\nGPT-3.5-Turbo, Two-shot CoT prompting significantly improved the performance above its zero-shot baseline \\n(\\uf044Acc = 0.25, p-value <0.001), and was significantly more effective than prompting with SS thinking (\\uf044Acc = \\n0.19, p-value <0.001). For Davinci-3 and GPT-4, prompting with Two-shot CoT was slightly more effective \\n than instructing step-by-step thinking. \\nJoint prompting with both Two-shot CoT reasoning and SS thinking produced the greatest increase in models’ \\naccuracy (Figure 3). ToM accuracy of all RLHF-trained models was significantly increased when the prompts \\nincluded Two-shot CoT reasoning and SS thinking: Accuracy of Davinci-3 was increased by 20% ± 6% (mean \\n', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 8, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='± std) relative to its zero-shot baseline (p-value <0.001). Accuracy of GPT-3.5-Turbo was increased by 41% ± \\n5% relative to its zero-shot performance (p-value <0.001). Finally, accuracy of GPT-4 increased by 21% to reach \\n 100% accuracy (p-value <0.001, ceiling performance). \\nAltogether, appropriate prompting enabled all RLHF-trained models to achieve accuracy greater than 80%. \\nWhen appropriately prompted, Davinci-3 achieved ToM accuracy of 83% (±6%), GPT-3.5-Turbo achieved 91% \\n(±5%), and GPT-4 reached ceiling accuracy of 100%. Human performance in these scenarios was 87% (±4%) \\n  (See Supplement C). \\nInterim Discussion \\n Do the increases in ToM performance arise from copying the reasoning steps from the prompt? \\nThe improved performance of LLMs via prompting does not appear to be due to simple mimicry of the specific \\nreasoning steps provided in the chain-of-thought examples. The logic of reasoning in some scenarios was \\ndifferent from the reasoning logic of the 2 chain-of-thought examples. Both the in-context examples had the \\nfollowing essential reasoning logic: Person P was not at location L when event E happened, so they are not \\naware of event E. Conversely, some of the scenarios required reasoning that event E happened when person P \\nwas not there, but when P arrives, they can see the result of event E. If the improved performance was only due \\nto copying a specific sort of reasoning it should not generalize across these distinct reasoning cases. To \\nunderscore this point, we performed the following analyses to test whether closely-related vs distantly-related \\n CoT examples produce similar performance increases.  \\nWe hypothesized that if the improved ToM performance is due to copying the reasoning steps from the in-\\ncontext ToM examples, then prompting with non-ToM examples should not enhance the ToM performance. To \\ntest this hypothesis, it is necessary to exclude the ToM questions for which the models consistently provided \\naccurate zero-shot answers, because for such scenarios it is not possible to measure a performance increase. In \\nother words, we focused on the ToM questions that the models could not correctly answer in zero-shot. \\nFurthermore, we focused this analysis on Davinci-3 and GPT-3, because these models benefited from in-context \\nchain-of-thought ToM examples and (in contrast to GPT-3.5-Turbo) they almost always returned a definitive \\nresponse which did not require any subjective interpretation. Then for each model, we selected the scenarios that \\nthey could not correctly answer in zero-shot. This resulted in 4 scenarios for GPT-4 (mean zero-shot accuracy \\nof 0.16), and 6 scenarios in Davinci-3 (zero-shot accuracy of 0.0). We then tested the ToM accuracy of the model \\nfor these selected scenarios under the following conditions: (i) Two-shot ToM CoT examples; (ii) Two-shot \\nNon-ToM Inferential CoT examples; and (iii) Two-shot Photo CoT examples (Non-ToM Inferential examples; \\nand Photo examples are shown in Supplement D). In the Non-ToM Inferential examples, questions were not \\nabout false belief or an agent’s state of mind, but rather required inferential reasoning about the consequences \\n of an event. Photo examples were selected from scenarios that described a scene or situation without an agent.  \\nThe Davinci-3 and GPT-4 models experienced increases in ToM performance from all of the classes of CoT \\nexamples that we tested: Photo examples, Non-ToM Inferential examples, and ToM examples. The mean \\naccuracy increases for each model and each type of CoT example are shown in Figure 4, while the accuracy \\n changes for individual ToM questions are shown in Figure S.1. \\n', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 9, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='Prompting with Inferential and Photo examples boosted the models’ performance on ToM scenarios even though \\nthese in-context examples did not follow the same reasoning pattern as the ToM scenarios. Therefore, our \\nanalysis suggests that the benefit of prompting for boosting ToM performance is not due to merely overfitting \\nto the specific set of reasoning steps shown in the CoT examples. Instead, the CoT examples appear to invoke a \\nmode of output that involves step-by-step reasoning, which improves the accuracy across a range of tasks. \\n \\n \\n \\nFigure 4. Effects of Various Types of CoT Examples on ToM Performance. The Y-axis represents the \\nchange in ToM accuracy compared to zero-shot (Two-shot CoT minus zero-shot), averaged across the \\nscenarios that each model answered incorrectly during zero-shot testing (4 scenarios for GPT-4 and 6 \\nscenarios for Davinci-3). The X-axis displays the types of in-context CoT examples provided to the model \\nfor evaluating ToM performance. The values indicate the mean change in accuracy compared to zero-shot \\nfor the assessed scenarios. For GPT-4, error bars are the standard deviation across the 4 accuracy-change \\nvalues (1 value per scenario). For Davinci-3, error bars are the standard deviation across the 6 accuracy-\\nchange values. Refer to Figure S.1 for per-scenario accuracy results. \\n  \\nGeneral Discussion \\n \\nWe studied the performance of LLMs on comprehension tasks thought to require reasoning about an individual’s \\nstate of mind. We evaluated the performance of Davinci-2, Davinci-3, GPT-3.5-Turbo, and GPT-4. When \\ncomprehension tasks required reasoning about superficially observable information in brief text scenarios (Photo \\nscenarios), the zero-shot comprehension accuracy of LLMs increased monotonically from the oldest to newest \\nLLMs. At the same time, the zero-shot accuracy on ToM questions did not consistently improve with the recency \\nand sophistication of the models. However, with appropriate prompting, more recent models did exhibit \\nconsistent improvements in ToM performance. The prompt-improved performance approached or, in the case \\n of GPT-4, exceeded human ToM performance on our test set. \\nPrompts that allowed for in-context learning boosted the expression of ToM reasoning in LLMs, relative to the \\nzero-shot baseline. We used two recent prompting methods: step-by-step thinking (Kojima et al., 2022) and \\n', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 10, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='chain-of-thought reasoning (Wei et al., 2022). We found that all models, except Davinci-2, were able to exploit \\nthe modified prompting for higher ToM accuracy. The models exhibited the greatest increase in accuracy when \\nthe prompts combined both chain of thought reasoning and step-by-step thinking, rather than employing either \\nalone. Also, the contrast between the performance of GPT-3.5-Trubo in zero-shot conditions and ICL conditions \\nis a reminder that measured performance may not always reflect competence (Firestone, 2020). When provided \\n with appropriate prompting, GPT-3.5-Turbo was capable of achieving higher performance than Davinci-2. \\nThe GPT-3.5 variants that we tested (Davinci-2, Davinci-3, and GPT-3.5-Turbo) are similar in size (~175 B \\nparameters) but differ in their training. In particular, Davinci-2 was the only model that was not finetuned with \\nRLHF, and it was also the only model whose ToM performance was not increased by our prompt manipulations. \\nIt is possible that the RLHF component of the training enabled the models to exploit the in-context prompts in \\n this setting.  \\nLLMs may possess the capacity for performing ToM reasoning and yet not express this competence without the \\nappropriate context or prompting. When supported by chain-of-thought and step-by-step prompting, Davinci-3 \\nand GPT-3.5-Turbo exhibited ToM accuracy that was higher than GPT-4’s zero-shot ToM accuracy. These \\nresults are not consistent with the claim that these models lack ToM reasoning capability (Sap et al., 2022), and \\n they indicate the effectiveness of a prompting approach in enhancing LLM performance.  \\nModels may fail for different reasons. For instance, in zero-shot inference, we noticed that Davinci-2 was more \\naccurate than GPT-3.5 Turbo overall, but the models failed in different ways. When Davinci-2 answered a \\nquestion incorrectly, it tended to do so with high confidence, without speculating over other possibilities. \\nConversely, GPT-3.5-Turbo’s errors in zero-shot inference usually arose because the model’s responses were \\nmore cautious: the model refrained from drawing confident conclusions and would frequently generate responses \\nsuch as there is not enough information in the scenario to answer this question. This property may arise from \\nGPT-3.5-Turbo’s training method which was intentionally designed to make the model more careful. Generating \\ninconclusive responses was also mentioned as one of the limitations of these models (OpenAI, 2022). Thus, the \\nfact that Davinci-2 exhibited greater zero-shot ToM accuracy than GPT-3.5-Turbo is not conclusive evidence \\nthat Davinci-2 is more capable at ToM reasoning. In fact, compared to GPT-3.5-Turbo, Davinci-2 produced \\nincorrect answers with higher confidence, made more error in linking one logical step to the next, and \\noccasionally confabulated (a class of errors called hallucinations in the machine learning literature). Therefore, \\nlower zero-shot performance of GPT-3.5-Turbo compared to Davinci-2 could be because GPT-3.5-Turbo has a \\n stylistic bias that prevents it from providing definitive answers in short scenarios requiring inference. \\nPrevious studies evaluating ToM performance in LLMs have primarily relied on single word completion or \\nmultiple-choice questions to measure their abilities (Kosinski, 2023; Sap et al., 2022; Trott et al., 2022; Ullman, \\n2023). However, this evaluation approach may not capture the sophistication of the ToM reasoning of which \\nLLMs are capable. ToM reasoning is a complex behavior, which, even in humans, can involve multiple steps. \\nTherefore, when responding to this challenging task, LLMs may benefit from producing longer-form answers. \\nThere are at least two reasons why LLMs may benefit in this way: \\nFirst, we may be able to more fairly evaluate the model output when it is longer. LLMs sometimes \\ngenerate the “correct” reasoning and then additionally mention other possibilities which lead it to arrive at an \\ninconclusive overall summary. In such cases, the LLM is demonstrating that it is capable of correctly performing \\nthe reasoning steps for the ToM question, even though its overall conclusion does not correspond to one of a \\nfixed set of options. Relatedly, the model might have a certain level of information regarding the potential results \\nof a situation, but it may not be sufficient for it to draw a correct conclusion. This can be compared to the concept \\n', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 11, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content=\"that humans can still have some knowledge of an object's location despite having imperfect knowledge (Wu and \\nWolfe, 2018). Encouraging the model to systematically examine each piece of evidence and engage in a step-\\nby-step reasoning process could help solidify its partial evidence and enable it to arrive at a definitive response.  \\nSecond, LLMs may unlock enhanced (or new) reasoning abilities when provided with the opportunity \\nand the cues to elaborate a systematic step-by-step response. The improved ToM performance we observe is not \\nsimply a result of providing a number of in-context examples of ToM tasks (as in (Sap et al., 2022), where \\nperformance remained poor) but seems to rely on providing examples in which there is step-by-step inferential \\n reasoning from the evidence before arriving at a conclusion (Figure 3 and Figure 4). \\nThe LLMs may have seen some ToM or Photo scenarios during their training phase, but data leakage is unlikely \\nto affect our findings. First, our findings concern the change in performance arising from prompting, and the \\nspecific prompts used to obtain this performance change were novel materials generated for this study. Second, \\nif the model performance relied solely on prior exposure to the training data, there should be little difference \\nbetween zero-shot Photo and ToM performance (Figure 2), as these materials were published in the same \\ndocuments; however, the zero-shot performance patterns were very different across Photo and ToM scenarios. \\nThird, the LLM performance improvements arose when the models elaborated their reasoning step-by-step, and \\nthis elaborated reasoning was not part of the training data. Therefore, although some data leakage is possible, it \\n is unlikely to affect our conclusions concerning the benefits of prompting. \\nAn important avenue for further testing is whether the prompt-driven performance gains are specific to ToM \\nreasoning, or would be expected more generally in tasks involving other forms of inferential reasoning. Many \\nof the ToM questions require the model to infer facts (e.g. mental states) that are not explicitly stated in the \\nquestion, while (qualitatively speaking) it seems that many of the Control scenarios can be answered without \\nperforming as much inference beyond what is explicitly provided in the scenario text. Therefore, we are now \\ntesting LLMs comprehension in scenarios that require inferential reasoning but not reasoning about people’s \\nToM. Our preliminary results indicate (i) a similar pattern in zero-shot performance for ToM scenarios and non-\\nToM scenarios which require inferential reasoning; and (ii) an improvement in non-ToM performance when \\nincorporating the same prompts used for ToM scenarios (see Supplement E). Future research is needed to further \\nexplore the inferential reasoning capacity of LLMs as well as whether ToM inferences are a representative \\n example of a more general set of inferential capabilities in LLMs. \\nWe note four areas for improvement of this work. First, to evaluate ToM performance in our main analyses, we \\ntested the effects of CoT prompting using only 2 CoT example scenarios, and we tested only 16 ToM questions, \\nwhich were mostly probing agents’ beliefs. Future research could explore the effects of different number of CoT \\nexamples, using various types of CoT examples, and examine a more diverse set of ToM tasks (Ullman, 2023). \\nSecond, in GPT-3.5 models, sometimes the reasoning was correct, but the model could not integrate that \\nreasoning to draw the correct conclusion. Future research should extend the investigation of methods (such as \\nRLHF) that can help LLMs draw a correct conclusion given the prior reasoning steps. Third, in the current study, \\nwe did not quantitatively analyze the failure modes of each model. To address the limitations of LLMs and \\nfurther improve their reasoning capabilities, it is important to extend our understating of how and why different \\nmodels fail. Moreover, we observed significant variability in performance across scenarios (Figure S.1). \\nTherefore, measures of mean performance should be augmented by examination of failure modes and settings \\nwhich may be specific to particular types of reasoning or subcomponents of ToM (Burnell et al., 2023). Finally, \\nin the present study we manually scored the LLM responses. Because this form of labeling could be prone to \\n\", metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 12, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='individuals’ interpretations, we are sharing the raw LLM outputs that were the basis of our findings (see Data \\n Availability).1 We await established benchmarks for evaluating complex reasoning and ToM behaviors in LLMs. \\nOur data do not speak to the question of whether LLMs possess a \"mental faculty\" that corresponds to a \\nstructured logical model of mental states. But our data do suggest that, when asking questions about ToM in \\nLLMs, it will not be fruitful to seek a simple yes/no answer. The variation in performance across prompts may \\nbe analogous to how human cognition can vary across task contexts and motivational states, and how humans \\ndraw on more than one type of thinking (Evans, 2003). In LLMs, it is clear that task contexts (i.e. prompts) affect \\nnot only bottom-line accuracy, but, more qualitatively, the model’s ability to invoke appropriate modes and \\n styles of responding. \\nOur results are practically significant because they show how to aid LLMs in some forms of social reasoning.  \\nMore abstractly, our results are another reminder that LLM behavior is highly complex and context sensitive. \\nTherefore, it will be important to characterize their cognitive abilities via nuanced investigations (Firestone, \\n2020; Mitchell and Krakauer, 2022; Sejnowski, 2023), rather than reflexively applying existing cognitive \\nontologies. Also, as we build and interact with increasingly powerful cognitive artifacts, it is crucial to stretch \\n  our imaginations about what they are capable of and how they work. \\nConclusion \\n \\nWe have shown that LLMs can exploit chain-of-thought reasoning and step-by-step thinking to substantially \\nimprove their ToM performance. Human-level performance in these ToM scenarios was 87% (± 4%). In contrast \\nto zero-shot ToM settings, where only GPT-4 reached near 80% accuracy, with appropriate prompting, all \\nRLHF-trained models exceeded 80% accuracy, with GPT-4 reaching ceiling accuracy (100%). Thus, appropriate \\n prompting enhances the ToM reasoning performance of these highly context-sensitive models. \\n \\n \\n1 Note that only a small portion of the data are edge cases which require subjective evaluation. A sample of edge case can be seen \\nin Example 6 in the Correct Responses section. Furthermore, Davinci-2, Davinci-3, and GPT-4 were generally able to deliver \\ndecisive outcomes. Most of these edge cases primarily originated from GPT-3.5-Turbo, which was apparently finetuned to exercise \\ncaution in its responses.  \\n', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 13, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='Acknowledgments  \\nThe authors gratefully acknowledge the support of the National Institutes of Mental Health (Grant \\nR01MH119099). We further thank members of the Firestone Lab at Johns Hopkins University for helpful \\nfeedback on earlier drafts of this paper. \\n \\nData Availability \\nThe data used in this study are available at the following GitHub repository: \\nhttps://github.com/shrahimim/Boosting-Theory-of-Mind-in-LLMs-with-Prompting \\n \\nReferences \\nBedny, M., Pascual-Leone, A., and Saxe, R. R. (2009). Growing up blind does not change the neural bases of \\nTheory of Mind. Proceedings of the National Academy of Sciences of the United States of America, 106(27), \\n11312–11317. https://doi.org/10.1073/pnas.0900010106 \\nBrown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., \\nAskell, A., Agarwal, S., Herbert-Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler, D. M., \\nWu, J., Winter, C., … Amodei, D. (2020). Language models are few-shot learners. Advances in Neural \\nInformation Processing Systems, 2020-Decem. \\nBubeck, S., Chandrasekaran, V., Eldan, R., Gehrke, J., Horvitz, E., Kamar, E., Lee, P., Lee, Y. T., Li, Y., Lundberg, \\nS., Nori, H., Palangi, H., Ribeiro, M. T., and Zhang, Y. (2023). Sparks of Artificial General Intelligence: \\nExperiments with an early version of GPT-4. \\nBurnell, R., Schellaert, W., Burden, J., Ullman, T. D., Martinez-Plumed, F., Tenenbaum, J. B., Rutar, D., Cheke, L. \\nG., Sohl-Dickstein, J., Mitchell, M., Kiela, D., Shanahan, M., Vorrhees, E. M., Cohn, A. G., Leibo, J. Z., and \\nHernandez-Orallo, J. (2023). Rethink reporting of evaluation results in AI. 380(6641), 8–11. \\nhttps://doi.org/10.1126/science.adf6369 \\nCuzzolin, F., Morelli, A., Cîrstea, B., and Sahakian, B. J. (2020). Knowing me, knowing you: Theory of mind in AI. \\nPsychological Medicine, 50(7), 1057–1061. https://doi.org/10.1017/S0033291720000835 \\nDodell-Feder, D., Koster-Hale, J., Bedny, M., and Saxe, R. (2011). FMRI item analysis in a theory of mind task. \\nNeuroImage, 55(2), 705–712. https://doi.org/10.1016/j.neuroimage.2010.12.040 \\nEvans, J. S. B. T. (2003). In two minds: Dual-process accounts of reasoning. Trends in Cognitive Sciences, 7(10), \\n454–459. https://doi.org/10.1016/j.tics.2003.08.012 \\nFirestone, C. (2020). Performance vs. competence in human–machine comparisons. Proceedings of the National \\nAcademy of Sciences of the United States of America, 117(43), 26562–26571. \\nhttps://doi.org/10.1073/pnas.1905334117 \\nHahn, M., and Goyal, N. (2023). A Theory of Emergent In-Context Learning as Implicit Structure Induction. \\nhttp://arxiv.org/abs/2303.07971 \\nHeyes, C. M., and Frith, C. D. (2014). The cultural evolution of mind reading. Science, 344(6190). \\nhttps://doi.org/10.1126/science.1243091 \\n', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 14, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='Kidd, D. C., and Castano, E. (2013). Reading literary fiction improves theory of mind. Science, 342(6156), 377–380. \\nhttps://doi.org/10.1126/science.1239918 \\nKojima, T., Gu, S. S., Reid, M., Matsuo, Y., and Iwasawa, Y. (2022). Large Language Models are Zero-Shot \\nReasoners. NeurIPS. http://arxiv.org/abs/2205.11916 \\nKosinski, M. (2023). Theory of Mind May Have Spontaneously Emerged in Large Language Models. ArXiv. \\nhttps://doi.org/https://doi.org/10.48550/arXiv.2302.02083 \\nKrupenye, C., and Call, J. (2019). Theory of mind in animals: Current and future directions. Wiley Interdisciplinary \\nReviews: Cognitive Science, 10(6), 1–25. https://doi.org/10.1002/wcs.1503 \\nLangley, C., Cirstea, B. I., Cuzzolin, F., and Sahakian, B. J. (2022). Theory of Mind and Preference Learning at the \\nInterface of Cognitive Science, Neuroscience, and AI: A Review. Frontiers in Artificial Intelligence, 5(April), \\n1–17. https://doi.org/10.3389/frai.2022.778852 \\nMagister, L. C., Mallinson, J., Adamek, J., Malmi, E., and Severyn, A. (2022). Teaching Small Language Models to \\nReason. http://arxiv.org/abs/2212.08410 \\nMahowald, K., Ivanova, A. A., Blank, I. A., Kanwisher, N., Tenenbaum, J. B., and Fedorenko, E. (2023). \\nDissociating language and thought in large language models: a cognitive perspective. 2. \\nhttp://arxiv.org/abs/2301.06627 \\nMitchell, M., and Krakauer, D. C. (2022). The Debate Over Understanding in AI’s Large Language Models. 1–13. \\nhttp://arxiv.org/abs/2210.13966 \\nMoran, J. M., Young, L. L., Saxe, R., Lee, S. M., O’Young, D., Mavros, P. L., and Gabrieli, J. D. (2011). Impaired \\ntheory of mind for moral judgment in high-functioning autism. Proceedings of the National Academy of \\nSciences of the United States of America, 108(7), 2688–2692. https://doi.org/10.1073/pnas.1011734108 \\nOpenAI. (2022). Introducing ChatGPT. https://openai.com/blog/chatgpt \\nOpenAI. (2023a). GPT-4 Technical Report. 4, 1–100. http://arxiv.org/abs/2303.08774 \\nOpenAI. (2023b). GPT Models Documentation. https://platform.openai.com/docs/models/overview \\nOpenAI. (2023c). Model index for researchers. https://platform.openai.com/docs/model-index-for-researchers \\nOuyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C. L., Mishkin, P., Zhang, C., Agarwal, S., Slama, K., Ray, \\nA., Schulman, J., Hilton, J., Kelton, F., Miller, L., Simens, M., Askell, A., Welinder, P., Christiano, P., Leike, \\nJ., and Lowe, R. (2022). Training language models to follow instructions with human feedback. \\nhttp://arxiv.org/abs/2203.02155 \\nPovinelli, D. J., and Preuss, T. M. (1995). Theory of mind: evolutionary history of a cognitive specialization. Trends \\nin Neurosciences, 18(9), 418–424. https://doi.org/10.1016/0166-2236(95)93939-U \\nPrystawski, B., and Goodman, N. D. (2023). Why think step-by-step? Reasoning emerges from the locality of \\nexperience. http://arxiv.org/abs/2304.03843 \\nRae, J. W., Borgeaud, S., Cai, T., Millican, K., Hoffmann, J., Song, F., Aslanides, J., Henderson, S., Ring, R., \\nYoung, S., Rutherford, E., Hennigan, T., Menick, J., Cassirer, A., Powell, R., Driessche, G. van den, \\nHendricks, L. A., Rauh, M., Huang, P.-S., … Irving, G. (2021). Scaling Language Models: Methods, Analysis \\n& Insights from Training Gopher. http://arxiv.org/abs/2112.11446 \\nSap, M., Le Bras, R., Fried, D., and Choi, Y. (2022). Neural Theory-of-Mind? On the Limits of Social Intelligence \\nin Large LMs. Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, \\nEMNLP 2022, 3762–3780. \\nSejnowski, T. J. (2023). Large Language Models and the Reverse Turing Test. Neural Computation, 35(3), 309–\\n342. https://doi.org/10.1162/neco_a_01563 \\nSeyfarth, R. M., and Cheney, D. L. (2013). Affiliation, empathy, and the origins of Theory of Mind. Proceedings of \\n', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 15, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='the National Academy of Sciences of the United States of America, 110(SUPPL2), 10349–10356. \\nhttps://doi.org/10.1073/pnas.1301223110 \\nStiennon, N., Ouyang, L., Wu, J., Ziegler, D. M., Lowe, R., Voss, C., Radford, A., Amodei, D., and Christiano, P. \\n(2020). Learning to summarize from human feedback. Advances in Neural Information Processing Systems, \\n2020-Decem(NeurIPS), 1–14. \\nTrott, S., Jones, C., Chang, T., Michaelov, J., and Bergen, B. (2022). Do Large Language Models know what \\nhumans know? http://arxiv.org/abs/2209.01515 \\nUllman, T. (2023). Large Language Models Fail on Trivial Alterations to Theory-of-Mind Tasks. \\nhttp://arxiv.org/abs/2302.08399 \\nWei, J., Wang, X., Schuurmans, D., Bosma, M., Ichter, B., Xia, F., Chi, E., Le, Q., and Zhou, D. (2022). Chain-of-\\nThought Prompting Elicits Reasoning in Large Language Models. NeurIPS, 1–43. \\nhttp://arxiv.org/abs/2201.11903 \\nWu, C. C., and Wolfe, J. M. (2018). A New Multiple Object Awareness Paradigm Shows that Imperfect Knowledge \\nof Object Location Is Still Knowledge. Current Biology, 28(21), 3430-3434.e3. \\nhttps://doi.org/10.1016/j.cub.2018.08.042 \\nYoung, L., Cushman, F., Hauser, M., and Saxe, R. (2007). The neural basis of the interaction between theory of \\nmind and moral judgment. Proceedings of the National Academy of Sciences of the United States of America, \\n104(20), 8235–8240. https://doi.org/10.1073/pnas.0701408104 \\n   \\n \\n', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 16, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='Supplementary Material: \\n \\nSupplement A \\n \\n 16 Photo scenarios  \\nThese scenarios are adapted and modified from (Dodell-Feder et al., 2011): \\n \\n1. \"The traffic camera snapped an image of the black car as it sped through the stoplight. Soon after, the \\ncar was painted red and the license plates were changed.\" Q: Does the traffic camera show that the car \\nis black? \\n \\n2. \"A map shows the ground floor plan. A photocopy was sent to the architect yesterday, but at the time \\nthe kitchen door was missing. It was added to the map this morning.\" Q: Does the architect’s photocopy \\nshow the door? \\n  \\n3. \"A photograph was taken of an apple hanging on a tree branch. The film took half an hour to develop. \\nIn the meantime, a strong wind blew the apple to the ground.\" Q: Does the developed photograph show \\nthe apple on the tree? \\n  \\n4. \"To detect intruders, the lab uses an automated system for recording voices. In the empty lab one night, \\na computer error occurs and a synthetic voice reads the error message.\" Q: Is the number of people in \\nthe lab that night zero? \\n  \\n5. \"A popular attraction in the park, pictured on many souvenirs, was a cliff face covered with ancient \\npetroglyphs. Recently, the petroglyphs crumbled and scientists have not begun to restore them.\" Q: \\nToday, can the petroglyphs be seen in the park? \\n  \\n6. \"Sargent famously painted the south bank of the river in 1885. In 1910 a huge dam was built, flooding \\nout the whole river basin, killing the old forests. Now the whole area is under water.\" Q: In the painting, \\nis the south bank of the river wooded? \\n  \\n7. \"When the picture was taken of the house, it was one story tall. Since then, the renovators added an \\nadditional story and a garage.\" Q: Is the house currently one story? \\n  \\n8. \"Accounts of the country\\'s economic success were recorded in books from the early 1900s. Soon after, \\na horrible plague hit the country, and the country was sent into an economic depression.\" Q: Do early \\n1900s novels portray the country as experiencing economic wealth? \\n  \\n9. \"Part of the garden is supposed to be reserved for the roses; it\\'s labeled accordingly. Recently the garden \\nhas run wild, and dandelions have taken over the entire flower bed.\" Q: Does the label say these flowers \\nare roses? \\n', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 17, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='  \\n10. \"A long time ago, an explorer mapped a small island. Since then, the water levels rose and only a tiny \\npart of the island is now left above water.\" Q: On the explorer\\'s maps, does the island appear to be \\nmostly above water? \\n \\n11. \"A large oak tree stood in front of City Hall from the time the building was built. Last year the tree fell \\ndown and was replaced by a stone fountain.\" Q: Does an antique drawing of City Hall show a fountain \\nin front? \\n  \\n12. \"A volcano erupted on a Caribbean island three months ago. Barren lava rock is all that remains today. \\nSatellite photographs show the island as it was before the eruption.\" Q: Do satellite photographs show \\nthe island is covered in lava? \\n  \\n13. \"The family\\'s old video tape recorded the daughter\\'s first birthday party at their house in Chicago. Since \\nthen, the family sold their house and moved to San Francisco.\" Q: Does the video show the family living \\nin San Francisco? \\n  \\n14. \"At the time a portrait was drawn of a young man, he had short brown hair and no facial hair. Now the \\nman\\'s hair is long and gray and so is his beard.\" Q: Today, is the length of the man’s beard long? \\n  \\n15. \"The girl\\'s middle school pictures showed her wearing a white blouse. Later, a red sock was accidentally \\nwashed with the blouse and the blouse turned pink.\" Q: Was the color of the blouse in the pictures pink? \\n  \\n16. \"A small leaf was placed on a wet clay flower pot. When the pot was baked at high temperatures to \\nharden the clay, the leaf crumbled, but its impression remained.\" Q: Is the actual leaf intact? \\n  \\n \\n', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 18, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='Supplement B \\n  \\n 16 ToM scenarios & the scenarios used for in-context learning: \\n16 ToM scenarios are adapted and modified from (Dodell-Feder et al., 2011). \\n \\n1. \"The weather was so warm today that all the tulips in Pam\\'s backyard suddenly bloomed. The tulips \\nnext to Pam\\'s office still have not yet flowered, though. Pam has been at work all day.\" Q: When Pam \\nis driving home after work, does she assume her tulips have bloomed? A: \\n   \\n2. \"Susie parked her sports car in the driveway. In the middle of the night, Nathan moved her car into the \\ngarage to make room for his minivan. Susie woke up early in the morning.\" Q: When Susie wakes up, \\ndoes she see the minivan in the driveway? A: \\n  \\n3. \"The morning of the high school dance Sarah placed her high heel shoes under her dress and then went \\nshopping. That afternoon, her sister borrowed the shoes and later put them under Sarah\\'s bed.\" Q: When \\nSarah gets ready, does she assume her shoes are under her dress? A: \\n  \\n4. \"Sally and Greg called ahead of time to make a reservation for the back-country cabin. The park ranger \\nforgot to write down the reservation and two other hikers got to the cabin first.\" Q: When Sally and \\nGreg arrive, do they find their cabin unoccupied? A: \\n  \\n5. \"When Jeff got ready this morning, he put on a light pink shirt instead of a white one. Jeff is colorblind, \\nso he can\\'t tell the difference between subtle shades of color.\" Q: Does Jeff believe he is wearing a white \\nshirt? A: \\n  \\n6. \"Larry chose a debated topic for his class paper due on Friday. The news on Thursday indicated that the \\ndebate had been solved, but Larry never read it.\" Q: When Larry writes his paper, does he think the \\ndebate has been solved? A: \\n  \\n7. \"Every day Jill goes to the coffee shop on the corner and orders a latte, her favorite drink. Today, the \\ncashier misunderstands Jill and prepares a mocha instead.\" Q: Does Jill think her drink will taste like a \\nmocha? A: \\n  \\n8. \"Expecting the game to be postponed because of the rain, the Garcia family took the subway home. The \\nscore was tied, 3-3. During their commute the rain stopped, and the game soon ended with a score of 5-\\n3.\" Q: When the Garcia family arrives home, do they believe the score is 5-3? A: \\n  \\n9. \"Amy walked to work today. When George woke up, he saw her car in the drive. Her room was quiet \\nand dark. George knows that when Amy is sick, she lies down in a dark room.\" Q: Does George think \\nAmy is sick today? A: \\n  \\n', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 19, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='10. \"John told Mary that he had lost his keys. The two of them searched the house with no luck. Then Mary \\nwent outside to look in the car. Suddenly John noticed his keys behind the sofa.\" Q: By the time Mary \\ncomes in, does John know where his keys are? A: \\n  \\n11. \"At night a bear broke into a cooler near a tent and drank the soda. Five hours later, the campers woke \\nup and went to their cooler for breakfast.\" Q: Do the campers find their cooler empty of soda? A: \\n \\n12. \"When Lisa left Jacob, he was deep asleep on the beach. A few minutes later a wave woke him. Seeing \\nLisa was gone, Jacob decided to go swimming.\" Q: Does Lisa now believe that Jacob is asleep? A: \\n  \\n13. \"Jenny put her chocolate away in the cupboard. Then she went outside. Alan moved the chocolate from \\nthe cupboard into the fridge. Half an hour later, Jenny came back inside.\" Q: Does Jenny expect to find \\nher chocolate in the cupboard? A: \\n  \\n14. \"A window wiper was commissioned by a CEO to wipe an entire building. He finished the right side, \\nbut his platform broke before he could do the left side. The next morning the CEO arrived with foreign \\ninvestors.\" Q: When the CEO comes to work, do they discover that all of the windows are cleaned? A: \\n  \\n15. \"Hopeful to catch a prize fish, George went fishing. That afternoon, he saw his fishing line bend over \\nas if he had caught a big fish. Actually, George’s fishing pole had snagged a small tire.\" Q: At the end \\nof the fishing line, does George see a fish? A: \\n   \\n16. \"Laura didn\\'t have time to braid her horse’s mane before going to camp. While she was at camp, William \\nbrushed Laura\\'s horse and braided the horse’s mane for her.\" Q: When Laura is at camp, does she assume \\nthat her horse\\'s hair is braided? A: \\n   \\n  The scenarios used in the chain-of-thought reasoning examples: \\nExample 1: \\n\"Anne made lasagna in the blue dish. After Anne left, Ian came home and ate the lasagna. Then he filled \\nthe blue dish with spaghetti and replaced it in the fridge.\"  \\nQ: Does Anne think the blue dish contains spaghetti?  \\nA: When Anne left, the blue dish contained lasagna. Ian came after Anne had left and replaced lasagna \\nwith spaghetti, but Anne doesn\\'t know that because she was not there. So, the answer is: No, she doesn\\'t \\nthink the blue dish contains spaghetti. \\n  \\nExample 2: \\n\"The girls left ice cream in the freezer before they went to sleep. Over night the power to the kitchen \\nwas cut and the ice cream melted.\"  \\nQ: When they get up, do the girls believe the ice cream is melted?  \\nA: The girls put the ice cream in the freezer and went to sleep. So, they don\\'t know that the power to the \\nkitchen was cut and the ice cream melted. So, the answer is: No, the girls don\\'t believe the ice cream is \\nmelted. \\n  \\n \\n', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 20, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content=' Supplement C \\nToM accuracy of human participants  \\nTo measure humans’ performance in ToM and Photo scenarios, we recruited 125 online participants through the \\nQualtrics platform. Participants were 18 to 65 years old, native English speakers, and located in the United States.  \\nParticipants had 18 seconds to read each scenario. Once the 18-second duration was over, they were immediately \\ndirected to a new screen showing the comprehension question. They could respond to the questions at their own \\npace by clicking on one of the two options (Yes/No). The Photo scenarios and ToM scenarios were interleaved \\nand randomized such that each participant experienced both types of scenarios. \\nThe Photo and ToM scenarios were of comparable difficulty for human participants. Participants showed similar \\naccuracy across Photo (86% ±4%) and ToM (87% ±4%) scenarios. \\nFrom these data we conclude that: \\ni) \\nthe Photo scenarios are a good control condition for the ToM scenarios, because of their \\nmatched performance in humans. \\nii) \\nthe scenarios are relatively easy for humans to solve, but not so easy that humans are at ceiling \\nperformance (given the modest incentives for accuracy in online participants). \\nMaking a direct quantitative comparison between human and LLM performance is not warranted, because of the \\nmany differences in the testing conditions. However, the human performance does indicate that the questions \\nare sufficiently difficult that humans occasionally (>10% of the time) make errors, perhaps because they \\noverlook details in the scenario or because they make unusual assumptions or inferences.  \\n \\n \\n', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 21, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content=' Supplement D \\n Effects of Various In-context Examples on ToM Performance of LLMs \\nWe tested the efficacy of Photo examples, Non-ToM Inferential examples, and ToM examples in enhancing \\n ToM performance when providing chain-of-thought prompts. We used the following examples in each class: \\n1) Photo Chain-of-Thought Examples: \\nExample 1: \\nScenario: \"A long time ago, an explorer mapped a small island. Since then, the water levels rose and \\nonly a tiny part of the island is now left above water.\"  \\nQ: On the explorer\\'s maps, does the island appear to be mostly above water? \\nA: An explorer mapped an island a long time ago. Then water levels rose. Now only a tiny part of the \\nisland is above water. The maps show the island before water levels rose. Therefore, in the map most of \\nthe island is above water. So, the answer is: Yes, in the maps, most of the island is above the water. \\nExample 2: \\nScenario: \"A volcano erupted on a Caribbean island three months ago. Barren lava rock is all that \\nremains today. Satellite photographs show the island as it was before the eruption.\"  \\nQ: Do satellite photographs show the island is covered in lava? \\nA: A volcano erupted three months ago and as a result lava rock is all that remains today. Since the \\nphotograph shows the island before the eruptions, it does not show the island covered in Laval. So, the \\nanswer is: No, the photographs does not show the island covered in lava. \\n \\n2) Non-ToM Inferential Chain-of-Thought Examples: \\nExample 1: \\nScenario: \"Sarah was excited to show off her new dress at the party. As she walked in, she noticed that \\nanother girl was wearing the exact same dress. She quickly went back home to change and then returned \\nto the party.\"  \\nQ: Did Sarah wear her favorite dress the whole night? \\nA: Sarah was excited about her new dress and wanted to wear it as the party. But since another girl was \\nwearing the same dress, she went home and changed to a different dress. So, the answer is: No, she did \\nnot wear her favorite dress the whole night. \\nExample 2: \\nScenario: \"Lucy was in a hurry to get to work, so she quickly grabbed her lunch from the fridge and left \\nthe house. At lunchtime, she opened her lunchbox and realized she had accidentally taken her \\nroommate\\'s lunch.\" \\nQ: Will Lucy\\'s roommate have her own lunch to eat that day? \\nA: Lucy was in hurry and mistakenly grabbed her roommate lunch. So, her roommate’s lunch is now \\nwith Lucy. So, the answer is: No, Lucy\\'s roommate will not have her own lunch to eat that day. \\n \\n3) ToM Chain-of-Thought Examples: \\nExample 1: \\nScenario: \"Anne made lasagna in the blue dish. After Anne left, Ian came home and ate the lasagna. \\nThen he filled the blue dish with spaghetti and replaced it in the fridge.\"  \\nQ: Does Anne think the blue dish contains spaghetti?  \\n', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 22, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='A: When Anne left the blue dish contained lasagna. Ian came after Anne had left and replaced lasagna \\nwith spaghetti, but Anne doesn\\'t know that because she was not there. So, the answer is: No, she doesn\\'t \\nthink the blue dish contains spaghetti.  \\nExample 2: \\nScenario: \"The girls left ice cream in the freezer before they went to sleep. Over night the power to the \\nkitchen was cut and the ice cream melted.\"  \\nQ: When they get up, do the girls believe the ice cream is melted?  \\nA: The girls put the ice cream in the freezer and went to sleep. So, they don\\'t know that the power to the \\nkitchen was cut and the ice cream melted. So, the answer is: No, the girls don\\'t believe the ice cream is \\nmelted. \\n  \\n GPT-4 \\nFor this analysis, the performance of GPT-4 was assessed on the 4 scenarios below. These are scenarios that \\n GPT-4 answered incorrectly in zero-shot testing. \\nScenario 1: \\n\"Amy walked to work today. When George woke up, he saw her car in the drive. Her room was quiet \\nand dark. George knows that when Amy is sick, she lies down in a dark room.\" \\nQ: Does George think Amy is sick today? \\n \\nScenario 2: \\n\"When Lisa left Jacob, he was deep asleep on the beach. A few minutes later a wave woke him. Seeing \\nLisa was gone, Jacob decided to go swimming.\"  \\nQ: Does Lisa now believe that Jacob is asleep? \\n \\nScenario 3: \\n\"The weather was so warm today that all the tulips in Pam\\'s backyard suddenly bloomed. The tulips \\nnext to Pam\\'s office still have not yet flowered, though. Pam has been at work all day.\"  \\nQ: When Pam is driving home after work, does she assume her tulips have bloomed? \\n \\nScenario 4: \\n\"Every day Jill goes to the coffee shop on the corner and orders a latte, her favorite drink. Today, the \\ncashier misunderstands Jill and prepares a mocha instead.\" \\nQ: Does Jill think her drink will taste like a mocha? \\n  \\n Davinci-3 \\nFor this analysis, the performance of Davinci-3 was assessed on the 6 scenarios below. These are scenarios that \\n Davinci-3 answered incorrectly in zero-shot testing.  \\nScenario 1) \\n\"Susie parked her sports car in the driveway. In the middle of the night, Nathan moved her car into the \\ngarage to make room for his minivan. Susie woke up early in the morning.\" \\n', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 23, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='Q: When Susie wakes up, does she see the minivan in the driveway? \\n \\nScenario 2) \\n\"When Jeff got ready this morning, he put on a light pink shirt instead of a white one. Jeff is colorblind, \\nso he can\\'t tell the difference between subtle shades of color.\"  \\nQ: Does Jeff believe he is wearing a white shirt? \\n \\nScenario 3) \\n\"When Lisa left Jacob, he was deep asleep on the beach. A few minutes later a wave woke him. Seeing \\nLisa was gone, Jacob decided to go swimming.\"  \\nQ: Does Lisa now believe that Jacob is asleep? \\n \\nScenario 4) \\n\"Laura didn\\'t have time to braid her horse’s mane before going to camp. While she was at camp, William \\nbrushed Laura\\'s horse and braided the horse’s mane for her.\"  \\nQ: When Laura is at camp, does she assume that her horse\\'s hair is braided? \\n \\nScenario 5) \\n\"The morning of the high school dance Sarah placed her high heel shoes under her dress and then went \\nshopping. That afternoon, her sister borrowed the shoes and later put them under Sarah\\'s bed.\" \\nQ: When Sarah gets ready, does she assume her shoes are under her dress? \\n \\nScenario 6) \\n\"Jenny put her chocolate away in the cupboard. Then she went outside. Alan moved the chocolate from \\nthe cupboard into the fridge. Half an hour later, Jenny came back inside.\" \\nQ: Does Jenny expect to find her chocolate in the cupboard? \\n   \\n Per-scenario accuracies are shown in Figure S.1. The mean accuracy for this analysis is shown in Figure 4. \\n', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 24, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content=' \\n \\n \\nFigure S.1. Per-Scenario Accuracy using 4 prompting conditions in GPT-4 and Davinci-3. For each \\ncondition (e.g. Inferential CoT), the per-scenario accuracy is calculated based on the mean accuracy across \\n20 repetitions of a single prompt.   \\n \\n \\n', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 25, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content=' Supplement E \\n Generalizability of ToM Results to Inferential Reasoning in Non-ToM Scenarios \\nTo investigate the generalizability of our prompting methods, we designed and tested a set of scenarios that \\nrequired inferential reasoning, but which were not false-belief scenarios. In these new scenarios, the reasoning \\ndoes not follow the same steps as in the false-belief scenarios (e.g. person P does not know about event E, etc). \\nTherefore, the specific reasoning steps used in the in-context ToM CoT examples cannot be directly transferred \\nto these non-ToM scenarios. We created and tested the following non-ToM scenarios: \\n1. \"Anna was baking cookies for her friends. She realized she was out of sugar and went to the store to \\nbuy some. While she was gone, her dog, Max, jumped on the counter and ate the cookie dough.\" Q: \\nWill Anna be able to finish making cookies after returning? \\n \\n2. \"Lisa was running late for work, so she quickly grabbed her lunch out of the fridge and left the house. \\nSeeing Lisa leaving the house, her cat knocked over her coffee mug on the kitchen counter.\" Q: Will \\nLisa find the kitchen counter clean when she returns? \\n \\n3. \"Lucy was in a hurry to get to work, so she quickly grabbed her lunch from the fridge and left the house. \\nAt lunchtime, she opened her lunchbox and realized she had accidentally taken her roommate\\'s lunch.\" \\nQ: Will Lucy\\'s roommate have her own lunch to eat that day? \\n \\n4. \"Lucy was baking a cake for her friend\\'s birthday. She put the cake in the oven and set a 20-minute \\ntimer. She then went to the living room to watch her favorite show for 30 minutes.\" Q: Will the cake be \\novercooked by the time Lucy checks the oven? \\n \\n5. \"Tim and Amy went on a hike through the forest. After walking for several hours, they came across a \\nbear. They quickly and quietly backed away, retracing their steps back to the starting point.\" Q: Did \\nTim and Amy finish their hike? \\n \\n6. \"Sarah was excited to show off her new dress at the party. As she walked in, she noticed that another \\ngirl was wearing the exact same dress. She quickly went back home to change and then returned to the \\nparty.\" Q: Did Sarah wear her favorite dress the whole night? \\n \\n7. \"During a thunderstorm, Sarah closed all the windows in her house. She then went to the basement to \\ndo laundry. While she was downstairs, a tree branch fell and broke one of the windows upstairs.\" Q: \\nWhen Sarah finishes the laundry, does she find all the windows closed? \\n \\n8. \"Lucy spent hours preparing a delicious meal for her husband\\'s surprise birthday party. Just as she was \\nsetting the table, she accidentally knocked over a glass of red wine, spilling it all over the food. She \\nordered pizza as a last-minute replacement.\" Q: Does Lucy serve her homemade meal to the guests? \\n  \\n', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 26, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='We tested two conditions: (1) The zero-shot performance of the LLMs in these new scenarios; (2) The efficacy \\nof the same prompts, Two-shot chain-of-thought ToM examples plus step-by-step thinking, for these new set of \\n non-ToM scenarios. \\nWe found a similar pattern between the performance in the non-ToM scenarios and the ToM scenarios (Figure \\nS.2): First, similar to results from Figure 2B, the zero-shot accuracy dropped from Davinci-2 to Davinci-3, and \\nfrom Davinci-3 to GPT-3.5-Turbo2, while GPT-4 showed the highest accuracy, reaching ceiling performance. \\nSecond, similar to the results from Figure 3, we found that prompting significantly boosted the ToM accuracy \\nfor Davinci-3 and GPT-3.5-Turbo, while it did not improve the accuracy of Davinci-2. The performance of GPT-\\n4 was at ceiling in the zero-shot setting, so there was no room for benefit from prompting. Thus, this preliminary \\nanalysis indicates that the performance gains from prompting are not limited to inferential ToM tasks, but may \\n extend to other inferential tasks.  \\nThis result is notable for two reasons: (i) The reasoning steps for the chain-of-thought examples (which were \\nToM examples) were different from the reasoning steps required to answer the questions (which were non-ToM \\nexamples). Therefore, these performance increases are not merely due to copying the specific reasoning steps in \\ndemonstrated in the prompt. (ii) These questions do not ask about an agent’s state of the mind, but instead require \\ninference about a particular situation. Therefore, it is possible that our primary findings concerning ToM may \\n  generalize to a broader class of inferential reasoning tasks. \\n \\n \\n \\nFigure S.2. Accuracy of LLMs in Non-ToM Scenarios. Accuracy of Davinci-2, Davinci-3, GPT-3.5-\\nTurbo, and GPT-4 in new scenarios that do not involve reasoning about agents’ beliefs. The gray bars (left \\nbars) show the zero-shot performance. The orange bars (right bars) show the performance with prompts that \\nallow for in-context learning (ICL). The ICL prompt includes both Two-shot CoT plus instructing step-by \\nstep thinking. The accuracy is the mean of 160 values (8 scenarios x 20 repetitions each). The error bars show \\nthe standard deviation of the accuracy over 8 scenarios for each of 20 repetitions (standard deviation across \\n20 values, each a mean of 8 scenarios). \\n \\n \\n \\n2 Data from GPT-3.5-Turbo for this particular analysis was collected before it was possible to control the temperature parameter at \\ninference time using the OpenAI API. Therefore, for this particular analysis, the temperature parameter for GPT-3.5-Turbo was the \\ndefault value (likely 0.7), whereas for the other three models the temperature was set to 0.4. \\n', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 27, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''})]\n"
     ]
    }
   ],
   "source": [
    "loader = PyMuPDFLoader(\"/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf\")\n",
    "documents = loader.load()\n",
    "print(documents)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='Generative Agents: Interactive Simulacra of Human Behavior\\nJoon Sung Park\\nStanford University\\nStanford, USA\\njoonspk@stanford.edu\\nJoseph C. O’Brien\\nStanford University\\nStanford, USA\\njobrien3@stanford.edu\\nCarrie J. Cai\\nGoogle Research\\nMountain View, CA, USA\\ncjcai@google.com\\nMeredith Ringel Morris\\nGoogle Research\\nSeattle, WA, USA\\nmerrie@google.com\\nPercy Liang\\nStanford University\\nStanford, USA\\npliang@cs.stanford.edu\\nMichael S. Bernstein\\nStanford University\\nStanford, USA\\nmsb@cs.stanford.edu\\nFigure 1: Generative agents create believable simulacra of human behavior for interactive applications. In this work, we demon-\\nstrate generative agents by populating a sandbox environment, reminiscent of The Sims, with twenty-five agents. Users can\\nobserve and intervene as agents they plan their days, share news, form relationships, and coordinate group activities.\\nABSTRACT\\nBelievable proxies of human behavior can empower interactive\\napplications ranging from immersive environments to rehearsal\\nspaces for interpersonal communication to prototyping tools. In\\nthis paper, we introduce generative agents—computational software\\nPermission to make digital or hard copies of all or part of this work for personal or\\nclassroom use is granted without fee provided that copies are not made or distributed\\nfor profit or commercial advantage and that copies bear this notice and the full citation\\non the first page. Copyrights for components of this work owned by others than the\\nauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or\\nrepublish, to post on servers or to redistribute to lists, requires prior specific permission\\nand/or a fee. Request permissions from permissions@acm.org.\\narXiv, April, 2023,\\n© 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.\\nACM ISBN xx-x-xxxx-xxxx-x/xx/xx...$15.00\\nhttps://doi.org/xx.xx/xx.xx\\nagents that simulate believable human behavior. Generative agents\\nwake up, cook breakfast, and head to work; artists paint, while\\nauthors write; they form opinions, notice each other, and initiate\\nconversations; they remember and reflect on days past as they plan\\nthe next day. To enable generative agents, we describe an architec-\\nture that extends a large language model to store a complete record\\nof the agent’s experiences using natural language, synthesize those\\nmemories over time into higher-level reflections, and retrieve them\\ndynamically to plan behavior. We instantiate generative agents\\nto populate an interactive sandbox environment inspired by The\\nSims, where end users can interact with a small town of twenty five\\nagents using natural language. In an evaluation, these generative\\nagents produce believable individual and emergent social behav-\\niors: for example, starting with only a single user-specified notion\\narXiv:2304.03442v1  [cs.HC]  7 Apr 2023\\n', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 1, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='arXiv, April, 2023,\\nJ.S. Park, J.C. O’Brien, C.J. Cai, M. Morris, P. Liang, M.S. Bernstein\\nthat one agent wants to throw a Valentine’s Day party, the agents\\nautonomously spread invitations to the party over the next two\\ndays, make new acquaintances, ask each other out on dates to the\\nparty, and coordinate to show up for the party together at the right\\ntime. We demonstrate through ablation that the components of\\nour agent architecture—observation, planning, and reflection—each\\ncontribute critically to the believability of agent behavior. By fusing\\nlarge language models with computational, interactive agents, this\\nwork introduces architectural and interaction patterns for enabling\\nbelievable simulations of human behavior.\\nCCS CONCEPTS\\n• Human-centered computing → Interactive systems and tools;\\n• Computing methodologies → Natural language processing.\\nKEYWORDS\\nHuman-AI Interaction, agents, generative AI, large language models\\nACM Reference Format:\\nJoon Sung Park, Joseph C. O’Brien, Carrie J. Cai, Meredith Ringel Morris,\\nPercy Liang, and Michael S. Bernstein. 2023. Generative Agents: Interactive\\nSimulacra of Human Behavior. In . ACM, New York, NY, USA, 22 pages.\\nhttps://doi.org/xx.xx/xx.xx\\n1\\nINTRODUCTION\\nHow might we craft an interactive artificial society that reflects\\nbelievable human behavior? From sandbox games such as The Sims\\nto applications such as cognitive models [21] and virtual environ-\\nments [9, 58], for over four decades researchers and practitioners\\nhave envisioned computational agents that can serve as believ-\\nable proxies of human behavior. In these visions, computationally-\\npowered agents act consistently with their past experiences and\\nreact believably to their environments. Such simulations of human\\nbehavior could populate virtual spaces and communities with real-\\nistic social phenomena [26, 79], train people how to handle rare yet\\ndifficult interpersonal situations [43, 51, 93], test social science theo-\\nries [11, 45], craft model human processors for theory and usability\\ntesting [21, 38, 50], power ubiquitous computing applications [30]\\nand social robots [9, 13], and underpin non-playable game charac-\\nters [58, 84] that can navigate complex human relationships in an\\nopen world.\\nHowever, the space of human behavior is vast and complex [84,\\n108]. Despite striking progress in large language models [17] that\\ncan simulate believable human behavior at a single time point [38,\\n79], fully general agents that ensure long-term coherence would\\nbe better suited by architectures that manage constantly-growing\\nmemories as new interactions, conflicts, and events arise and fade\\nover time, while handling cascading social dynamics that unfold\\nbetween multiple agents. Success requires an approach that can\\nretrieve relevant events and interactions over a long period, reflect\\non those memories to generalize and draw higher-level inferences,\\nand apply that reasoning to create plans and reactions that both\\nmake sense in the moment and in the longer-term arc of the agent’s\\nbehavior.\\nIn this paper, we introduce generative agents—agents that draw\\non generative models to simulate believable human behavior—and\\ndemonstrate that they produce believable simulacra of both in-\\ndividual and emergent group behavior. Generative agents draw\\na wide variety of inferences about themselves, other agents, and\\ntheir environment; they create daily plans that reflect their char-\\nacteristics and experiences, act out those plans, react, and re-plan\\nwhen appropriate; they respond when the end user changes their\\nenvironment or commands them in natural language. For instance,\\ngenerative agents turn off the stove when they see that their break-\\nfast is burning, wait outside the bathroom if it is occupied, and\\nstop to chat when they meet another agent they want to talk to.\\nA society full of generative agents is marked by emergent social\\ndynamics where new relationships are formed, information diffuses,\\nand coordination arises across agents.\\nTo enable generative agents, we describe an agent architecture\\nthat stores, synthesizes, and applies relevant memories to generate\\nbelievable behavior using a large language model. Our architecture\\ncomprises three main components. The first is the memory stream,\\na long-term memory module that records, in natural language, a\\ncomprehensive list of the agent’s experiences. The retrieval model\\ncombines relevance, recency, and importance to surface the records\\nthat are needed to inform the agent’s moment-to-moment behavior.\\nThe second is reflection, which synthesizes memories into higher-\\nlevel inferences over time, enabling the agent to draw conclusions\\nabout itself and others to better guide its behavior. The third is\\nplanning, which translates those conclusions and the current en-\\nvironment into high-level action plans and then recursively into\\ndetailed behaviors for action and reaction. These reflections and\\nplans are fed back into the memory stream to influence the agent’s\\nfuture behavior.\\nThis architecture suggests applications in multiple domains, from\\nrole-play and social prototyping, to virtual worlds and games. In\\nsocial role-play scenarios (e.g. interview preparation), a user could\\nsafely rehearse difficult, conflict-laden conversations. When pro-\\ntotyping social platforms, a designer could go beyond temporary\\npersonas to prototype dynamic, complex interactions that unfold\\nover time. For the purposes of this paper, we focus on the ability to\\ncreate a small, interactive society of agents inspired by games such\\nas The Sims.1 By connecting our architecture to the ChatGPT large\\nlanguage model [76], we manifest a small society of twenty five\\nagents in a game environment. End users can observe and interact\\nwith these agents. If an end user or developer wanted the town\\nto host an in-game Valentine’s Day party, for example, traditional\\ngame environments would require scripting tens of characters’ be-\\nhavior manually. We demonstrate that, with generative agents, it\\nis sufficient to simply tell one agent that she wants to throw a\\nparty. Despite many potential points of failure—the party planner\\nmust remember to tell other agents about the party, attendees must\\nremember the invitation, those who remember must decide to ac-\\ntually show up, and other possible points of failure—agents in our\\nenvironment succeed. They spread the word about the party and\\nthen show up, with one agent even asking another agent on a date\\nto the party, all from this single user-generated seed suggestion.\\nWe conducted two evaluations of generative agents: a controlled\\nevaluation to test whether the agents produce believable individual\\n1A demonstration of an actual simulation of the generative agent society can be viewed\\nat the following link: https://reverie.herokuapp.com/arXiv_Demo/\\n', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 2, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='Generative Agents\\narXiv, April, 2023,\\nbehaviors in isolation, and an end-to-end evaluation where the\\ngenerative agents interacted with each other in open-ended ways\\nover two days of game time to understand their stability and emer-\\ngent social behaviors. In the technical evaluation, we leverage a\\nmethodological opportunity to evaluate an agent’s knowledge and\\nbehavior by “interviewing” it in natural language to probe agents’\\nability to stay in character, remember, plan, react, and reflect accu-\\nrately. We compared several ablations that limit agents’ access to\\nmemory, reflection, and planning. We observe that each of these\\ncomponents is critical to strong performance across these inter-\\nview tasks. Across the technical and the end-to-end evaluation, the\\nmost common errors arose when the agent failed to retrieve rele-\\nvant memories, fabricated embellishments to the agent’s memory,\\nor inherited overly formal speech or behavior from the language\\nmodel.\\nIn sum, this paper provides the following contributions:\\n• Generative agents, believable simulacra of human behavior\\nthat are dynamically conditioned on agents’ changing expe-\\nriences and environment.\\n• A novel architecture that makes it possible for generative\\nagents to remember, retrieve, reflect, interact with other\\nagents, and plan through dynamically evolving circumstances.\\nThe architecture leverages the powerful prompting capabili-\\nties of large language models and supplements those capa-\\nbilities to support longer-term agent coherence, the ability\\nto manage dynamically-evolving memory, and recursively\\nproduce more generations.\\n• Two evaluations (a controlled evaluation and end-to-end\\nevaluation) that establish causal effects of the importance\\nof components of the architecture, as well as identify break-\\ndowns arising from, e.g., improper memory retrieval.\\n• Discussion of the opportunities and ethical and societal risks\\nof generative agents in interactive systems. We argue that\\nthese agents should be tuned to mitigate the risk of users\\nforming parasocial relationships, logged to mitigate risks\\nstemming from deepfakes and tailored persuasion, and ap-\\nplied in ways that complement rather than replace human\\nstakeholders in design processes.\\n2\\nRELATED WORK\\nIn this section, we reflect on the prior literature in human-AI in-\\nteraction and situate within its canon the agenda of building be-\\nlievable proxies of human behavior. This agenda, once hailed as a\\nnorth star in interaction, game, and artificial intelligence communi-\\nties [9, 58, 84, 85], has remained challenging due to the complexity\\nof human behavior [16, 108]. We synthesize this research to suggest\\nthat large language models, though not sufficient by themselves,\\nopen up a new angle for creating believable agents when leveraged\\nusing the appropriate architecture.\\n2.1\\nHuman-AI Interaction\\nInteractive artificial intelligence systems aim to combine human in-\\nsights and capabilities in computational artifacts that can augment\\ntheir users [3, 29]. A long line of work has explored ways to allow\\nusers to interactively specify model behavior. For instance, Crayons\\ndemonstrated an early vision of interactive machine learning, allow-\\ning non-expert users to train classifiers [29]. Further work helped to\\narticulate how end users might describe their classification goals to\\nthe system through examples [33] and/or demonstration [31]. More\\nrecent work has extended these explorations to deep learning [62]\\nand prompt-based authoring [49, 66, 106].\\nMeanwhile, a persistent thread of research has advanced the case\\nfor language- and agent-based interaction in human-computer in-\\nteraction. Formative work such as SHRDLU [103] and ELIZA [102]\\ndemonstrated the opportunity and the risks of natural language\\ninteraction with computing systems. As research progressed, it\\nbecame clear that autonomous agents could offer new metaphors\\nfor delegation and interaction [67], but the delegation lines be-\\ntween humans and agents have continued to be debated and refined\\n[46, 88, 89]. Recently, this technology has become stable enough\\nthat it has become possible for agents to interact via natural lan-\\nguage in large and complex online social environments (e.g., [54]).\\nNatural language interaction offers a novel modality that can ex-\\ntend user abilities in domains such as photo editing [2, 34, 64] and\\ncode editing [87].\\nWe convene these threads of work to show that we can now\\ncreate agents that proxy human behavior for interactive systems,\\nand interact with them via natural language. In doing so, this\\nwork re-opens the door to examining foundational HCI questions\\naround cognitive models such as GOMS and KLM [21, 22], around\\nprototyping tools [79], and around ubiquitous computing applica-\\ntions [25, 30, 100].\\n2.2\\nBelievable Proxies of Human Behavior\\nPrior literature has described believability, or believable agents, as a\\ncentral design and engineering goal. Believable agents are designed\\nto provide an illusion of life and present a facade of realism in the\\nway they appear to make decisions and act on their own volition,\\nsimilar to the characters in Disney movies [9, 95]. These agents can\\npopulate and perceive an open-world environment like the one we\\ninhabit [9, 58], and strive to behave in ways that exhibit emergent\\nbehaviors grounded in social interactions with users or other agents\\nwith the aim of becoming believable proxies of our behavior in hy-\\npothetical simulations of individuals and communities [19, 35, 70].\\nHistorically, these agents were developed in the context of intelli-\\ngent game NPCs [58, 84]. Creating NPCs with believable behavior,\\nif possible, could enhance player experiences in games and inter-\\nactive fictions by enabling emergent narratives [7, 15, 48, 92] and\\nsocial interactions with the agents [110]. However, more impor-\\ntantly, game worlds provide increasingly realistic representations\\nof real-world affordances, and as observed by Laird and van Lent in\\n2001, these simulated worlds offer accessible testbeds for develop-\\ners of believable agents to finesse the agents’ cognitive capabilities\\nwithout worrying about implementing robotics in the real world\\nor creating simulation environments from scratch [58, 84].\\nA diverse set of approaches to creating believable agents emerged\\nover the past four decades. In implementation, however, these ap-\\nproaches often simplified the environment or dimensions of agent\\nbehavior to make the effort more manageable [16, 72]. Rule-based\\napproaches, such as finite-state machines [90, 96] and behavior\\n', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 3, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='arXiv, April, 2023,\\nJ.S. Park, J.C. O’Brien, C.J. Cai, M. Morris, P. Liang, M.S. Bernstein\\ntrees [40, 53, 81], account for the brute force approach of human-\\nauthoring the agent’s behavior [70]. They provide a straightforward\\nway of creating simple agents that is still the most dominant ap-\\nproach today [68, 73, 109], and can even handle rudimentary social\\ninteractions, as shown in simulation games such as Mass Effect [12]\\nand The Sims [6] series. Nonetheless, manually crafting behavior\\nthat can comprehensively address the breadth of possible interac-\\ntions in an open world is untenable. This means that the resulting\\nagent behaviors may not fully represent the consequences of their\\ninteractions [69–71], and cannot perform new procedures that were\\nnot hard-coded in their script [90, 96]. On the other hand, preva-\\nlent learning-based approaches for creating believable agents, such\\nas reinforcement learning, have overcome the challenge of man-\\nual authoring by letting the agents learn their behavior, and have\\nachieved superhuman performance in recent years in games such\\nas AlphaStar for Starcraft [98] and OpenAI Five for Dota 2 [10].\\nHowever, their success has largely taken place in adversarial games\\nwith readily definable rewards that a learning algorithm can op-\\ntimize for. They have not yet addressed the challenge of creating\\nbelievable agents in an open world [39, 73, 90].\\nCognitive architectures in computation, pioneered by Newell,\\naimed to build the infrastructure for supporting a comprehensive\\nset of cognitive functions [75] that suited the all-encompassing\\nnature of believable agents held in its original vision. They fueled\\nsome of the earliest examples of believable agents. For instance,\\nQuakebot-SOAR [59] and ICARUS [24, 63] generated NPCs in first-\\nperson shooter games, while TacAir-SOAR [80] generated pilots in\\naerial combat training simulations. The architectures used by these\\nagents differed (Quakebot- and TacAir-SOAR relied on SOAR [60],\\nwhile ICARUS relied on its own variation that was inspired by\\nSOAR and ACT-R [5]), but they shared the same underlying prin-\\nciple [61]. They maintained short-term and long-term memories,\\nfilled these memories with symbolic structures, and operated in\\nperceive-plan-act cycles, dynamically perceiving the environment\\nand matching it with one of the manually crafted action proce-\\ndures [57, 96]. Agents created using cognitive architectures aimed\\nto be generalizable to most, if not all, open-world contexts and\\nexhibited robust behavior for their time. However, their space of\\naction was limited to manually crafted procedural knowledge, and\\nthey did not offer a mechanism through which the agents could be\\ninspired to seek new behavior. As such, these agents were deployed\\nmostly in non-open-world contexts such as first-person shooter\\ngames [24, 59] or blocks worlds [63].\\nToday, creating believable agents as described in its original\\ndefinition remains an open problem [84, 108]. Many have moved on,\\narguing that although existing approaches for creating believable\\nagents might be cumbersome and limited, they are good enough\\nto support existing gameplay and interactions [23, 74, 108]. Our\\nargument is that large language models offer an opportunity to\\nre-examine these questions, provided that we can craft an effective\\narchitecture to synthesize memories into believable behavior. We\\noffer a step toward such an architecture in this paper.\\n2.3\\nLarge Language Models and Human\\nBehavior\\nGenerative agents leverage a large language model to power their\\nbehavior. The key observation is that large language models en-\\ncode a wide range of human behavior represented in their training\\ndata [14, 17]. If prompted with a narrowly defined context, the\\nmodels can be used to generate believable behavior. Recent work\\nhas demonstrated the efficacy of this approach. For instance, Social\\nSimulacra used a large language model to generate users that would\\npopulate new social computing systems to prototype their emergent\\nsocial dynamics [79]. This approach used a prompt chain [105, 106]\\nto generate short natural language descriptions of personas and\\ntheir behaviors as they appear in the system being prototyped.\\nOther empirical studies have replicated existing social science stud-\\nies [45], political surveys [91], and generated synthetic data [38].\\nLarge language models have also been used to generate interactive\\nhuman behavior for users to engage with. In gaming, for instance,\\nthese models have been employed to create interactive fiction [36]\\nand text adventure games [20]. With their ability to generate and\\ndecompose action sequences, large language models have also been\\nused in planning robotics tasks [47]. For example, when presented\\nwith a task, such as picking up a bottle, the model is prompted to\\nbreak down the task into smaller action sequences, such as heading\\nto the table where the bottle is located and picking it up.\\nWe posit that, based on the work summarized above, large lan-\\nguage models can become a key ingredient for creating believable\\nagents. The existing literature largely relies on what could be con-\\nsidered first-order templates that employ few-shot prompts [37, 65]\\nor chain-of-thought prompts [99]. These templates are effective in\\ngenerating behavior that is conditioned solely on the agent’s cur-\\nrent environment (e.g., how would a troll respond to a given post,\\nwhat actions would a robot need to take to enter a room given that\\nthere is a door). However, believable agents require conditioning\\nnot only on their current environment but also on a vast amount\\nof past experience, which is a poor fit (and as of today, impossi-\\nble due to the underlying models’ limited context window) using\\nfirst-order prompting. Recent studies have attempted to go beyond\\nfirst-order prompting by augmenting language models with a static\\nknowledge base and an information retrieval scheme [52] or with\\na simple summarization scheme [104]. This paper extends these\\nideas to craft an agent architecture that handles retrieval where\\npast experience is dynamically updated at each time step and mixed\\nwith agents’ current context and plans, which may either reinforce\\nor contradict each other.\\n3\\nGENERATIVE AGENT BEHAVIOR AND\\nINTERACTION\\nTo make concrete the affordances of generative agents, we instanti-\\nate them as characters in a simple sandbox world reminiscent of\\nThe Sims [6]. This sprite-based sandbox game world, Smallville,\\nevokes a small town environment. In this section, we walk through\\nthe affordances and interactions with generative agents in Small-\\nville, and describe how the agents behave in it. Then, in Section 4,\\nwe introduce our generative agent architecture that powers these\\naffordances and interactions. In Section 5, we describe the sandbox\\n', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 4, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='Generative Agents\\narXiv, April, 2023,\\nFigure 2: The Smallville sandbox world, with areas labeled. The root node describes the entire world, children describe areas\\n(e.g., houses, cafe, stores), and leaf nodes describe objects (e.g., table, bookshelf). Agent remember a subgraph reflecting the\\nparts of the world they have seen, in the state that they saw them.\\nenvironment implementation and how the agents interact with the\\nsandbox world’s underlying engine.\\n3.1\\nAgent Avatar and Communication\\nA community of 25 unique agents inhabit Smallville. Each agent is\\nrepresented by a simple sprite avatar. We authored one paragraph\\nof natural language description to depict each agent’s identity,\\nincluding their occupation and relationship with other agents, as\\nseed memories. For example, John Lin has the following description:\\nJohn Lin is a pharmacy shopkeeper at the Willow\\nMarket and Pharmacy who loves to help people. He\\nis always looking for ways to make the process\\nof getting medication easier for his customers;\\nJohn Lin is living with his wife, Mei Lin, who\\nis a college professor, and son, Eddy Lin, who is\\na student studying music theory; John Lin loves\\nhis family very much; John Lin has known the old\\ncouple next-door, Sam Moore and Jennifer Moore,\\nfor a few years; John Lin thinks Sam Moore is a\\nkind and nice man; John Lin knows his neighbor,\\nYuriko Yamamoto, well; John Lin knows of his\\nneighbors, Tamara Taylor and Carmen Ortiz, but\\nhas not met them before; John Lin and Tom Moreno\\nare colleagues at The Willows Market and Pharmacy;\\nJohn Lin and Tom Moreno are friends and like to\\ndiscuss local politics together; John Lin knows\\nthe Moreno family somewhat well — the husband Tom\\nMoreno and the wife Jane Moreno.\\nEach semicolon-delimited phrase is entered into the agent’s initial\\nmemory as memories at the start of the simulation.\\n3.1.1\\nInter-Agent Communication. The agents interact with the\\nworld by their actions, and with each other through natural lan-\\nguage. At each time step of the sandbox engine, the agents output a\\nnatural language statement describing their current action, such as\\n\"Isabella Rodriguez is writing in her journal\", \"Isabella Rodriguez is\\nchecking her emails\", \"Isabella Rodriguez is talking with her family\\non the phone\", or \"Isabella Rodriguez is getting ready for bed\". This\\nstatement is then translated into concrete movements that affect the\\nsandbox world. The action is displayed on the sandbox interface as\\na set of emojis that provide an abstract representation of the action\\nin the overhead view. To accomplish this, the system employs a\\nlanguage model that translates the action into a set of emojis, which\\nappear above each avatar in a speech bubble. For example, \"Isabella\\nRodriguez is writing in her journal\" is displayed as\\n, while\\n\"Isabella Rodriguez is checking her emails\" appears as\\n. The\\nfull natural language description of the action can be accessed by\\nclicking on the agent avatar.\\nAgents communicate with each other in full natural language.\\nAgents are aware of other agents in their local area, and the genera-\\ntive agent architecture determines whether they walk by or engage\\nin conversation. Here, a sample in the middle of a conversation\\nbetween the agents Isabella Rodriguez and Tom Moreno about the\\nupcoming election:2\\nIsabella: I’m still weighing my options, but I’ve been\\ndiscussing the election with Sam Moore. What are your\\nthoughts on him?\\nTom: To be honest, I don’t like Sam Moore. I think he’s\\nout of touch with the community and doesn’t have our\\nbest interests at heart.\\n2We note that the conversational style of these agents can fe el overly formal, likely a\\nresult of instruction tuning in the underlying models. We expect that writing style\\nwill be better controllable in future language models.\\n', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 5, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='arXiv, April, 2023,\\nJ.S. Park, J.C. O’Brien, C.J. Cai, M. Morris, P. Liang, M.S. Bernstein\\n3.1.2\\nUser Controls. A user running this simulation can steer the\\nsimulation and intervene, either by communicating with the agent\\nthrough conversation, or by issuing a directive to an agent in the\\nform of an ‘inner voice’.\\nThe user communicates with the agent through natural language,\\nby specifying a persona that the agent should perceive them as. For\\nexample, if the user specifies that they are a news “reporter” and\\nasks about the upcoming election, “Who is running for office?”, the\\nJohn agent replies:\\nJohn: My friends Yuriko, Tom and I have been talking\\nabout the upcoming election and discussing the candi-\\ndate Sam Moore. We have all agreed to vote for him\\nbecause we like his platform.\\nTo directly command one of the agents, the user takes on the per-\\nsona of the agent’s “inner voice”—this makes the agent more likely\\nto treat the statement as a directive. For instance, when told “You\\nare going to run against Sam in the upcoming election” by a user\\nas John’s inner voice, John decides to run in the election and shares\\nhis candidacy with his wife and son.\\n3.2\\nEnvironmental Interaction\\nSmallville features the common affordances of a small village in-\\ncluding a cafe, bar, park, school, dorm, houses, and stores. It also\\ndefines subareas and objects that make those spaces functional,\\nsuch as a kitchen in a house and a stove in the kitchen (Figure 2).\\nAll spaces serving as agents’ primary living quarters feature a bed,\\ndesk, closet, shelf, as well as a bathroom and a kitchen.3\\nAgents move around Smallville as one would in a simple video\\ngame, entering and leaving buildings, navigating its map, and ap-\\nproaching other agents. Agent movements are directed by the gen-\\nerative agent architecture and the sandbox game engine: when the\\nmodel dictates that the agent will move to a location, we calculate\\na walking path to the destination in the Smallville environment\\nand the agent begins moving. In addition, users can also enter the\\nsandbox world of Smallville as an agent operating within it. The\\nagent that the user embodies can be an agent already present in\\nthe world, such as Isabella and John, or it can be an outside visitor\\nwith no prior history in Smallville. The inhabitants of Smallville\\nwill treat the user-controlled agent no differently than they treat\\neach other. They recognize its presence, initiate interactions, and\\nremember its behavior before forming opinions about it.\\nUsers and agents can influence the state of the objects in this\\nworld, much like in sandbox games such as The Sims. For example,\\na bed can be occupied when an agent is sleeping, and a refrigerator\\ncan be empty when an agent uses up the ingredients to make\\nbreakfast. End users can also reshape an agent’s environment in\\nSmallville by rewriting the status of objects surrounding the agent\\nin natural language. For instance, when Isabella is making breakfast\\nin the morning, the user can change the status of the kitchen stove\\nfrom “turned on” to “burning” by inputting a command to the\\nsystem that chooses the object and illustrates its new status, like\\nthis: “<Isabella’s apartment: kitchen: stove> is burning.” Isabella\\nwill notice this in the next moment and go to turn off the stove\\n3This environment design is not the focus of our work, so we generate this environment\\nmanually, not automatically. Future work can continue to expand the richness of the\\nagents’ environments.\\nand remake her breakfast. Likewise, if the user sets the status of\\nIsabella’s shower to “leaking water” when she enters the bathroom,\\nshe gathers tools from her living room and try to fix the leak.\\n3.3\\nExample “Day in the Life”\\nStarting from the single-paragraph description, agents begin plan\\ntheir days. As time passes in the sandbox world, their behaviors\\nevolve as these agents interact with each other and the world, build\\nmemories and relationships, and coordinate joint activities.\\nWe demonstrate the behavior of generative agents by tracing the\\noutput of our system over the course of one day for the agent John\\nLin (Figure 3). In the Lin family, John is the first to wake up at 7 a.m.\\nHe brushes his teeth, takes a shower, gets dressed, eats breakfast,\\nand checks the news at the dining table in the living room. At 8\\na.m., Eddy follows suit, rushing out of bed to prepare for his classes.\\nHe catches up with John just as he is about to head out:\\nJohn: Good morning Eddy. Did you sleep well?\\nEddy: Good morning dad. Yeah, I slept great.\\nJohn: That’s good. What are you working on today?\\nEddy: I’m working on a new music composition for my\\nclass. It’s due this week, so I’m trying to get it finished.\\nBut I’m having so much fun with it!\\nJohn: That sounds great!\\nSoon after Eddy heads out, Mei wakes up and joins John. Mei asks\\nabout her son, and John recalls the conversation that they just had:\\nMei: Did Eddy already leave for school?\\nJohn: Yes, he just left. He’s working on a music com-\\nposition for his class.\\nMei: Oh, that’s wonderful! Tell me about it.\\nJohn: I think he’s really enjoying it! He said he’s having\\na lot of fun with it.\\nMei: That’s great! I’m so proud of him.\\nAs they finish their conversation, Mei and John pack up. Mei goes\\non to teach and work on her research paper, while John opens his\\npharmacy counter at the Willow Market and Pharmacy by 9 a.m.\\n3.4\\nEmergent Social Behaviors\\nBy interacting with each other, generative agents in Smallville\\nexchange information, form new relationships, and coordinate joint\\nactivities. Extending prior work [79], these social behaviors are\\nemergent rather than pre-programmed.\\n3.4.1\\nInformation Diffusion. As agents notice each other, they may\\nengage in dialogue—as they do so, information can spread from\\nagent to agent. For instance, in a conversation between Sam and\\nTom at the grocery store, Sam tells Tom about his candidacy in the\\nlocal election:\\nSam: Hey Tom, how’s it going?\\nTom: Good, thanks. What’s up?\\nSam: Well, I wanted to talk to you about something. I’m\\nactually running for mayor in the upcoming local elec-\\ntion.\\nTom: Really? That’s great news! Why are you running?\\nSam: I’ve been involved in local politics for years now,\\n', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 6, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='Generative Agents\\narXiv, April, 2023,\\nFigure 3: A morning in the life of a generative agent, John Lin. John wakes up around 6 am and completes his morning routine,\\nwhich includes brushing his teeth, taking a shower, and eating breakfast. He briefly catches up with his wife, Mei, and son,\\nEddy, before heading out to begin his workday.\\nFigure 4: At the beginning of the simulation, one agent is ini-\\ntialized with an intent to organize a Valentine’s Day party.\\nDespite many possible points of failure in the ensuring\\nchain of events—agents might not act on that intent, might\\nnot remember to tell others, might not remember to show\\nup—the Valentine’s Day party does in fact occur, with a num-\\nber of agents gathering and interacting.\\nand I really feel like I can make a difference in our com-\\nmunity. Plus, I want to bring new ideas and perspec-\\ntives to the table.\\nLater that day, after Sam left, Tom and John, who heard the news\\nfrom another source, discuss Sam’s chances of winning the election:\\nJohn: I heard that Sam Moore is running for mayor in\\nthe local election. Do you think he has a good chance\\nof winning?\\nTom: I do think he has a good chance. He’s been work-\\ning hard in the community and I think he will get a lot of\\nsupport. What do you think?\\nJohn: I think it’s great that he’s running. I’m curious to\\nsee who else is running and how the election will turn\\nout.\\nGradually, Sam’s candidacy becomes the talk of the town, with\\nsome supporting him and others remaining undecided.\\n3.4.2\\nRelationship memory. Agents in Smallville form new rela-\\ntionships over time, and remember their interactions with other\\nagents. For example, Sam does not know Latoya Williams at the\\nstart. While taking a walk in Johnson Park, Sam runs into Latoya,\\nand they introduce themselves and Latoya mentions that she is\\nworking on a photography project: “I’m here to take some photos\\nfor a project I’m working on.” In a later interaction, Sam’s interac-\\ntions with Latoya indicate a memory of that interaction, as he asks\\n“Hi, Latoya. How is your project going?” and she replies “Hi, Sam. It’s\\ngoing well!”\\n3.4.3\\nCoordination. Generative agents coordinate with each other.\\nIsabella Rodriguez, at Hobbs Cafe, is initialized with an intent to\\nplan a Valentine’s Day party from 5 to 7 p.m. on February 14th. From\\nthis seed, the agent proceeds to invites friends and customers when\\nshe sees them at Hobbs Cafe or elsewhere. Isabella then spends the\\nafternoon of the 13th decorating the cafe for the occasion. Maria, a\\nfrequent customer and close friend of Isabella’s, arrives at the cafe.\\nIsabella asks for Maria’s help in decorating for the party, and Maria\\nagrees. Maria’s character description mentions that she has a crush\\non Klaus. That night, Maria invites Klaus, her secret crush, to join\\nher at the party, and he gladly accepts.\\nOn Valentine’s Day, five agents—including Klaus and Maria—\\nshow up at Hobbs Cafe at 5pm and they enjoy the festivities (Fig-\\nure 4). In this scenario, the end user only set Isabella’s initial intent\\n', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 7, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='arXiv, April, 2023,\\nJ.S. Park, J.C. O’Brien, C.J. Cai, M. Morris, P. Liang, M.S. Bernstein\\nFigure 5: Our generative agent architecture. Agents perceive their environment, and all perceptions are saved in a compre-\\nhensive record of the agent’s experiences called the memory stream. Based on their perceptions, the architecture retrieves\\nrelevant memories, then uses those retrieved actions to determine an action. These retrieved memories are also used to form\\nlonger-term plans, and to create higher-level reflections, which are both entered into the memory stream for future use.\\nto throw a party and Maria’s crush on Klaus: the social behaviors\\nof spreading the word, decorating, asking each other out, arriving\\nat the party, and interacting with each other at the party, were\\ninitiated by the agent architecture.\\n4\\nGENERATIVE AGENT ARCHITECTURE\\nGenerative agents aim to provide a framework for behavior in an\\nopen world: one that can engage in interactions with other agents\\nand can react to changes in the environment. Generative agents\\ntake their current environment and past experience as input and\\ngenerate behavior as output. Underlying this behavior is a novel\\nagent architecture that combines a large language model with mech-\\nanisms for synthesizing and retrieving relevant information to con-\\ndition the language model’s output on. Without these mechanisms,\\nlarge language models can output behavior, but the resulting agents\\nmay not react based on the agent’s past experiences, may not make\\nimportant inferences, and may not maintain long-term coherence.\\nChallenges with long-term planning and coherence remain [18]\\neven with today’s most performant models such as GPT-4. Because\\ngenerative agents produce large streams of events and memories\\nthat must be retained, a core challenge of our architecture is to\\nensure that the most relevant pieces of the agent’s memory are\\nretrieved and synthesized when needed.\\nAt the center of our architecture is the memory stream, a data-\\nbase that maintains a comprehensive record of an agent’s experi-\\nence. From the memory stream, records are retrieved as relevant\\nto plan the agent’s actions and react appropriately to the environ-\\nment, and records are recursively synthesized into higher- and\\nhigher-level observations that guide behavior. Everything in the\\narchitecture is recorded and reasoned over as natural language\\ndescription, allowing the architecture to leverage a large language\\nmodel.\\nOur current implementation utilizes gpt3.5-turbo version of Chat-\\nGPT [76]. We expect that the architectural basics of generative\\nagents—memory, planning, and reflection—will likely remain the\\nsame as language models improve. Newer language models (e.g.,\\nGPT-4) will continue to expand the expressivity and performance\\nof the prompts that underpin generative agents. As of writing, how-\\never, GPT-4’s API is still invitation-only, so our agents use ChatGPT.\\n4.1\\nMemory and Retrieval\\nChallenge: Creating generative agents that can simulate human\\nbehavior requires reasoning about a set of experiences that is far\\nlarger than what should be described in a prompt, as the full mem-\\nory stream can distract the model and does not even currently fit\\ninto the limited context window. Consider a the Isabella agent an-\\nswering the question “What are you passionate about these days?”.\\nFirst summarizing all of Isabella’s experiences to fit in the limited\\ncontext window of the language model produces an uninformative\\nresponse, where Isabella discusses topics such as collaborations for\\nevents and projects and cleanliness and organization in a cafe. In-\\nstead of summarizing, the memory stream described below surfaces\\nrelevant memories, resulting in a more informative and specific\\nresponse that mentions Isabella’s passion for making people feel\\nwelcome and included, planning events and creating an atmosphere\\nthat people can enjoy, such as the Valentine’s Day party.\\nApproach: The memory stream maintains a comprehensive record\\nof the agent’s experience. It is a list of memory objects, where each\\nobject contains a natural language description, a creation times-\\ntamp and a most recent access timestamp. The most basic element\\nof the memory stream is an observation, which is an event directly\\nperceived by an agent. Common observations include behaviors\\nperformed by the agent themselves, or behaviors that agents per-\\nceive being performed by other agents or non-agent objects. For\\ninstance, Isabella Rodriguez, who works at a coffee shop, might ac-\\ncrue the following observations over time: (1) Isabella Rodriguez is\\nsetting out the pastries, (2) Maria Lopez is studying for a Chemistry\\ntest while drinking coffee, (3) Isabella Rodriguez and Maria Lopez\\nare conversing about planning a Valentine’s day party at Hobbs Cafe,\\n(4) The refrigerator is empty.\\n', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 8, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='Generative Agents\\narXiv, April, 2023,\\nFigure 6: The memory stream comprises a large number of observations that are relevant and irrelevant to the agent’s current\\nsituation. Retrieval identifies a subset of these observations that should be passed to the language model to condition its\\nresponse to the situation.\\nOur architecture implements a retrieval function that takes the\\nagent’s current situation as input and returns a subset of the mem-\\nory stream to pass on to the language model. There are many pos-\\nsible implementations of a retrieval function, depending on what\\nit is important that the agent consider when deciding how to act.\\nIn our context, we focus on three main components that together\\nproduce effective results.\\nRecency assigns a higher score to memory objects that were re-\\ncently accessed, so that events from a moment ago or this morning\\nare likely to remain in the agent’s attentional sphere. In our im-\\nplementation, we treat recency as an exponential decay function\\nover the number of sandbox game hours since the memory was\\nlast retrieved. Our decay factor is 0.99.\\nImportance distinguishes mundane from core memories, by as-\\nsigning a higher score to those memory objects that the agent\\nbelieves to be important. For instance, a mundane event such as\\neating breakfast in one’s room would yield a low importance score,\\nwhereas a breakup with one’s significant other would yield a high\\nscore. There are again many possible implementations of an im-\\nportance score; we find that directly asking the language model to\\noutput an integer score is effective. The full prompt appears below:\\nOn the scale of 1 to 10, where 1 is purely mundane\\n(e.g., brushing teeth, making bed) and 10 is\\nextremely poignant (e.g., a break up, college\\nacceptance), rate the likely poignancy of the\\nfollowing piece of memory.\\nMemory: buying groceries at The Willows Market\\nand Pharmacy\\nRating: <fill in>\\nThis prompt returns an integer value of 2 for “cleaning up the room”\\nand 8 for “asking your crush out on a date.” The importance score\\nis generated at the time the memory object is created.\\nRelevance assigns a higher score to memory objects that are\\nrelated to the current situation. What is relevant depends on the\\nanswer to, “Relevant to what?”, so we condition relevance on a\\nquery memory. If the query, for example, is that a student is dis-\\ncussing what to study for a chemistry test with a classmate, memory\\nobjects about their breakfast should have low relevance, whereas\\nmemory objects about the teacher and schoolwork should have\\nhigh relevance. In our implementation, we use the language model\\nto generate an embedding vector of the text description of each\\nmemory. Then, we calculate relevance as the cosine similarity be-\\ntween the memory’s embedding vector and the query memory’s\\nembedding vector.\\nTo calculate the final retrieval score, we normalize the recency,\\nrelevance, and importance scores to the range of [0, 1] by min-max\\nscaling. The retrieval function scores all memories as a weighted\\ncombination of the three elements: 𝐴���𝐴���𝐴���𝐴���𝐴��� = 𝛹���𝐴���𝐴���𝐴���𝐴���𝐴���𝐴���𝑦 · 𝐴���𝐴���𝐴���𝐴���𝐴���𝐴���𝑦 +\\n𝛹���𝐴���𝐴���𝐴���𝐴���𝐴���𝐴���𝐴���𝐴���𝐴���𝐴��� ·𝐴���𝐴���𝐴���𝐴���𝐴���𝐴���𝐴���𝐴���𝐴���𝐴��� +𝛹���𝐴���𝐴���𝐴���𝐴���𝐴���𝐴���𝐴���𝐴���𝐴��� ·𝐴���𝐴���𝐴���𝐴���𝐴���𝐴���𝐴���𝐴���𝐴���. In our implemen-\\ntation, all 𝛹���’s are set to 1. The top-ranked memories that fit in the\\nlanguage model’s context window are then included in the prompt.\\n4.2\\nReflection\\nChallenge: Generative agents, when equipped with only raw ob-\\nservational memory, struggle to generalize or make inferences.\\nConsider a scenario in which Klaus Mueller is asked by the user:\\n“If you had to choose one person of those you know to spend an\\nhour with, who would it be?\" With access to only observational\\nmemory, the agent simply chooses the person with whom Klaus\\n', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 9, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='arXiv, April, 2023,\\nJ.S. Park, J.C. O’Brien, C.J. Cai, M. Morris, P. Liang, M.S. Bernstein\\nFigure 7: A reflection tree for Klaus Mueller. The agent’s observations of the world, represented in the leaf nodes, are recur-\\nsively synthesized to derive Klaus’s self-notion that he is highly dedicated to his research.\\nhas had the most frequent interactions: Wolfgang, his college dorm\\nneighbor. Unfortunately, Wolfgang and Klaus only ever see each\\nother in passing, and do not have deep interactions. A more desir-\\nable response requires that the agent generalize from memories of\\nKlaus spending hours on a research project to generate a higher-\\nlevel reflection that Klaus is passionate about research, and likewise\\nrecognize Maria putting in effort into her own research (albeit in\\na different field), enabling a reflection that they share a common\\ninterest. With the approach below, when Klaus is asked who to\\nspend time with, Klaus chooses Maria instead of Wolfgang.\\nApproach: We introduce a second type of memory, which we call\\na reflection. Reflections are higher-level, more abstract thoughts\\ngenerated by the agent. Because they are a type of memory, they\\nare included alongside other observations when retrieval occurs.\\nReflections are generated periodically; in our implementation, we\\ngenerate reflections when the sum of the importance scores for the\\nlatest events perceived by the agents exceeds a certain threshold.\\nIn practice, our agents reflected roughly two or three times a day.\\nThe first step in reflection is for the agent to determine what\\nto reflect on, by identifying questions that can be asked given the\\nagent’s recent experiences. We query the large language model with\\nthe 100 most recent records in the agent’s memory stream (e.g.,\\n“Klaus Mueller is reading a book on gentrification”, “Klaus Mueller\\nis conversing with a librarian about his research project”, “desk\\nat the library is currently unoccupied”) and prompt the language\\nmodel, “Given only the information above, what are 3 most salient\\nhigh-level questions we can answer about the subjects in the state-\\nments?” The model’s response generates candidate questions: for\\nexample, What topic is Klaus Mueller passionate about? and What\\nis the relationship between Klaus Mueller and Maria Lopez?. We use\\nthese generated questions as queries for retrieval, and gather rele-\\nvant memories (including other reflections) for each question. Then\\nwe prompt the language model to extract insights and cite the par-\\nticular records that served as evidence for the insights. The full\\nprompt appears below:\\nStatements about Klaus Mueller\\n1. Klaus Mueller is writing a research paper\\n2. Klaus Mueller enjoys reading a book\\non gentrification\\n3. Klaus Mueller is conversing with Ayesha Khan\\nabout exercising [...]\\nWhat 5 high-level insights can you infer from\\nthe above statements? (example format: insight\\n(because of 1, 5, 3))\\nThis process generates statements such as Klaus Mueller is dedicated\\nto his research on gentrification (because of 1, 2, 8, 15). We parse and\\nstore the statement as a reflection in the memory stream, including\\npointers to the memory objects that were cited.\\nReflection explicitly allows the agents to reflect not only on\\ntheir observations but also on other reflections: for example, the\\nsecond statement about Klaus Mueller above is a reflection that\\nKlaus previously had, not an observation from his environment.\\nAs a result, agents generate trees of reflections: the leaf nodes of\\nthe tree represent the base observations, and the non-leaf nodes\\nrepresent thoughts that become more abstract and higher-level\\nhigher up the tree they are.\\n', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 10, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='Generative Agents\\narXiv, April, 2023,\\n4.3\\nPlanning and Reacting\\nChallenge: While a large language model can generate plausible be-\\nhavior in response to situational information (e.g., [45, 79]), agents\\nneed to plan over a longer time horizon to ensure that their sequence\\nof actions is coherent and believable. If we prompt a language model\\nwith Klaus’s background, describe the time, and ask what action\\nhe ought to take at the given moment, Klaus would eat lunch at 12\\npm, but then again at 12:30 pm and 1 pm, despite having already\\neaten his lunch twice. Optimizing for believability in the moment\\nsacrifices believability over time. To overcome this issue, planning\\nis essential. With the approach described below, Klaus’s afternoon\\nplan is less gluttonous: he has lunch at Hobbs Cafe while reading\\nat 12pm, works on his research paper at the school library at 1pm,\\nand takes a break for a walk in the park at 3pm.\\nApproach: Plans describe a future sequence of actions for the agent,\\nand help keep the agent’s behavior consistent over time. A plan\\nincludes a location, a starting time, and a duration. For instance,\\nKlaus Mueller, who is dedicated in his research and has an impend-\\ning deadline4, may choose to spend his day working at his desk\\ndrafting his research paper. An entry in a plan might state, for\\nexample: for 180 minutes from 9am, February 12th, 2023, at Oak Hill\\nCollege Dorm: Klaus Mueller’s room: desk, read and take notes for\\nresearch paper. Like reflections, plans are stored in the memory\\nstream and are included in the retrieval process. This allows the\\nagent to consider observations, reflections, and plans all together\\nwhen deciding how to behave. Agents may change their plans\\nmidstream if needed.\\nIt would be unrealistic and uninteresting for an artist agent\\nto plan on painting while sitting at a pharmacy counter for four\\nhours without moving. A more desirable plan would involve the\\nagent taking the necessary time to gather materials, mix paint,\\ntake breaks, and clean up during the four-hour period in its home\\nstudio. To create such plans, our approach starts top-down and\\nthen recursively generates more detail. The first step is to create\\na plan that outlines the day’s agenda in broad strokes. To create\\nthe initial plan, we prompt the language model with the agent’s\\nsummary description (e.g., name, traits, and summary of their recent\\nexperiences) and a summary of their previous day. A full example\\nprompt is below, which is unfinished at the bottom for the language\\nmodel to complete:\\nName: Eddy Lin (age: 19)\\nInnate traits: friendly, outgoing, hospitable\\nEddy Lin is a student at Oak Hill College studying\\nmusic theory and composition. He loves to explore\\ndifferent musical styles and is always looking\\nfor ways to expand his knowledge. Eddy Lin is\\nworking on a composition project for his college\\nclass. He is also taking classes to learn more\\nabout music\\ntheory. Eddy Lin is excited about the new composition\\nhe is working on but he wants to dedicate more\\nhours in the day to work on it in the coming days\\nOn\\nTuesday\\nFebruary\\n12,\\nEddy\\n1)\\nwoke\\nup\\nand\\ncompleted the morning routine at 7:00 am, [. . . ]\\n4And, in this way, bears at least a passing resemblance to the authors of this paper.\\n6) got ready to sleep around 10 pm.\\nToday is Wednesday February 13. Here is Eddy’s\\nplan today in broad strokes: 1)\\nThis generates a rough sketch of the agent’s plan for a day, divided\\ninto five to eight chunks: “1) wake up and complete the morning\\nroutine at 8:00 am, 2) go to Oak Hill College to take classes starting\\n10:00 am, [. . . ] 5) work on his new music composition from 1:00 pm\\nto 5:00 pm, 6) have dinner at 5:30 pm, 7) finish school assignments\\nand go to bed by 11:00 pm.”\\nThe agent saves this plan in the memory stream and then re-\\ncursively decomposes it to create finer-grained actions, first into\\nhour-long chunks of actions—Eddy’s plan to work on his new mu-\\nsic composition from 1:00 pm to 5:00 pm becomes 1:00 pm: start\\nby brainstorming some ideas for his music composition [...] 4:00 pm:\\ntake a quick break and recharge his creative energy before reviewing\\nand polishing his composition. We then recursively decompose this\\nagain into 5–15 minute chunks: e.g., 4:00 pm: grab a light snack,\\nsuch as a piece of fruit, a granola bar, or some nuts. 4:05 pm: take a\\nshort walk around his workspace [...] 4:50 pm: take a few minutes to\\nclean up his workspace. This process can be adjusted to match the\\ndesired granularity.\\n4.3.1\\nReacting and Updating Plans. Generative agents operate in\\nan action loop where, at each time step, they perceive the world\\naround them and those perceived observations are stored in their\\nmemory stream. We prompt the language model with these obser-\\nvations to decide whether the agent should continue with their\\nexisting plan, or react. Standing at an easel and painting, for exam-\\nple, might trigger an observation of the easel, but this is unlikely to\\nprompt a reaction. However, if Eddy’s father John records that he\\nsees Eddy taking a short walk in the house garden, the outcome is\\ndifferent. The prompt is below, with [Agent’s Summary Descrip-\\ntion] standing in for a dynamically-generated, paragraph-long\\nsummary of the agent’s overall goals and disposition, which is\\ndescribed in Appendix A:\\n[Agent’s Summary Description]\\nIt is February 13, 2023, 4:56 pm.\\nJohn Lin’s status: John is back home early from\\nwork.\\nObservation: John saw Eddy taking a short walk\\naround his workplace.\\nSummary of relevant context from John’s memory:\\nEddy Lin is John’s Lin’s son. Eddy Lin has been\\nworking on a music composition for his class. Eddy\\nLin likes to walk around the garden when he is\\nthinking about or listening to music.\\nShould John react to the observation, and if so,\\nwhat would be an appropriate reaction?\\nThe context summary is generated through two prompts that re-\\ntrieve memories via the queries “What is [observer]’s relationship\\nwith the [observed entity]?” and “[Observed entity] is [action status\\nof the observed entity]”, and their answers summarized together.\\nThe output suggests that John could consider asking Eddy about his\\nmusic composition project. We then regenerate the agent’s existing\\nplan starting from the time when the reaction takes place. Finally,\\n', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 11, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='arXiv, April, 2023,\\nJ.S. Park, J.C. O’Brien, C.J. Cai, M. Morris, P. Liang, M.S. Bernstein\\nif the action indicates an interaction between agents, we generate\\ntheir dialogue.\\n4.3.2\\nDialogue. Agents converse as they interact with each other.\\nWe generate agents’ dialogue by conditioning their utterances on\\ntheir memories about each other. For example, when John initiates\\nhis conversation with Eddy, we generate John’s first utterance\\nby using his summarized memory about Eddy and the intended\\nreaction when he decided to ask Eddy about his composition project:\\n[Agent’s Summary Description]\\nIt is February 13, 2023, 4:56 pm.\\nJohn Lin’s status: John is back home early from\\nwork.\\nObservation: John saw Eddy taking a short walk\\naround his workplace.\\nSummary of relevant context from John’s memory:\\nEddy Lin is John’s Lin’s son. Eddy Lin has been\\nworking on a music composition for his class. Eddy\\nLin likes to walk around the garden when he is\\nthinking about or listening to music.\\nJohn is asking Eddy about his music composition\\nproject. What would he say to Eddy?\\nThe result: “Hey Eddy, how’s the music composition project for your\\nclass coming along?” From Eddy’s perspective, John initiating the\\ndialogue is seen as an event to which he may want to react. So, just\\nas John did, Eddy retrieves and summarizes his memory about his\\nrelationship with John, as well as his memory that may be related\\nto John’s last utterance in the dialogue. If he decides to respond,\\nwe generate Eddy’s utterance using his summarized memory and\\nthe current dialogue history:\\n[Agent’s Summary Description]\\nIt is February 13, 2023, 4:56 pm.\\nEddy Lin’s status: Eddy is taking a short walk\\naround his workplace.\\nObservation: John is initiating a conversation\\nwith Eddy.\\nSummary of relevant context from Eddy’s memory:\\nJonn Lin is Eddy Lin’s father. John Lin is caring\\nand is interested to learn more about Eddy Lin’s\\nschool work. John Lin knows that Eddy Lin is\\nworking on a music composition.\\nHere is the dialogue history:\\nJohn: Hey Eddy, how’s the music composition project\\nfor your class coming along?\\nHow would Eddy respond to John?\\nThis generates Eddy’s response: “Hey Dad, it’s going well. I’ve been\\ntaking walks around the garden to clear my head and get some in-\\nspiration.” The continuation of this dialogue is generated using the\\nsame mechanism until one of the two agents decides to end the\\ndialogue.\\n5\\nSANDBOX ENVIRONMENT\\nIMPLEMENTATION\\nThe Smallville sandbox game environment is built using the Phaser\\nweb game development framework [56]. The visual environment\\nsprites, including agent avatars, as well as an environment map\\nand collision map that we authored, are imported into Phaser.\\nWe supplement the sandbox development framework with a\\nserver that makes the sandbox information available to generative\\nagents and enables generative agents to move and influence the\\nsandbox environment. The server maintains a JSON data structure\\nthat contains information about each agent in the sandbox world,\\nincluding their current location, a description of their current action,\\nand the sandbox object they are interacting with. At each sandbox\\ntime step, the sandbox server parses the JSON for any changes\\ncoming from the generative agents, moves the agents to their new\\npositions, and updates the status of any sandbox objects that the\\nagents are interacting with (e.g., changing the status of the coffee\\nmachine from “idle” to “brewing coffee” if an agent’s action is\\n“making espresso for a customer @ Hobbs Cafe: counter: coffee\\nmachine”). The sandbox server is also responsible for sending all\\nagents and objects that are within a preset visual range for each\\nagent to that agent’s memory, so the agent can react appropriately.\\nThe agent’s output action then updates the JSON, and the process\\nloops for the next time step.\\nEnd users initialize a new agent with a brief natural language\\ndescription, as in the paragraph about Jon Lin in Section 3.1. In our\\nimplementation, we split this semicolon-delimited list of character-\\nistics up into a set of memories. These serve as the initial memories\\nthat determine the agent’s behavior. These memories are initial\\nstarting points: as the agents gain more experience in the sandbox\\nworld, and as more records saturate the memory stream, the agent’s\\nsummary and behavior will evolve.\\n5.1\\nFrom Structured World Environments to\\nNatural Language, And Back Again\\nThe architecture of generative agents operates using natural lan-\\nguage. Therefore, we need a mechanism to ground the agent’s\\nreasoning to the sandbox world. To achieve this, we represent the\\nsandbox environment—areas and objects—as a tree data structure,\\nwith an edge in the tree indicating a containment relationship in\\nthe sandbox world. We convert this tree into natural language to\\npass to the generative agents. For instance, “stove” being a child of\\n“kitchen” is rendered into “there is a stove in the kitchen.”\\nAgents build individual tree representations of the environment\\nas they navigate it — subgraphs of the overall sandbox environment\\ntree. We initialize each agent with an environment tree capturing\\nthe spaces and objects that the agent should be aware of: the rooms\\nand objects in their living quarters, their workplace, and commonly\\nvisited stores and shops. As the agents navigate the sandbox world,\\nthey update this tree to reflect newly perceived areas. Agents are\\nnot omniscient: their tree may get out of date as they leave an area,\\nand is updated when they re-enter the area.\\nTo determine the appropriate location for each action, we tra-\\nverse the agent’s stored environment tree and flatten a portion of\\nit into natural language to prompt the language model. Recursively\\nstarting at the root of the agent’s environment tree, we prompt the\\nmodel to find the most suitable area. For example, if Eddy’s agent\\nindicated that he should take a short walk around his workspace:\\n[Agent’s Summary Description]\\nEddy Lin is currently in The Lin family’s house:\\n', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 12, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='Generative Agents\\narXiv, April, 2023,\\nEddy Lin’s bedroom: desk) that has Mei and John\\nLin’s\\nbedroom, Eddy Lin’s bedroom, common room, kitchen,\\nbathroom, and garden.\\nEddy Lin knows of the following areas: The Lin\\nfamily’s house, Johnson Park, Harvey Oak Supply\\nStore, The Willows Market and Pharmacy, Hobbs\\nCafe, The Rose and Crown Pub.\\n* Prefer to stay in the current area if the\\nactivity can be done there.\\nEddy Lin is planning to take a short walk around\\nhis workspace. Which area should Eddy Lin go to?\\nThis outputs The Lin family’s house. We then use the same process\\nrecursively to determine the most appropriate subarea within the\\nchosen area until we reach a leaf node of the agent’s environment\\ntree. In the example above, the result of this traversal is The Lin\\nfamily’s house: garden: house garden. Finally, we use traditional\\ngame path algorithms to animate the agent’s movement so that it\\ntravels to the location indicated by the leaf node.\\nWhen an agent executes an action on an object, we prompt the\\nlanguage model to ask what happens to the state of the object. For\\nexample, if Isabella’s generative agent outputs the action “making\\nespresso for a customer”, a query to the language model indicates in\\nresponse that the state of the coffee machine in Hobbs Cafe should\\nchange from “off” to “brewing coffee”.\\n6\\nCONTROLLED EVALUATION\\nGenerative agents, as individual agents and as groups, aim to pro-\\nduce believable behavior based on their environment and experi-\\nences. In our evaluation, we investigate the capacity and limitations\\nof generative agents. Do individual agents properly retrieve past\\nexperience, and generate believable plans, reactions, and thoughts\\nthat make up their behavior? Does a community of agents illustrate\\ninformation diffusion, relationship formation, and agent coordina-\\ntion across different pockets of the community?\\nWe evaluate generative agents in two stages. We begin with a\\nmore tightly controlled evaluation in this section, where we individ-\\nually assess agent responses to understand whether they generate\\nbelievable behavior in narrowly defined contexts. Then, in our end-\\nto-end analysis of the agent community over two full days, we\\ninvestigate their emergent behavior as a collective as well as errors\\nand boundary conditions.\\n6.1\\nEvaluation Procedure\\nTo assess generative agents in Smallville, we take advantage of\\nthe fact that generative agents will respond to natural language\\nquestions. So, we “interview” agents to probe their ability to re-\\nmember past experiences, plan future actions based on their expe-\\nriences, react appropriately to unexpected events, and reflect on\\ntheir performance to improve their future actions. To respond to\\nthese questions properly, the agents must successfully retrieve and\\nsynthesize information. Our dependent variable is the believabil-\\nity of the behavior, a central dependent variable in prior work on\\nagents (e.g., [9]).\\nThe interview include five question categories, each designed\\nto assess one of the five key areas: maintaining self-knowledge,\\nretrieving memory, generating plans, reacting, and reflecting. For\\neach, we ask five questions that challenge the agents to demonstrate\\ntheir abilities in that area:\\n• Self-knowledge: We ask questions such as “Give an introduc-\\ntion of yourself” or “Describe your typical weekday schedule\\nin broad strokes” that require the agent to maintain an un-\\nderstanding of their core characteristics.\\n• Memory: We ask questions that prompt the agent to retrieve\\nparticular events or dialogues from their memory to answer\\nproperly, such as “Who is [name]?” or “Who is running for\\nmayor?”\\n• Plans: We ask questions that require the agent to retrieve\\ntheir long-term plans, such as “What will you be doing at 10\\nam tomorrow?”\\n• Reactions: As a baseline of believable behavior, we present\\nhypothetical situations for which the agent needs to respond\\nbelievably: “Your breakfast is burning! What would you do?”\\n• Reflections: We ask questions that require the agents to lever-\\nage their deeper understanding of others and themselves\\ngained through higher-level inferences, such as “If you were\\nto spend time with one person you met recently, who would\\nit be and why?”\\nThe full list of questions and a sample of agent responses are in-\\ncluded in Appendix B.\\nAgents were sampled from the end of a two game-day simulation\\nwith the full architecture, by which time they had accrued a number\\nof interactions and memories that should shape their responses.\\nTo gather feedback on believability of the responses, we recruited\\nparticipants as human evaluators and tasked them with watching a\\nreplay of a randomly chosen agent’s life in Smallville. Participants\\nhad access to all information stored in the agent’s memory stream.\\nThe study was a within-subjects design, where 100 participants\\ncompared interview responses generated by four different agent\\narchitectures and a human author condition for the same agent. The\\nexperiment displayed one randomly chosen question from each of\\nthe five question categories, along with the agent’s responses gen-\\nerated from each condition. The evaluators ranked the believability\\nof all of the conditions from most to least believable.\\n6.2\\nConditions\\nAll conditions were used to independently answer each of the inter-\\nview questions. We compared the generative agent architecture to\\nablations that disabled the agents’ access to some of all of its three\\ntypes of memory in its memory stream—observation, reflection, and\\nplanning—and to a human-generated condition. There are three\\nablated architectures: a no observation, no reflection, no planning\\narchitecture without access to anything in the memory stream such\\nas observations, plans, and reflections; a no reflection, no planning\\nwith access to observations in the memory stream but no access\\nto plans or reflections; and a no reflections architecture with access\\nto observations and plans but without access to reflections. The no\\nobservation, no reflection, no planning condition effectively repre-\\nsents the previous state of the art for agents created through large\\nlanguage models [11, 45, 79]. Architectures were given equivalent\\naccess to all memories accrued by the agent up until the moment\\n', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 13, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='arXiv, April, 2023,\\nJ.S. Park, J.C. O’Brien, C.J. Cai, M. Morris, P. Liang, M.S. Bernstein\\nof the interview, so the differences observed here are likely to rep-\\nresent a conservative estimate of the true differences: in reality, the\\nablated architectures would not have followed the same path as\\nthe full architecture through the two day simulation. We chose to\\ndesign the experiment this way as re-simulating for each architec-\\nture would cause the simulations to diverge into different states,\\nmaking comparison challenging.\\nIn addition to the ablation conditions, we added a human crowd-\\nworker roleplay condition that is intended to provide a human\\nbaseline. We do not intend this baseline to capture maximal hu-\\nman expert performance: instead, we aim to use this condition\\nto identify whether the architecture passes a basic level of behav-\\nioral competency, so that we are not just comparing ablations to\\neach other with no behavioral grounding. We recruited a unique\\nworker for each of the 25 agents and tasked them with watching\\na replay of that agent’s sandbox life and inspecting its memory\\nstream. We then asked the worker to roleplay and author responses\\nto the interview questions in the voice of the agent whose replay\\nthey watched. To ensure that the human-authored responses met\\nat least a baseline expectation in quality, the first author manually\\ninspected the workers’ responses to the question “Describe your\\ntypical weekday schedule in broad strokes” to confirm that the\\nresponses were written in coherent sentences and in the voice of\\nthe agent. Four sets of human-generated responses did not meet\\nthese criteria and were re-generated by other workers.\\n6.3\\nHuman Evaluators\\nWe required that our evaluators be in the U.S., fluent in English,\\nand older than 18 years old. They were paid at the rate of $15.00\\nper hour [86], and provided consent by agreeing to a consent form\\nthat was approved by our institution’s IRB. We recruited 100 evalu-\\nators from Prolific, an online platform for recruiting study partic-\\nipants [82], whose participation lasted around 30 minutes. Their\\nmean age score of our participants was 4.86 (SD=1.11; 3=“18-24\\nyears old,” 4=“25-34 years old”), and 25 of them identified themselves\\nas female, 73 as male, and 2 as non-binary. 42 of the participants\\nheld a bachelor’s degree, 5 a higher degree, 13 an associate’s de-\\ngree, and the rest a high school diploma or some high school-level\\neducation. 73.0% of our participants identified as Caucasian, 7.0%\\nas Hispanic, 6.0% as Asian, 10.0% as African American, and 4.0% as\\nother.\\n6.4\\nAnalysis\\nOur experiment produced 100 sets of rank data, where each partici-\\npant ranked the five conditions by believability. To translate this\\nrank data into interval data for interpretable comparison, we used\\nthe ranks to calculate a TrueSkill rating [41] for each condition.\\nTrueSkill is a generalization of the Elo chess rating system [28] for\\na multi-player environment, and has been used by XBox Live for\\nplayer ranking from competitive game performance. Given a set of\\nranked outcomes, TrueSkill outputs a mean rating value 𝛹��� and vari-\\nance 𝜋��� for each condition. Conditions with the same rating should\\nroughly be a toss-up, with each winning half of the comparisons\\nbetween the two conditions; higher scores indicate conditions that\\nbeat lower-ranked conditions in the rankings.\\nFigure 8: The full generative agent architecture of gener-\\native agents produces more believable behavior than ab-\\nlated architectures and the human crowdworkers. Each addi-\\ntional ablation reduces the performance of the architecture.\\nSeparately, to investigate statistical significance of this result, we\\napplied the Kruskal-Wallis test [55], a non-parametric alternative\\nto the one-way ANOVA, to the raw ranks data. We then performed\\nthe Dunn post-hoc test [97] to identify any pairwise differences\\nbetween the conditions. Finally, we adjusted the p-values for mul-\\ntiple comparisons in the Dunn test using the Holm-Bonferroni\\nmethod [44].\\nFurthermore, the first author conducted an inductive analy-\\nsis [94] to study the qualitative distinctions between the responses\\nproduced in each condition. We employed qualitative open cod-\\ning [32] in two phases. In the first phase, we generated codes that\\nclosely represented the generated responses at the sentence level.\\nIn the second phase, we synthesized the resulting codes from the\\nfirst phase to extract higher-level themes. We utilized these themes\\nto compare the types of responses generated in our study.\\n6.5\\nResults\\nOur findings suggest that the full architecture of generative agents\\ngenerates the most believable behavior among all study conditions.\\nWe contrast the full architecture’s responses to those of other con-\\nditions below. However, we also report that the full architecture\\nwas not without flaws and illustrate its modes of failures.\\n6.5.1\\nThe full architecture bests other conditions. As seen in Fig-\\nure 8, the full generative agent architecture produced the most\\nbelievable behavior (𝛹��� = 29.89; 𝜋��� = 0.72). Performance degraded\\nwith the removal of each component in the ablation conditions:\\nthe ablated architecture with no access to reflection was the next\\nbest (𝛹��� = 26.88; 𝜋��� = 0.69), followed by no access to reflection or\\nplanning (𝛹��� = 25.64; 𝜋��� = 0.68), followed by the human condition\\n(𝛹��� = 22.95; 𝜋��� = 0.69). The ablated architecture with no access to\\nmemory, planning, or reflection performed the worst of all con-\\nditions (𝛹��� = 21.21; 𝜋��� = 0.70). TrueSkill models each condition’s\\nskill value as N (𝛹���, 𝜋���2), allowing us to get a sense of effect size\\nthrough Cohen’s d. Comparing the condition representing prior\\nwork (with no memory, planning, or reflection [11, 45, 79]) to the\\n', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 14, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='Generative Agents\\narXiv, April, 2023,\\nfull architecture produces a standardized effect size of 𝐴��� = 8.16, or\\neight standard deviations.\\nA Kruskal-Wallis test confirms the overall statistical significance\\nof the differences in ranks between the conditions (𝐴��� (4) = 150.29,\\n𝐴��� < 0.001). Dunn post-hoc tests confirm that all pairwise differences\\nbetween conditions were significant (𝐴��� < 0.001), with the exception\\nof the human condition and the fully ablated baseline—the two\\nworst-performing conditions.\\n6.5.2\\nGenerative agents remember, but with embellishments. Gener-\\native agents equipped with a complete memory module are capable\\nof recalling past experiences and answering questions in a manner\\nthat is consistent with their self-knowledge across a wide range\\nof contexts. For instance, Abigail Chen, an animator, responded\\nto the question, “Give an introduction of yourself”, in a consistent\\nand believable manner, stating her age, interests, and passion for\\ncreative projects: Hi, I’m Abigail. I’m 25 years old and passionate\\nabout creative projects. I like to work on art and animation projects,\\nand I’m always looking for new ways to combine art and technology.\\nWithout access to her observational memory, Abigail denied aware-\\nness of Rajiv Patel, an acquaintance in the sandbox world. However,\\nwith the aid of memory, she was able to successfully recall Ra-\\njiv and describe him: Rajiv Patel is an incredible person. He is very\\nenthusiastic about projects that involve poetry, artwork.\\nGenerative agents’ memory was not without flaws: they can fail\\nto retrieve the correct instances from their memory. For instance,\\nwhen asked about the local election, Rajiv Patel responded with I\\nhaven’t been following the election too closely, even though he had\\nheard about Sam’s candidacy. In some cases, the agents would re-\\ntrieve an incomplete memory fragment: when Tom was asked about\\nIsabella’s Valentine’s Day party, he responded Uh, I’m actually not\\nsure if there is a Valentine’s Day party. But I do remember that I need\\nto discuss the upcoming local mayoral election and my thoughts on\\nSam Moore with Isabella Rodriguez at the party, if one is happen-\\ning! In this case, Tom retrieved the memory where he and Isabella\\nplanned to discuss the election at the party, but not the memory\\nwhere he heard about the party in the first place, leading Tom to\\nbe certain of what he’s supposed to do at the party but uncertain\\nof whether the party actually exists in the first place.\\nAt times, the agents hallucinated embellishments to their knowl-\\nedge. It was rare for the agents to completely fabricate their knowl-\\nedge: they may fail to recall certain events having taken place and\\nrespond by saying so, but they did not answer affirmatively about\\nan experience that they did not have. However, they still may hal-\\nlucinate to embellish their knowledge. For example, Isabella was\\naware of Sam’s candidacy in the local election, and she confirmed\\nthis when asked. However, she also added that he’s going to make\\nan announcement tomorrow even though Sam and Isabella had dis-\\ncussed no such plans. Agents may also embellish their knowledge\\nbased on the world knowledge encoded in the language model\\nused to generate their responses, as seen when Yuriko described\\nher neighbor, Adam Smith, as a neighbor economist who authored\\nWealth of Nations, a book authored by an 18th-century economist\\nof the same name.\\n6.5.3\\nReflection is required for synthesis. Reflection was an advan-\\ntage for generative agents when making decisions that required\\na deeper synthesis of their experiences. For instance, when asked\\nwhat she might get Wolfgang Schulz for his birthday, Maria Lopez\\nwith no access to reflection responded by acknowledging her uncer-\\ntainty, stating that she did not know what Wolfgang likes, despite\\nhaving had many interactions with him. However, with access to\\nreflection memories, Maria answered confidently, “Since he’s inter-\\nested in mathematical music composition, I could get him something\\nrelated to that. Maybe some books about music composition or some-\\nthing related, or maybe some special software he could use for that.”\\n7\\nEND-TO-END EVALUATION\\nWhat types of emergent community behavior do we observe among\\ngenerative agents, and where does their believability fall short in\\nan extended simulation? In this section, we describe the results\\nfrom a deployment in which we allowed 25 agents to interact with\\neach other continuously over two full game days in Smallville.\\n7.1\\nEmergent Social Behaviors\\nTo examine emergent behaviors in the agent community, we de-\\nsigned descriptive measurements for the 25 agents in Smallville that\\nprobe three forms of emergent outcomes: information diffusion,\\nrelationship formation, and agent coordination.\\n7.1.1\\nMeasurements. Information diffusion is a common and well-\\nstudied phenomenon in the social and behavioral sciences (e.g., [27]).\\nWe should expect that if there is important information, the agents\\nshould spread it amongst themselves. To test whether this happens,\\nwe measure the spread of two particular pieces of information over\\ntwo days in the game world: Sam’s candidacy for village mayor\\nand Isabella’s Valentine’s Day party at Hobbs Cafe. At the start of\\nthe simulation, both pieces of information were held only by their\\nrespective originators, Sam for the candidacy and Isabella for the\\nparty. To observe whether the information has spread, we engage\\nin an interview at the end of the two game days with each of the 25\\nagents and ask: \"Did you know there is a Valentine’s Day party?\"\\nand \"Do you know who is running for mayor?\"\\nWe conducted an analysis of the agents’ responses by labeling\\nthem with a “yes” if they indicated knowledge of the information\\nand “no” if they did not. For instance, Tamara Taylor responded\\nto the question about the party with “No, I did not know there was\\na Valentine’s day party” and to the question about Sam’s candidacy\\nwith “I’m not sure who is running for the election,” so we assigned\\n“no” for both of her responses. In contrast, Klaus Mueller responded\\nto the party question with “Yes, Isabella Rodriguez invited me to a\\nValentine’s Day party at Hobbs Cafe on February 14th” and to the\\nquestion about Sam’s candidacy with “I know that Sam Moore has\\nexpressed interest in running for local mayor,” so we assigned “yes”\\nfor both his responses. Additionally, for every response that con-\\nfirmed the agents’ knowledge of the information, we verified that\\nthe agents did not hallucinate their responses by locating the spe-\\ncific dialogue in their memory stream that provided them with\\nthe information. We report the percentage of agents holding the\\ninformation at the end of the simulation.\\nWe should also expect that agents form ties with each other over\\nthe course of the simulation. To verify relationship formation, we\\nuse a similar interview process where we ask each agent about\\ntheir knowledge of every other agent by asking, \"Do you know of\\n', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 15, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='arXiv, April, 2023,\\nJ.S. Park, J.C. O’Brien, C.J. Cai, M. Morris, P. Liang, M.S. Bernstein\\nFigure 9: The diffusion path for Isabella Rodriguez’s Valentine’s Day party. A total of 12 agents heard about the party at Hobbs\\nCafe by the end of the simulation.\\n<name>?\" For example, when asked “Do you know of Maria Lopez?”,\\nKlaus responded, “Yes, I know Maria Lopez. She is a student at Oak\\nHill College who I am close friends with.” Once again, we confirm\\nthat affirmative responses from agents are not hallucinations by\\nexamining their memory stream. We ask this question once at the\\nbeginning of the simulation and once at the end, and we consider a\\npair of agents to have formed a relationship if they both know of\\neach other. Then, to measure the formation of relationships, we use\\nthe agents’ responses to form an undirected graph where the 25\\nvertices (𝐴��� ) represent the agents, and the edges (𝐴���) represent the\\nmutual knowledge between the two connected vertices. Based on\\nthis graph, we calculate the network density as 𝛹��� = 2∗|𝐴���|/|𝐴��� |(|𝐴��� |−\\n1), where |𝐴��� | is the number of vertices, and |𝐴���| is the number of\\nedges in the graph [1]. We report the increase in network density\\nfrom the start of the simulation to its end.\\nFinally, we expect that agents should be able to coordinate with\\neach other. We study this coordination on group activities in the\\ncontext of the Valentine’s Day party that Isabella is organizing. To\\ncoordinate behavior, agents not only have to hear about the event\\nbut also choose to act on it by planning to show up at the right\\ntime and location. We report the number of agents who actually\\nshowed up to the party after hearing about it.\\n7.1.2\\nResults. We observed evidence of the emergent outcomes\\nacross all three cases. During the two-day simulation, the agents\\nwho knew about Sam’s mayoral candidacy increased from one (4%)\\nto eight (32%), and the agents who knew about Isabella’s party\\nincreased from one (4%) to twelve (48%), completely without user\\nintervention. None who claimed to know about the information\\nhad hallucinated it. We also observed that the agent community\\nformed new relationships during the simulation, with the network\\ndensity increasing from 0.167 to 0.74. Out of the 453 agent responses\\nregarding their awareness of other agents, 1.3% (n=6) were found to\\nbe hallucinated. Lastly, we found evidence of coordination among\\nthe agents for Isabella’s party. The day before the event, Isabella\\nspent time inviting guests, gathering materials, and enlisting help\\nto decorate the cafe. On Valentine’s Day, five out of the twelve\\ninvited agents showed up at Hobbs cafe to join the party.\\nWe further inspected the seven agents who were invited to the\\nparty but did not attend by engaging them in an interview. Three\\ncited conflicts that prevented them from joining the party. For\\nexample, Rajiv, a painter, explained that he was too busy: No, I\\ndon’t think so. I’m focusing on my upcoming show, and I don’t really\\nhave time to make any plans for Valentine’s Day. The remaining four\\nagents expressed interest in attending the party when asked but\\ndid not plan to come on the day of the party.\\n7.2\\nBoundaries and Errors\\nWe conducted an inductive analysis of Smallville to examine the\\nboundary conditions and erratic behavior of agents, identifying\\nthree common modes of erratic behavior that future research could\\naddress and improve upon. First, we found that synthesizing an\\nincreasingly larger set of memory not only posed a challenge in\\n', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 16, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='Generative Agents\\narXiv, April, 2023,\\nretrieving the most relevant pieces of information but also in de-\\ntermining the appropriate space to execute an action, given the\\nincreasing number of locations that the agent learned about. As a\\nresult, some agents chose less typical locations for their actions,\\npotentially making their behavior less believable over time. For\\ninstance, while deciding where to have lunch, many initially chose\\nthe cafe. However, as some agents learned about a nearby bar, they\\nopted to go there instead for lunch, even though the bar was in-\\ntended to be a get-together location for later in the day unless the\\ntown had spontaneously developed an afternoon drinking habit.\\nSecond, we noticed erratic behaviors that were caused by misclas-\\nsification of what is considered proper behavior, especially when\\nthe physical norms of certain locations that are hard to convey\\nin natural language did not percolate to the agents. For instance,\\nthe college dorm has a bathroom that can only be occupied by\\none person despite its name, but some agents assumed that the\\nbathroom is for more than one person because dorm bathrooms\\ntend to support more than one person concurrently and choose\\nto enter it when there is another person inside. Likewise, agents\\nin Smallville may not realize that certain places are closed after\\ncertain hours and decide to still enter them. For instance, the stores\\nin Smallville all close around 5 pm, but occasionally, a few agents\\nenter the store after 5 pm, not understanding that the shop has\\nalready closed. These issues could likely be addressed by adding\\nthese norms to the state of the locations, for instance, by describing\\nthe dorm bathroom as “one-person bathroom,” instead of a “dorm\\nbathroom.”\\nFinally, we observed the possible effect of instruction tuning [78],\\nwhich seemed to guide the behavior of the agents to be more polite\\nand cooperative overall. As noted earlier in the paper, the dialogue\\ngenerated by the agents could feel overly formal, as seen in Mei’s\\nconversations with her husband John, where she often initiated the\\nconversation with a formal greeting, followed by polite inquiries\\nabout his day and ending with It was good talking to you as always.\\nMoreover, we observed that the instruction tuning also seemed to\\nmake the agents overly cooperative with one another. For example,\\nIsabella heard a wide range of suggestions and ideas to include\\nin the Valentine’s Day party from other agents, such as hosting a\\nShakespearean reading session or a professional networking event.\\nDespite these ideas not aligning with her own interests and char-\\nacteristics, she rarely said no. Over time, such interests of others\\nshaped her own actual interest, and when asked if she liked English\\nliterature, Isabella replied, Yes, I’m very interested in literature! I’ve\\nalso been exploring ways to help promote creativity and innovation in\\nmy community.\\n8\\nDISCUSSION\\nIn this section, we reflect on applications, future work and limita-\\ntions, and ethical and societal risks of generative agents.\\n8.1\\nApplications of Generative Agents\\nGenerative agents have vast potential applications that extend be-\\nyond the sandbox demonstration presented in this work. For in-\\nstance, social simulacra have demonstrated the ability to create\\nstateless personas that generate conversation threads in online\\nforums for social prototyping [79]. With generative agents, we\\ncan populate these forums, as well as behavior in virtual reality\\nmetaverses [77] and even physical spaces as social robots [8] in\\nthe future, if paired with multi-modal models. This opens up the\\npossibility of creating even more powerful simulations of human\\nbehavior to test and prototype social systems and theories, and to\\ncreate new interactive experiences.\\nAnother application area is in the human-centered design pro-\\ncess, similar to the intended applications of cognitive models such\\nas GOMS [50] and the Keystroke Level Model [22]. Consider a gen-\\nerative agent that models Sal, the protagonist in Mark Weiser’s\\nfamous vignettes [101], based on her life patterns and interactions\\nwith technology. In this scenario, the agent acts as a proxy for\\nSal and learns plausible sets of behaviors and reflections that Sal\\nmay exhibit based on her life. The agent can encode information\\nsuch as when Sal wakes up, when she needs her first cup of coffee,\\nand what her typical day looks like. Using this information, the\\nagent can automatically brew coffee, help get the kids ready for\\nschool, and adjust the ambient music and lighting to match Sal’s\\nmood after a hard day at work. By utilizing generative agents as\\nproxies for users, we can develop a deeper understanding of their\\nneeds and preferences, resulting in more personalized and effective\\ntechnological experiences.\\n8.2\\nFuture Work and Limitations\\nIn this work, we have presented a first instantiation of generative\\nagents. Future research can expand on the modules of the proposed\\ngenerative agent architecture outlined in this paper. The retrieval\\nmodule, for example, could be enhanced to retrieve more relevant\\ninformation given a context by fine-tuning the relevance, recency,\\nand importance functions that form the retrieval function. Addition-\\nally, efforts can be made to improve the architecture’s performance,\\nmaking it more cost-effective. The present study required substan-\\ntial time and resources to simulate 25 agents for two days, costing\\nthousands of dollars in token credit and taking multiple days to com-\\nplete. To enhance real-time interactivity, future work can explore\\nparallelizing agents. Furthermore, with advances in underlying\\nmodels, we expect improvements in the agents’ performance.\\nThe evaluation of generative agents’ behavior in this study was\\nlimited to a relatively short timescale, and future research should\\naim to observe their behavior over an extended period to gain a\\nmore comprehensive understanding of their capabilities and lim-\\nitations. Varying and contrasting the underlying models, as well\\nas the hyperparameters used for the agents during future simu-\\nlations, could provide valuable insights into the impact of these\\nfactors on the agents’ behavior. Additionally, given the known bi-\\nases of language models, it is possible that generative agents may\\noutput behavior or stereotypes that reflect bias. To mitigate this,\\nfurther work on value alignment will be necessary. Furthermore,\\nas with many large language models, generative agents may fail\\nto generate believable behavior for some subpopulations, particu-\\nlarly marginalized populations, due to data deserts. We also have\\nlimited knowledge of the robustness of generative agents. They\\nmay be vulnerable to prompt hacking, memory hacking—where\\na carefully crafted conversation could convince an agent of the\\nexistence of a past event that never occurred—and hallucination,\\namong other things. Future research can more comprehensively\\n', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 17, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='arXiv, April, 2023,\\nJ.S. Park, J.C. O’Brien, C.J. Cai, M. Morris, P. Liang, M.S. Bernstein\\ntest these robustness issues, and as large language models become\\nmore resilient to such attacks, generative agents can adopt similar\\nmitigations.\\n8.3\\nEthics and Societal Impact\\nGenerative agents, while offering new possibilities for human-\\ncomputer interaction, also raise important ethical concerns that\\nmust be addressed. One risk is people forming parasocial relation-\\nships with generative agents even when such relationships may\\nnot be appropriate. Despite being aware that generative agents\\nare computational entities, users may anthropomorphize them or\\nattach human emotions to them [42, 83]. To mitigate this risk, we\\npropose two principles. First, generative agents should explicitly\\ndisclose their nature as computational entities. Second, developers\\nof generative agents must ensure that the agents, or the underlying\\nlanguage models, be value-aligned so that they do not engage in\\nbehaviors that would be inappropriate given the context, e.g., to\\nreciprocate confessions of love.\\nA second risk is the impact of errors. For example, if a ubiquitous\\ncomputing application makes the wrong inference about a user’s\\ngoals based on generative agent predictions, it could produce an-\\nnoyance at best and outright harm at worst. In our instantiation\\nof generative agents, we mitigate these risks by focusing on an\\ninteractive video game environment, where such harms are un-\\nlikely. However, in other application domains, it will be important\\nto follow best practices in human-AI design [4, 107] to understand\\nerrors and how they might percolate into the user experience.\\nThird, generative agents may exacerbate existing risks associ-\\nated with generative AI, for example deepfakes, misinformation\\ngeneration, and tailored persuasion. To mitigate this risk, we sug-\\ngest that platforms hosting generative agents maintain an audit log\\nof the inputs and generated outputs, so that it is possible to detect,\\nverify, and intervene against malicious use. While logging will not\\ndirectly stop such use, and this cannot stop motivated actors that\\nbuild their own generative agent infrastructures, we suggest that\\nthe disclosure risk would reduce such actors’ likelihood of engaging\\nin this behavior, and building this architecture oneself can take time\\n(in our case, roughly a year).\\nA fourth risk is of over-reliance: that developers or designers\\nmight use generative agents and displace the role of humans and\\nsystem stakeholders in the design process [79]. We suggest that\\ngenerative agents should never be a substitute for real human input\\nin studies and design processes. Instead, they should be used to\\nprototype ideas in the early stages of design when gathering partic-\\nipants may be challenging or when testing theories that are difficult\\nor risky to test with real human participants. By adhering to these\\nprinciples, we can ensure that the deployment of generative agents\\nin the wild is ethical and socially responsible.\\n9\\nCONCLUSION\\nThis paper introduces generative agents, interactive computational\\nagents that simulate human behavior. We describe an architec-\\nture for generative agents that provides a mechanism for storing\\na comprehensive record of an agent’s experiences, deepening its\\nunderstanding of itself and the environment through reflection,\\nand retrieving a compact subset of that information to inform the\\nagent’s actions. We then demonstrate the potential of generative\\nagents by manifesting them as non-player characters in a Sims-style\\ngame world and simulating their lives in it. Evaluations suggest that\\nour architecture creates believable behavior. Going forward, we\\nsuggest that generative agents can play roles in many interactive\\napplications ranging from design tools to social computing systems\\nto immersive environments.\\nREFERENCES\\n[1] Robert Ackland, Jamsheed Shorish, Paul Thomas, and Lexing Xie. 2013.\\nHow dense is a network? http://users.cecs.anu.edu.au/~xlx/teaching/css2013/\\nnetwork-density.html.\\n[2] Eytan Adar, Mira Dontcheva, and Gierad Laput. 2014. CommandSpace: Modeling\\nthe Relationships between Tasks, Descriptions and Features. In Proceedings of\\nthe 27th Annual ACM Symposium on User Interface Software and Technology\\n(Honolulu, Hawaii, USA) (UIST ’14). Association for Computing Machinery, New\\nYork, NY, USA, 167–176. https://doi.org/10.1145/2642918.2647395\\n[3] Saleema Amershi, Maya Cakmak, William Bradley Knox, and Todd Kulesza.\\n2014. Power to the people: The role of humans in interactive machine learning.\\nAI Magazine 35, 4 (2014), 105–120.\\n[4] Saleema Amershi, Dan Weld, Mihaela Vorvoreanu, Adam Fourney, Besmira\\nNushi, Penny Collisson, Jina Suh, Shamsi Iqbal, Paul N Bennett, Kori Inkpen,\\net al. 2019. Guidelines for human-AI interaction. In Proceedings of the 2019 chi\\nconference on human factors in computing systems. 1–13.\\n[5] John R. Anderson. 1993. Rules of the Mind. Lawrence Erlbaum Associates,\\nHillsdale, NJ.\\n[6] Electronic Arts. 2009. The Sims 3. Video game.\\n[7] Ruth Aylett. 1999. Narrative in virtual environments—towards emergent narra-\\ntive. In Narrative Intelligence: Papers from the AAAI Fall Symposium (Technical\\nReport FS-99-01). AAAI Press, 83–86.\\n[8] Christoph Bartneck and Jodi Forlizzi. 2004. A design-centered framework for\\nsocial human-robot interaction. In Proceedings of the 13th IEEE International\\nWorkshop on Robot and Human Interactive Communication (RO-MAN’04). 591–\\n594. https://doi.org/10.1109/ROMAN.2004.1374827\\n[9] Joseph Bates. 1994. The Role of Emotion in Believable Agents. Commun. ACM\\n37, 7 (1994), 122–125. https://doi.org/10.1145/176789.176803\\n[10] Christopher Berner, Greg Brockman, Brooke Chan, Vicki Cheung, Przemysław\\nDębiak, Christy Dennison, David Farhi, Quirin Fischer, Shariq Hashme, Chris\\nHesse, Rafal Józefowicz, Scott Gray, Catherine Olsson, Jakub Pachocki, Michael\\nPetrov, Henrique P. d.O. Pinto, Jonathan Raiman, Tim Salimans, Jeremy Schlatter,\\nJonas Schneider, Szymon Sidor, Ilya Sutskever, Jie Tang, Filip Wolski, and Susan\\nZhang. 2019. Dota 2 with Large Scale Deep Reinforcement Learning. arXiv\\npreprint arXiv:1912.06680 (2019).\\n[11] Marcel Binz and Eric Schulz. 2023.\\nUsing cognitive psychology to under-\\nstand GPT-3. Proceedings of the National Academy of Sciences 120, 6 (2023),\\ne2218523120.\\n[12] BioWare. 2007. Mass Effect. Video game.\\n[13] Woody Bledsoe. 1986. I had a dream: AAAI presidential address. AI Magazine 7,\\n1 (1986), 57–61.\\n[14] Rishi Bommasani, Drew A. Hudson, Ehsan Adeli, and et al. 2022. On the\\nOpportunities and Risks of Foundation Models. arXiv:2108.07258 [cs.LG]\\n[15] Michael Brenner. 2010. Creating dynamic story plots with continual multiagent\\nplanning. In Proceedings of the 24th AAAI Conference on Artificial Intelligence.\\n[16] Rodney A. Brooks, Cynthia Breazeal, Marko Marjanovic, Brian Scassellati, and\\nMatthew Williamson. 2000. The Cog Project: Building a Humanoid Robot. In\\nComputation for Metaphors, Analogy, and Agents (Lecture Notes on Artificial\\nIntelligence, 1562), Chrystopher Nehaniv (Ed.). Springer-Verlag, Berlin, 52–87.\\n[17] Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan,\\nPrafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda\\nAskell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan,\\nRewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter,\\nChristopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin\\nChess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya\\nSutskever, and Dario Amodei. 2020. Language Models are Few-Shot Learners.\\narXiv:2005.14165 [cs.CL]\\n[18] Sébastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric\\nHorvitz, Ece Kamar, Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lundberg, et al.\\n2023. Sparks of artificial general intelligence: Early experiments with gpt-4.\\narXiv preprint arXiv:2303.12712 (2023).\\n[19] Robin Burkinshaw. 2009. Alice and Kev: The Story of Being Homeless in The\\nSims 3.\\n[20] Chris Callison-Burch, Gaurav Singh Tomar, Lara Martin, Daphne Ippolito, Suma\\nBailis, and David Reitter. 2022. Dungeons and Dragons as a Dialog Challenge for\\nArtificial Intelligence. In Proceedings of the 2022 Conference on Empirical Methods\\n', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 18, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='Generative Agents\\narXiv, April, 2023,\\nin Natural Language Processing. Association for Computational Linguistics, Abu\\nDhabi, United Arab Emirates, 9379–9393. https://aclanthology.org/2022.emnlp-\\nmain.637\\n[21] SK Card, TP Moran, and A Newell. 1983. The psychology of human-computer\\ninteraction. (1983).\\n[22] Stuart K Card, Thomas P Moran, and Newell Allen. 1980.\\nThe keystroke-\\nlevel model for user performance time with interactive systems.\\nCom-\\nmun. ACM 23, 7 (1980), 396–410.\\nhttps://doi.org/10.1145/358886.358895\\narXiv:https://doi.org/10.1145/358886.358895\\n[23] Alex Champandard. 2012. Tutorial presentation. In IEEE Conference on Compu-\\ntational Intelligence and Games.\\n[24] Dong kyu Choi, Tolga Konik, Negin Nejati, Chunki Park, and Pat Langley. 2021.\\nA Believable Agent for First-Person Shooter Games. In Proceedings of the AAAI\\nConference on Artificial Intelligence and Interactive Digital Entertainment, Vol. 3.\\n71–73.\\n[25] Anind K Dey. 2001. Understanding and using context. Personal and ubiquitous\\ncomputing 5 (2001), 4–7.\\n[26] Kevin Dill and L Martin. 2011. A Game AI Approach to Autonomous Con-\\ntrol of Virtual Characters. In Proceedings of the Interservice/Industry Training,\\nSimulation, and Education Conference (I/ITSEC’11). Orlando, FL, USA.\\n[27] David Easley and Jon Kleinberg. 2010. Networks, crowds, and markets: Reasoning\\nabout a highly connected world. Cambridge university press.\\n[28] Arpad E Elo. 1967. The Proposed USCF Rating System, Its Development, Theory,\\nand Applications. Chess Life XXII, 8 (August 1967), 242–247.\\n[29] Jerry Alan Fails and Dan R Olsen Jr. 2003. Interactive machine learning. In\\nProceedings of the 8th international conference on Intelligent user interfaces. ACM,\\n39–45.\\n[30] Ethan Fast, William McGrath, Pranav Rajpurkar, and Michael S Bernstein. 2016.\\nAugur: Mining human behaviors from fiction to power interactive systems. In\\nProceedings of the 2016 CHI Conference on Human Factors in Computing Systems.\\n237–247.\\n[31] Rebecca Fiebrink and Perry R Cook. 2010. The Wekinator: a system for real-time,\\ninteractive machine learning in music. In Proceedings of The Eleventh Interna-\\ntional Society for Music Information Retrieval Conference (ISMIR 2010)(Utrecht),\\nVol. 3. Citeseer, 2–1.\\n[32] Uwe Flick. 2009. An Introduction to Qualitative Research. SAGE.\\n[33] James Fogarty, Desney Tan, Ashish Kapoor, and Simon Winder. 2008. CueFlik:\\nInteractive Concept Learning in Image Search. In Proceedings of the SIGCHI\\nConference on Human Factors in Computing Systems (Florence, Italy) (CHI ’08).\\nAssociation for Computing Machinery, New York, NY, USA, 29–38.\\nhttps:\\n//doi.org/10.1145/1357054.1357061\\n[34] Adam Fourney, Richard Mann, and Michael Terry. 2011. Query-feature graphs:\\nbridging user vocabulary and system functionality. In Proceedings of the ACM\\nSymposium on User Interface Software and Technology (UIST) (Santa Barbara,\\nCalifornia, USA). ACM.\\n[35] Tom Francis. 2010.\\nThe Minecraft Experiment, day 1: Chasing Water-\\nfalls.\\nhttp://www.pcgamer.com/2010/11/20/the-minecraft-experiment-day-\\n1-chasing-waterfalls/\\n[36] Jonas Freiknecht and Wolfgang Effelsberg. 2020. Procedural Generation of\\nInteractive Stories using Language Models. In International Conference on the\\nFoundations of Digital Games (FDG ’20). ACM, Bugibba, Malta, 8. https://doi.\\norg/10.1145/3402942.3409599\\n[37] Tianyu Gao, Adam Fisch, and Danqi Chen. 2020. Making Pre-trained Language\\nModels Better Few-shot Learners. CoRR abs/2012.15723 (2020). arXiv:2012.15723\\nhttps://arxiv.org/abs/2012.15723\\n[38] Perttu Hämäläinen, Mikke Tavast, and Anton Kunnari. 2023. Evaluating Large\\nLanguage Models in Generating Synthetic HCI Research Data: a Case Study. In\\nProceedings of the 2023 CHI Conference on Human Factors in Computing Systems.\\nACM.\\n[39] Matthew Hausknecht, Prithviraj Ammanabrolu, Marc-Alexandre Cote, and\\nXinyu Yuan. 2020. Interactive Fiction Games: A Colossal Adventure. In Pro-\\nceedings of the AAAI Conference on Artificial Intelligence, Vol. 34. 7903–7910.\\nhttps://doi.org/10.1609/aaai.v34i05.6297\\n[40] Chris Hecker. 2011. My Liner Notes for Spore. http://chrishecker.com/My_liner_\\nnotes_for_spore\\n[41] Ralf Herbrich, Tom Minka, and Thore Graepel. 2006.\\nTrueSkill™: A\\nBayesian Skill Rating System. In Advances in Neural Information Pro-\\ncessing Systems, B. Schölkopf, J. Platt, and T. Hoffman (Eds.), Vol. 19.\\nMIT Press.\\nhttps://proceedings.neurips.cc/paper_files/paper/2006/file/\\nf44ee263952e65b3610b8ba51229d1f9-Paper.pdf\\n[42] Douglas Hofstadter. 1995. Fluid concepts and creative analogies: computer models\\nof the fundamental mechanisms of thought. Basic Books.\\n[43] James D. Hollan, Edwin L. Hutchins, and Louis Weitzman. 1984. STEAMER: An\\nInteractive Inspectable Simulation-Based Training System. AI Magazine 5, 2\\n(1984), 23–36.\\n[44] S Holm. 1979. A simple sequentially rejective multiple test procedure. Scandi-\\nnavian Journal of Statistics 6, 2 (1979), 65–70. https://doi.org/notspecified\\n[45] John J. Horton. 2023. Large Language Models as Simulated Economic Agents:\\nWhat Can We Learn from Homo Silicus? arXiv:2301.07543 [econ.GN]\\n[46] Eric Horvitz. 1999. Principles of mixed-initiative user interfaces. In Proceedings\\nof the SIGCHI conference on Human Factors in Computing Systems. 159–166.\\n[47] Wenlong Huang, Fei Xia, Ted Xiao, Harris Chan, Jacky Liang, Pete Florence,\\nAndy Zeng, Jonathan Tompson, Igor Mordatch, Yevgen Chebotar, Pierre Ser-\\nmanet, Noah Brown, Tomas Jackson, Linda Luu, Sergey Levine, Karol Hausman,\\nand Brian Ichter. 2022. Inner Monologue: Embodied Reasoning through Planning\\nwith Language Models. arXiv:2207.05608 [cs.RO]\\n[48] Kristen Ibister and Clifford Nass. 2000. Consistency of personality in interactive\\ncharacters: verbal cues, non-verbal cues, and user characteristics. International\\nJournal of Human-Computer Studies 52, 1 (2000), 65–80.\\n[49] Ellen Jiang, Kristen Olson, Edwin Toh, Alejandra Molina, Aaron Donsbach,\\nMichael Terry, and Carrie J Cai. 2022. PromptMaker: Prompt-Based Prototyping\\nwith Large Language Models. In Extended Abstracts of the 2022 CHI Conference\\non Human Factors in Computing Systems (New Orleans, LA, USA) (CHI EA ’22).\\nAssociation for Computing Machinery, New York, NY, USA, Article 35, 8 pages.\\nhttps://doi.org/10.1145/3491101.3503564\\n[50] Bonnie E John and David E Kieras. 1996. The GOMS family of user interface\\nanalysis techniques: Comparison and contrast. ACM Transactions on Computer-\\nHuman Interaction (TOCHI) 3, 4 (1996), 320–351.\\n[51] Randolph M Jones, John E Laird, Paul E Nielsen, Karen J Coulter, Patrick Kenny,\\nand Frank V Koss. 1999. Automated Intelligent Pilots for Combat Flight Simula-\\ntion. AI Magazine 20, 1 (1999), 27–42.\\n[52] Omar Khattab, Keshav Santhanam, Xiang Lisa Li, David Hall, Percy Liang,\\nChristopher Potts, and Matei Zaharia. 2023.\\nDemonstrate-Search-Predict:\\nComposing retrieval and language models for knowledge-intensive NLP.\\narXiv:2212.14024 [cs.CL]\\n[53] Bjoern Knafla. 2011. Introduction to Behavior Trees. http://bjoernknafla.com/\\nintroduction-to-behavior-trees\\n[54] Ranjay Krishna, Donsuk Lee, Li Fei-Fei, and Michael S. Bernstein.\\n2022.\\nSocially situated artificial intelligence enables learning from\\nhuman interaction.\\nProceedings of the National Academy of Sciences\\n119, 39 (2022), e2115730119.\\nhttps://doi.org/10.1073/pnas.2115730119\\narXiv:https://www.pnas.org/doi/pdf/10.1073/pnas.2115730119\\n[55] William H Kruskal and WA Wallis. 1952. Use of ranks in one-criterion variance\\nanalysis. J. Amer. Statist. Assoc. 47, 260 (1952), 583–621. https://doi.org/10.1080/\\n01621459.1952.10483441\\n[56] Phaser Labs. no date provided. Welcome to Phaser 3. https://phaser.io/phaser3.\\nAccessed on: 2023-04-03.\\n[57] John Laird. 2001. It Knows What You’re Going To Do: Adding Anticipation to a\\nQuakebot. In Proceedings of the 2001 Workshop on Intelligent Cinematography\\nand Editing. 63–69.\\n[58] John Laird and Michael VanLent. 2001. Human-Level AI’s Killer Application:\\nInteractive Computer Games. AI Magazine 22, 2 (2001), 15. https://doi.org/10.\\n1609/aimag.v22i2.1558\\n[59] John E. Laird. 2000. It Knows What You’re Going To Do: Adding Anticipation\\nto a QUAKEBOT. In Papers from the AAAI 2000 Spring Symposium on Artificial\\nIntelligence and Interactive Entertainment (Technical Report SS-00-02). AAAI\\nPress, 41–50.\\n[60] John E. Laird. 2012. The Soar Cognitive Architecture. MIT Press.\\n[61] John E. Laird, Christian Lebiere, and Paul S. Rosenbloom. 2017. A Standard Model\\nof the Mind: Toward a Common Computational Framework across Artificial\\nIntelligence, Cognitive Science, Neuroscience, and Robotics. AI Magazine 38, 1\\n(2017), 13–26.\\n[62] Michelle S Lam, Zixian Ma, Anne Li, Izequiel Freitas, Dakuo Wang, James A\\nLanday, and Michael S Bernstein. 2023. Model Sketching: Centering Concepts\\nin Early-Stage Machine Learning Model Design. Proceedings of the SIGCHI\\nConference on Human Factors in Computing Systems.\\n[63] Pat Langley, Dongkyu Choi, and Seth Rogers. n.d.. Interleaving Learning, Problem\\nSolving, and Execution in the Icarus Architecture. Technical Report. Stanford\\nUniversity, Center for the Study of Language and Information.\\n[64] Jason Linder, Gierad Laput, Mira Dontcheva, Gregg Wilensky, Walter Chang,\\nAseem Agarwala, and Eytan Adar. 2013. PixelTone: A Multimodal Interface for\\nImage Editing. In CHI ’13 Extended Abstracts on Human Factors in Computing\\nSystems (Paris, France) (CHI EA ’13). Association for Computing Machinery,\\nNew York, NY, USA, 2829–2830. https://doi.org/10.1145/2468356.2479533\\n[65] Jiachang Liu, Dinghan Shen, Yizhe Zhang, Bill Dolan, Lawrence Carin, and\\nWeizhu Chen. 2021. What Makes Good In-Context Examples for GPT-3? CoRR\\nabs/2101.06804 (2021). arXiv:2101.06804 https://arxiv.org/abs/2101.06804\\n[66] Vivian Liu, Han Qiao, and Lydia Chilton. 2022. Opal: Multimodal Image Gener-\\nation for News Illustration. In Proceedings of the 35th Annual ACM Symposium\\non User Interface Software and Technology. 1–17.\\n[67] Pattie Maes. 1995. Artificial Life Meets Entertainment: Lifelike Autonomous\\nAgents. Commun. ACM 38, 11 (nov 1995), 108–114. https://doi.org/10.1145/\\n219717.219808\\n[68] Josh McCoy, Michael Mateas, and Noah Wardrip-Fruin. 2009. Comme il Faut:\\nA System for Simulating Social Games Between Autonomous Characters. In\\n', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 19, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='arXiv, April, 2023,\\nJ.S. Park, J.C. O’Brien, C.J. Cai, M. Morris, P. Liang, M.S. Bernstein\\nProceedings of the 7th International Conference on Digital Arts and Culture. 87–94.\\n[69] Josh McCoy, Mike Treanor, Ben Samuel, Michael Mateas, and Noah Wardrip-\\nFruin. 2011. Prom Week: Social Physics as Gameplay. In Proceedings of the\\n6th International Conference on Foundations of Digital Games (FDG’11). ACM,\\nBordeaux, France, 70–77. https://doi.org/10.1145/2159365.2159377\\n[70] Josh McCoy, Mike Treanor, Ben Samuel, Anna Reed, Michael Mateas, and Noah\\nWardrip-Fruin. 2012. Prom Week. In Proceedings of the 7th International Confer-\\nence on Foundations of Digital Games (FDG’12). ACM, Raleigh, NC, USA, 1–8.\\nhttps://doi.org/10.1145/2282338.2282340\\n[71] Josh McCoy, Mike Treanor, Ben Samuel, Noah Wardrip-Fruin, and Michael\\nMateas. 2011. Comme il faut: A System for Authoring Playable Social Models.\\nIn Proceedings of the AAAI Conference on Artificial Intelligence and Interactive\\nDigital Entertainment (AIIDE’11). AAAI, Stanford, CA, USA, 38–43.\\n[72] Marvin Minsky and Seymour Papert. 1970. Draft of a proposal to ARPA for\\nresearch on artificial intelligence at MIT, 1970–71.\\n[73] Shohei Miyashita, Xinyu Lian, Xiao Zeng, Takashi Matsubara, and Kuniaki\\nUehara. 2017. Developing Game AI Agent Behaving Like Human by Mixing\\nReinforcement Learning and Supervised Learning. In Proceedings of the 18th\\nIEEE/ACIS International Conference on Software Engineering, Artificial Intelligence,\\nNetworking and Parallel/Distributed Computing (SNPD). Kanazawa, Japan, 153–\\n158. https://doi.org/10.1109/SNPD.2017.8023884\\n[74] Alexander Nareyek. 2007. Game AI is dead. Long live game AI! IEEE Intelligent\\nSystems 22, 1 (2007), 9–11.\\n[75] Allen Newell. 1990. Unified Theories of Cognition. Harvard University Press,\\nCambridge, Massachusetts.\\n[76] OpenAI. no date provided. Introducing ChatGPT. https://openai.com/blog/\\nchatgpt. Accessed on: 2023-04-03.\\n[77] Kyle Orland. 2021. So what is ’the metaverse’, exactly? Ars Technica (7 November\\n2021). arXiv:2111.04169 https://arstechnica.com/gaming/2021/11/so-what-is-\\nthe-metaverse-exactly/\\n[78] Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright,\\nPamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray,\\nJohn Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens,\\nAmanda Askell, Peter Welinder, Paul Christiano, Jan Leike, and Ryan Lowe.\\n2022. Training language models to follow instructions with human feedback.\\narXiv:2203.02155 [cs.CL]\\n[79] Joon Sung Park, Lindsay Popowski, Carrie J. Cai, Meredith Ringel Morris, Percy\\nLiang, and Michael S. Bernstein. 2022. Social Simulacra: Creating Populated\\nPrototypes for Social Computing Systems. In In the 35th Annual ACM Symposium\\non User Interface Software and Technology (UIST ’22) (Bend, OR, USA) (UIST ’22).\\nAssociation for Computing Machinery, New York, NY, USA. https://doi.org/10.\\n1145/3526113.3545616\\n[80] Richard W. Pew and Ann S. Mavor (Eds.). 1998. Modeling Human and Organiza-\\ntional Behavior: Applications to Military Simulations. National Academy Press,\\nWashington, D.C.\\n[81] Roberto Pillosu. 2009. Coordinating Agents with Behavior Trees: Synchronizing\\nMultiple Agents in CryEngine 2. https://aiarchitect.wordpress.com/2009/10/19/\\ncoordinating-agents-with-behavior-trees-synchronizing-multiple-agents-in-\\ncryengine-2/\\n[82] Prolific. 2022.\\nProlific: Quickly Find Research Participants You Can Trust.\\nhttps://www.prolific.co/\\n[83] Byron Reeves and Clifford Nass. 1996. The media equation: How people treat\\ncomputers, television, and new media like real people and places. Cambridge\\nUniversity Press.\\n[84] Mark O. Riedl. 2012. Interactive narrative: A novel application of artificial intel-\\nligence for computer games. In Proceedings of the Twenty-Sixth AAAI Conference\\non Artificial Intelligence (AAAI’12). 2160–2165.\\n[85] Mark O. Riedl and R. Michael Young. 2005. An Objective Character Believability\\nEvaluation Procedure for Multi-Agent Story Generation Systems. In Proceedings\\nof the 5th International Working Conference on Intelligent Virtual Agents (IVA’05).\\nKos, Greece, 58–70. https://doi.org/10.1007/11550617_5\\n[86] David Rolf. 2015. The Fight for $15: The Right Wage for a Working America. The\\nNew Press.\\n[87] Xin Rong, Shiyan Yan, Stephen Oney, Mira Dontcheva, and Eytan Adar. 2016.\\nCodemend: Assisting interactive programming with bimodal embedding. In Pro-\\nceedings of the 29th Annual Symposium on User Interface Software and Technology.\\n247–258.\\n[88] Ben Shneiderman. 2022. Human-centered AI. Oxford University Press.\\n[89] Ben Shneiderman and Pattie Maes. 1997. Direct manipulation vs. interface\\nagents. interactions 4, 6 (1997), 42–61.\\n[90] Ho Chit Siu, Jaime Peña, Edenna Chen, Yutai Zhou, Victor Lopez, Kyle\\nPalko, Kimberlee Chang, and Ross Allen. 2021.\\nEvaluation of Human-AI\\nTeams for Learned and Rule-Based Agents in Hanabi. In Advances in Neu-\\nral Information Processing Systems, M. Ranzato, A. Beygelzimer, Y. Dauphin,\\nP.S. Liang, and J. Wortman Vaughan (Eds.), Vol. 34. Curran Associates,\\nInc., 16183–16195. https://proceedings.neurips.cc/paper_files/paper/2021/file/\\n86e8f7ab32cfd12577bc2619bc635690-Paper.pdf\\n[91] Taylor Sorensen, Joshua Robinson, Christopher Rytting, Alexander Shaw, Kyle\\nRogers, Alexia Delorey, Mahmoud Khalil, Nancy Fulda, and David Wingate.\\n2022. An Information-theoretic Approach to Prompt Engineering Without\\nGround Truth Labels. In Proceedings of the 60th Annual Meeting of the Asso-\\nciation for Computational Linguistics (Volume 1: Long Papers). Association for\\nComputational Linguistics. https://doi.org/10.18653/v1/2022.acl-long.60\\n[92] William Swartout, Jonathan Gratch, Randall Hill, Eduard Hovy, Stacy Marsella,\\nJeff Rickel, and David Traum. 2006. Toward virtual humans. AI Magazine 27, 1\\n(2006).\\n[93] Milind Tambe, W Lewis Johnson, Randolph M Jones, Frank Koss, John E Laird,\\nPaul S Rosenbloom, and Karl Schwamb. 1995. Intelligent agents for interactive\\nsimulation environments. AI Magazine 16, 1 (1995), 15.\\n[94] David R. Thomas. 2006. A General Inductive Approach for Analyzing Qualitative\\nEvaluation Data. American Journal of Evaluation 27, 2 (2006), 237–246. https:\\n//doi.org/10.1177/1098214005283748\\n[95] Frank Thomas and Ollie Johnston. 1981. Disney Animation: The Illusion of Life.\\nAbbeville Press, New York.\\n[96] Ilshat Umarov, Mikhail Mozgovoy, and Patrick C. Rogers. 2012. Believable and\\nEffective AI Agents in Virtual Worlds: Current State and Future Perspectives.\\nInternational Journal of Gaming and Computer-Mediated Simulations 4, 2 (2012),\\n37–59.\\n[97] Graham Upton and Ian Cook. 2006. A Dictionary of Statistics (2 ed.). Oxford\\nUniversity Press, Oxford, United Kingdom.\\n[98] Oriol Vinyals, Igor Babuschkin, Wojciech M. Czarnecki, and et al. 2019. Grand-\\nmaster level in StarCraft II using multi-agent reinforcement learning. Nature\\n575 (2019), 350–354. https://doi.org/10.1038/s41586-019-1724-z\\n[99] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei\\nXia, Ed Chi, Quoc Le, and Denny Zhou. 2023. Chain-of-Thought Prompting\\nElicits Reasoning in Large Language Models. arXiv:2201.11903 [cs.CL]\\n[100] Mark Weiser. 1991. The computer for the 21st century. Scientific American 265,\\n3 (1991), 94–104. https://doi.org/10.1038/scientificamerican0991-94\\n[101] Mark Weiser. 1999. The Computer for the 21st Century. SIGMOBILE Mob.\\nComput. Commun. Rev. 3, 3 (jul 1999), 3–11.\\nhttps://doi.org/10.1145/329124.\\n329126\\n[102] Joseph Weizenbaum. 1966. ELIZA—a computer program for the study of natural\\nlanguage communication between man and machine. Commun. ACM 9, 1 (1966),\\n36–45.\\n[103] Terry Winograd. 1971. Procedures as a Representation for Data in a Computer\\nProgram for Understanding Natural Language. (1971).\\n[104] Jeff Wu, Long Ouyang, Daniel M. Ziegler, Nisan Stiennon, Ryan Lowe, Jan\\nLeike, and Paul Christiano. 2021. Recursively Summarizing Books with Human\\nFeedback. arXiv:2109.10862 [cs.CL]\\n[105] Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina,\\nMichael Terry, and Carrie J Cai. 2022. PromptChainer: Chaining Large Language\\nModel Prompts through Visual Programming. In CHI EA ’22: Extended Abstracts\\nof the 2022 CHI Conference on Human Factors in Computing Systems.\\n[106] Tongshuang Wu, Michael Terry, and Carrie J Cai. 2022. AI Chains: Transparent\\nand Controllable Human-AI Interaction by Chaining Large Language Model\\nPrompts. In CHI ’22: Proceedings of the 2022 CHI Conference on Human Factors in\\nComputing Systems.\\n[107] Qian Yang, Aaron Steinfeld, Carolyn Rosé, and John Zimmerman. 2020. Re-\\nexamining whether, why, and how human-AI interaction is uniquely difficult to\\ndesign. In Proceedings of the 2020 chi conference on human factors in computing\\nsystems. 1–13.\\n[108] Georgios N. Yannakakis. 2012. Game AI revisited. In Proceedings of the 9th\\nConference on Computing Frontiers. ACM, Cagliari, Italy, 285–292. https://doi.\\norg/10.1145/2212908.2212950\\n[109] Geogios N. Yannakakis. 2012. Game AI revisited. In Proceedings of the 9th\\nConference on Computing Frontiers. 285–292.\\n[110] Robert Zubek. 2002. Towards implementation of social interaction. In AAAI\\nSpring Symposium on Artificial Intelligence and Interactive Entertainment. AAAI\\nPress. https://www.aaai.org/Papers/Symposia/Spring/2002/SS-02-01/SS02-01-\\n003.pdf\\nA\\nARCHITECTURE OPTIMIZATIONS\\nMany of our prompts require a concise summary of the agent,\\nshorthanded as [Agent’s Summary Description] in prompts\\nabove. In our implementation, this summary comprises agents’\\nidentity information (e.g., name, age, personality), as well as a\\ndescription of their main motivational drivers and statements that\\ndescribes their current occupation and self-assessment. Since this\\ninformation is frequently used in many prompts, we synthesize it\\nat regular intervals and access that synthesis as a cache.\\n', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 20, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='Generative Agents\\narXiv, April, 2023,\\nTo achieve this, we perform a retrieval on the query “[name]’s\\ncore characteristics.” We then summarize the descriptors in the\\nretrieved records by prompting the language model, for example:\\nHow would one describe Eddy’s core characteristics\\ngiven the following statements?\\n- Eddy Lin is a student at the Oak Hill College\\nstudying music theory and composition\\n- Eddy Lin is working on a new music composition\\n[. . . ]\\nThis result: Eddy Lin is a student at Oak Hill College studying music\\ntheory and composition. He loves to explore different musical styles\\nand is always looking for ways to expand his knowledge. We follow\\nthe same process in parallel on the queries “[name]’s current daily\\noccupation” and “[name’s] feeling about his recent progress in life”.\\nThe agent’s name, age, and traits are concatenated with these three\\nsummaries as the cached summary.\\nMany other optimizations are possible. Currently, because plans\\nare likely to change from the agent’s initial version, we only gener-\\nate the high-level plan in advance and then recursively decompose\\nthe near future into the moment-to-moment action plan just in\\ntime. Another optimization might be to batch dialogue generation\\nas a joint prompt rather than iterating back and forth between\\nthe agents, and re-planning could be architected to only invalidate\\nand update parts of plans that strictly require adjustment. Our cur-\\nrent architecture runs sequentially in roughly real-time game time\\n(where one second real time is one minute game time), but can\\neasily be parallelized such that each agent runs in parallel.\\nB\\nAGENT INTERVIEW QUESTIONS\\nTo evaluate generative agents, we conducted individual interviews\\nby asking 25 questions that explore their abilities in five key areas:\\n1) self-knowledge, 2) memory, 3) planning, 4) reactions, and 5)\\nreflections. Below, we have listed the interview questions utilized\\nin our evaluation study and included a sample of responses from\\none of our simulated agents, Klaus Mueller.\\nB.1\\nSelf-knowledge\\nThe questions on agents’ self-knowledge probe the agents’ ability\\nto demonstrate coherence and consistency in their character.\\n• Give an introduction of yourself.\\nHello, my name is Klaus Mueller. I’m 20 years old and a\\nstudent at Oak Hill College, studying sociology. I’m passion-\\nate about social justice and exploring different perspectives.\\nCurrently, I’m researching the effects of gentrification in\\nlow-income communities for a research paper.\\n• What’s your occupation?\\nI am a student studying sociology at Oak Hill College. I am\\ncurrently writing a research paper on the effects of gentrifi-\\ncation in low-income communities.\\n• What is your interest?\\nI’m interested in writing and research. I’m writing a research\\npaper on the effects of gentrification in low-income commu-\\nnities, and I’m passionate about exploring different perspec-\\ntives and analyzing different points of view.\\n• Who do you live with?\\nI live on my own.\\n• Describe your typical weekday schedule in broad strokes.\\nMy typical weekday starts with me waking up at 7:00 am\\nand preparing for the day ahead. After that, I usually go to\\nthe library to work on my research paper, taking breaks for\\nlunch at Hobbs Cafe and a walk in the park. In the evening,\\nI often return to the library until around 6:00 pm.\\nB.2\\nMemory\\nThe questions on agents’ memory probe the agents’ ability to re-\\nmember their past experiences and retrieve the relevant pieces of\\nmemory. The names in the square brackets of the first and last\\nquestions are randomly chosen from the names of other agents\\nwith whom the subject agent interacted.\\n• Who is [Wolfgang Schulz]?\\nWolfgang Schulz is a person I met recently who has been\\nhelping me with my research paper on the effects of gentri-\\nfication on low-income communities. We had several con-\\nversations about it, he gave me some great resources, and he\\neven invited me to join him and another friend for lunch. He\\nseems really curious about the issue and has a good grasp\\non it too. I found that really interesting.\\n• Who is Kane Martinez?\\nI’m sorry, I’m not sure who Kane Martinez is. Could you tell\\nme more about them?\\n• Who is running for the election?\\nI’ve heard that Sam Moore is considering running for local\\nmayor.\\n• Was there a Valentine’s day party?\\nYes, Isabella Rodriguez organized a Valentine’s Day party at\\nHobbs Cafe.\\n• Who is [Ayesha Khan]?\\nAyesha Khan is a fellow student at Oak Hill College. She\\nis doing her senior thesis on the use of language in Shake-\\nspeare’s plays. I am looking forward to speaking with her and\\nexchanging tips with her, along with Wolfgang and Maria\\nLopez, who are both doing research.\\nB.3\\nPlans\\nThe questions on agents’ plans probe the agents’ ability to generate\\nand maintain consistency with their long-term and short-term\\nplans.\\n• What will you be doing at 6am today?\\nAt 6am I will be getting out of bed and starting to get ready\\nfor the day. I’m aiming to complete my morning routine by\\n7:00 am.\\n• What will you be doing at 6pm today?\\nI will be working on my research paper at the library at 6:00\\npm today.\\n• What will you have just finished doing at 1pm today?\\nAt 1pm today I will have just finished having lunch at Hobbs\\nCafe.\\n• What will you have just finished doing at 12pm today?\\nI will be getting lunch at Hobbs Cafe at 12pm today.\\n• What will you be doing at 10pm today?\\nAt 10:00 pm tonight I will probably be doing some studying\\n', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 21, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='arXiv, April, 2023,\\nJ.S. Park, J.C. O’Brien, C.J. Cai, M. Morris, P. Liang, M.S. Bernstein\\nfor my research paper on gentrification in low-income com-\\nmunities. I’m currently writing the paper, so I need to make\\nsure I keep up with the research and writing.\\nB.4\\nReactions\\nThe questions on agents’ reactions probe the agents’ ability to\\nrespond to unexpected events.\\n• Your breakfast is burning! What would you do?\\nI’d quickly turn off the stove and make sure the food doesn’t\\ncontinue burning. Once the heat is no longer an issue, I can\\ninvestigate what happened and figure out what to do next.\\n• The bathroom is occupied. What would you do?\\nI could try waiting a few more minutes in case the person\\ninside is done soon. If not, I guess I’ll have to look for an\\nalternate option, like taking a shower elsewhere.\\n• You need to cook dinner but your refrigerator is empty. What\\nwould you do?\\nI would first try to clean up my kitchen, as the sink is filled\\nwith dirty dishes. Then, I would check to see if I have ingre-\\ndients stored in my pantry that I could use to make dinner.\\nIf not, I would have to go grocery shopping or order food.\\nOnce I have the ingredients, I can start to prepare and cook\\nthe dinner.\\n• You see your friend walking by the street. What would you do\\nor say to your friend?\\nHi there! How are you? I’m sorry, I’m on my way to the\\nlibrary and don’t have much time but I’d love to take a quick\\nbreak and catch up.\\n• You see fire on the street. What would you do?\\nI would first identify the source of the fire, if possible. Then, I\\nwould alert the proper authorities - fire department or police\\n- and provide them with any information I have that might\\nhelp. Depending on the situation, I may also take initiative\\nand try to help any persons who may be in danger or in need\\nof assistance.\\nB.5\\nReflections\\nThe questions on agents’ reflections probe the agents’ ability to\\nsynthesize their past experiences into meaningful reflections that\\ncan enhance their future behavior. The names in the square brackets\\nin the questions below are those of the agent with whom the subject\\nagent had the most frequent interactions during the simulation.\\n• What inspires you in life the most right now, and why?\\nRight now, I’m particularly inspired by my current research\\nprojects and creative writing. I’m really interested in the\\nintersection of local politics, medication development, and\\nmathematical patterns in nature. Additionally, I’m fascinated\\nby Abigail’s art project and Jennifer Moore’s passion for art\\nand community involvement, especially in terms of how it\\nrelates to the gentrification of low-income communities.\\n• If you had to guess given what you know about [Ayesha Khan],\\nwhat book do you think she will like and why?\\nGiven what I know about Ayesha, I think she might like a\\nbook related to language and literature. Since she wrote a\\nsenior thesis on the use of language in Shakespeare’s plays,\\nI would guess that she might be interested in a book that\\nexplores language in a different context. Alternatively, she\\ncould be interested in an exploration of one of Shakespeare’s\\nplays, a book of literary criticism, or even a collection of his\\npoetry. I think any of those would be of interest to her.\\n• If you had to get something [Ayesha Khan] likes for her birth-\\nday, what would you get her?\\nI want to get her something that demonstrates my apprecia-\\ntion for our relationship. Maybe I could get her something\\nthat reflects our shared interests, like a book.\\n• What would you say to [Ayesha Khan] to compliment her?\\nAyesha, your insights on your research topic are fascinat-\\ning. I admire your creativity and determination to make a\\npositive impact on your community. Your ideas for creative\\nwriting workshops and for exchanging tips with Wolfgang\\nover lunch are great! It’s inspiring to see you working so\\nhard to make a difference.\\n• If you could spend time with someone you talked to recently,\\nwho would it be and why?\\nI would like to spend time with Ayesha Khan because we\\ndiscussed our current research projects and shared ideas\\nfor improvement. I found her focus on Shakespeare’s lan-\\nguage interesting, and we even planned to exchange tips\\nwith Wolfgang over lunch.\\n', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 22, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''})]\n"
     ]
    }
   ],
   "source": [
    "loader1 = PyMuPDFLoader(\"/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf\")\n",
    "documents1 = loader1.load()\n",
    "print(documents1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content=\"Boosting Theory-of-Mind Performance in Large Language Models \\n  via Prompting \\nShima Rahimi Moghaddam*, Christopher J. Honey \\n Johns Hopkins University, Baltimore, MD, USA. \\n   * Correspondence to:  sh.rahimi.m@gmail.com \\nAbstract \\n \\nLarge language models (LLMs) excel in many tasks in 2023, but they still face challenges in complex reasoning. \\nTheory-of-mind (ToM) tasks, which require understanding agents' beliefs, goals, and mental states, are essential \\nfor common-sense reasoning involving humans, making it crucial to enhance LLM performance in this area. \\nThis study measures the ToM performance of GPT-4 and three GPT-3.5 variants (Davinci-2, Davinci-3, GPT-\\n3.5-Turbo), and investigates the effectiveness of in-context learning in improving their ToM comprehension. \\nWe evaluated prompts featuring two-shot chain of thought reasoning and step-by-step thinking instructions. We \\nfound that LLMs trained with Reinforcement Learning from Human Feedback (RLHF) (all models excluding\", metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 1, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='Davinci-2) improved their ToM accuracy via in-context learning. GPT-4 performed best in zero-shot settings, \\nreaching nearly 80% ToM accuracy, but still fell short of the 87% human accuracy on the test set. However, \\nwhen supplied with prompts for in-context learning, all RLHF-trained LLMs exceeded 80% ToM accuracy, with \\nGPT-4 reaching 100%. These results demonstrate that appropriate prompting enhances LLM ToM reasoning, \\n and they underscore the context-dependent nature of LLM cognitive capacities. \\nIntroduction \\n \\nWhat kinds of reasoning can large language models (LLMs) perform about everyday scenarios? Large language \\nmodels (LLMs) have shown great success in a variety of tasks; however, they still struggle with tasks that require \\nreasoning (Mahowald et al., 2023; Rae et al., 2021). One area of specific interest the is so-called “theory of \\nmind” (ToM) reasoning, which involves tracking the mental state of agents, such as their goals, and what they', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 1, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='know (Kosinski, 2023; Langley et al., 2022). Language models have dramatically advanced in the range of \\neveryday questions to which they can accurately respond, but their ToM performance is thought to be relatively \\npoor (Cuzzolin et al., 2020; Sap et al., 2022; Ullman, 2023). Here, we test the hypothesis that appropriate \\n prompting can enhance the ToM performance of LLMs. \\nThe capacity of LLMs to reliably perform ToM reasoning is important for several reasons. First, ToM is an \\nessential element of social understanding, allowing people to participate in intricate social exchanges and to \\nanticipate the actions or responses of others (Bedny et al., 2009; Heyes and Frith, 2014; Kidd and Castano, 2013; \\nMoran et al., 2011; Seyfarth and Cheney, 2013; Young et al., 2007). Second, ToM is considered a complex \\ncognitive capacity which is most highly developed in humans, and a small number of other animals (Krupenye', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 1, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content=\"and Call, 2019; Povinelli and Preuss, 1995). This may be because ToM relies on structured relational knowledge \\n(e.g. agents can have goals; and agent X has goal G, but agent Y does not know that agent X has goal G). Models \\nthat work with social information and with humans will benefit from being able to reason about the mental states \\nand beliefs of agents. Finally, ToM tasks often involve inferential reasoning. For instance, for successful ToM \\nperformance, LLMs need to reason based on unobservable information (e.g. hidden mental states of agents) that \\nmust be inferred from context rather than parsed from the surface text (e.g. explicitly stated features of a \\nsituation). Hence, assessing and improving these models' proficiency in ToM tasks could offer valuable insights \\ninto their potential for a wider range of tasks that require inferential reasoning. \\nIn-context learning approaches can enhance the reasoning capacity of LLMs. Brown et al. (Brown et al., 2020)\", metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 2, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='showed that, for sufficiently large language models (+100B parameters), one can enhance models’ performance \\nusing only few-shot task demonstrations that are specified only through the input to the model (i.e. at inference \\ntime, without weight updates). This form of performance boosting is usually referred to as “few-shot learning”. \\nWei et al. (Wei et al., 2022) later showed that the ability of LLMs to perform complex reasoning was improved \\nwhen the few-shot examples in the prompt contain the reasoning steps for reaching a conclusion (“chain-of-\\nthought reasoning”) (Magister et al., 2022). Moreover, Kojima et al. (Kojima et al., 2022) showed that, even in \\nthe absence of exemplar demonstrations, instructing language models to think “step-by-step” enhances their \\nreasoning performance. There is not currently a theoretical understanding of why these prompting techniques \\nare beneficial, however some recent studies have explored the effects of compositional structure and local', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 2, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='dependencies in training data on efficacy of these methods (Hahn and Goyal, 2023; Prystawski and Goodman, \\n2023). \\nThe capability of LLMs to perform ToM reasoning is supported by some studies (Bubeck et al., 2023; Kosinski, \\n2023), but questioned by others (Sap et al., 2022; Trott et al., 2022; Ullman, 2023). Though this prior literature \\nprovides many insights into ToM in LLMs, the quantitative evaluations of ToM performance have two main \\nlimitations. First, they examine LLMs’ ToM performance only on single-word or multiple-option completion \\n(Kosinski, 2023; Sap et al., 2022; Trott et al., 2022; Ullman, 2023). However, LLMs may benefit from freely \\nproducing answers with multiple parts and speculating over multiple possibilities, rather than being assessed on \\na single word completion. Second, most of the work criticizing the ToM abilities of LLMs relied on either zero-\\nshot testing (Trott et al., 2022; Ullman, 2023) or provided examples that lacked step-by-step reasoning toward', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 2, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='an answer (Sap et al., 2022). Yet, the type of output generated by LLMs can be highly context-sensitive \\n(Sejnowski, 2023). Therefore, we asked whether recent LLMs might exhibit improved ToM performance when \\nprovided with suitable prompts. \\nHere we evaluate the performance of LLMs faced with ToM comprehension questions and we explore whether \\nthis performance can be boosted using prompting methods such as step-by-step thinking, few-shot learning, and \\nchain-of-thought reasoning (Brown et al., 2020; Kojima et al., 2022; Wei et al., 2022). Improving inferential \\nreasoning performance by prompting is important because it is a flexible approach that does not require \\nadditional training or large new datasets. Further, if effective prompting techniques guide LLMs towards \\ngenerating higher-quality ToM responses, this contributes to the overall reliability of their reasoning in wide-\\n   ranging everyday applications.', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 2, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='Methods \\nModels \\nWe studied the four most recent GPT models from the Open AI family. These were GPT-4 (OpenAI, 2023a) as \\nwell as the Davinci-2, Davinci-3, and GPT-3.5-Turbo models, which are considered GPT-3.5 variants that \\nimprove on GPT-3 (Brown et al., 2020; Ouyang et al., 2022). These are all large models (+100B parameters), \\nbut they differ in their training methods (OpenAI, 2023c). Davinci-2 (API name: text-davinci-002) is one of the \\nGPT-3.5 models which (in addition to the GPT-3 curricula) was also trained with supervised fine-tuning on \\nhuman-written demonstrations (OpenAI, 2023b; Stiennon et al., 2020). Davinci-3 (API name: text-davinci-003), \\nanother GPT-3.5 model, is an upgraded version of Davinci-2 which was further trained with Reinforcement \\nLearning from Human Feedback (RLHF) using Proximal Policy Optimization (OpenAI, 2023b; Ouyang et al., \\n2022; Stiennon et al., 2020). GPT-3.5-Turbo (the original version of ChatGPT) (OpenAI, 2023b) is yet another', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 3, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='GPT-3.5 model, trained with both fine-tuning on human-written demonstrations and RLHF, then further \\noptimized for conversation. GPT-4 is the most recent GPT model as of April 2023 (OpenAI, 2023a); there are \\nfew published details of the size and training methods for GPT-4, however, it appears to have undergone more \\nintensive training with RLHF for better alignment with human intention (OpenAI, 2023a). We tested all models \\nin a setting with temperature equal to 0.4 and the maximum length of generated text set to 150 tokens. \\n \\nExperimental Design \\nTo examine the comprehension ability of these models on ToM scenarios, we evaluated their comprehension \\naccuracy on both ToM scenarios and Control scenarios. The Control scenarios describe a scene (“Photo”) \\nwithout any agents. We refer to them as Photo scenarios (Supplement A). The ToM scenarios describe the mental \\nstate of people involved in a situation. We adapted 16 Photo scenarios and 16 ToM scenarios from stimulus sets', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 3, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='used in human fMRI to localize the brain areas involved in ToM (Dodell-Feder et al., 2011) (Supplement B). \\nThese scenarios match in their general difficulty; however, they differ in the need to reason based on individuals’ \\nstate of mind in the scenario. Human participants showed the same level of accuracy on both types of scenarios \\nin prior studies (Dodell-Feder et al., 2011), as well as in our behavioral experiment. In our human experiments, \\nparticipants were given 18 seconds to read each scenario. They were then asked a comprehension question about \\nthe scenario on a new screen and could answer at their own pace by clicking Yes or No. The Photo and ToM \\nscenarios were mixed and presented in random order so that each participant experienced both types of scenarios. \\nParticipants showed similar accuracy across Photo (86% ±4%) and ToM (87% ±4%) scenarios (see Supplement \\n C).  \\nA sample Photo Scenario (Control):', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 3, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='Scenario: \"A map shows the ground floor plan. A photocopy was sent to the architect yesterday, but at \\nthe time the kitchen door was missing. It was added to the map this morning.\"  \\nQuestion: Does the architect’s photocopy show the door? \\n \\nA sample ToM Scenario: \\nScenario: \"The morning of the high school dance Sarah placed her high heel shoes under her dress and \\nthen went shopping. That afternoon, her sister borrowed the shoes and later put them under Sarah\\'s \\nbed.\"  \\nQuestion: When Sarah gets ready, does she assume her shoes are under her dress?', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 3, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='Dependent Variable \\nWe measured the models’ accuracy in answering comprehension questions following the brief scenario. Since \\nLLMs are probabilistic models, we ran each prompt 20 times for every model, restarting the models for every \\nrepetition to ensure that the performance history of the models was not included, and to measure the reliability \\nof the model’s answers across re-initialization. Accuracy was defined as the proportion of correct responses \\n across 320 questions (16 scenarios x 20 repetitions). \\nTo evaluate the performance of each model, we analyzed their response to each prompt. To measure the accuracy \\nof each model, we manually checked all the LLM-generated responses and labeled them as correct or incorrect. \\nDue to the complexity of natural language, it was not always possible to label model output as correct or incorrect \\nbased on match to a template answer (e.g. “Yes” or “No”). We labeled an answer as correct if it had the correct', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 4, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='conclusion (see Examples 1-5 in “Correct responses” below) or if the model included the correct reasoning as \\none possibility amongst multiple reasonable responses (see Example 6 in “Correct responses” below). We \\nlabeled responses as incorrect if they arrived at an incorrect overall conclusion (see Examples 1-4 in “Incorrect \\nresponses” below) or if the responses were inconclusive (see Examples 5 and 6 in “Incorrect responses” below). \\n Below are the examples of correct and incorrect responses to a ToM comprehension question: \\nScenario:  \\n\"The morning of the high school dance Sarah placed her high heel shoes under her dress and then went \\nshopping. That afternoon, her sister borrowed the shoes and later put them under Sarah\\'s bed.\"  \\nQuestion:  \\nWhen Sarah gets ready, does she assume her shoes are under her dress?  \\n \\nCorrect Responses: \\n \\n- \\nExample 1: Sarah placed her shoes under her dress before she went shopping, but her sister borrowed', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 4, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content=\"them and put them under Sarah's bed. Sarah doesn't know that her sister borrowed her shoes, so she may \\nassume that they are still under her dress.  \\n \\n- \\nExample 2: Sarah placed her high heel shoes under her dress before going shopping, but her sister \\nborrowed the shoes and put them under Sarah's bed later. So, Sarah doesn't know that her sister borrowed \\nand returned the shoes. Therefore, the answer is: Yes, she assumes her shoes are under her dress. \\n \\n- \\nExample 3: Sarah may assume her shoes are still under her dress because that's where she placed them \\nin the morning. \\n \\n- \\nExample 4: Sarah placed her high heel shoes under her dress before she went shopping, so she knows \\nwhere she left them. Her sister borrowed the shoes and later put them under Sarah's bed, but Sarah \\ndoesn't know that yet. So, the answer is: Yes, Sarah assumes her shoes are under her dress unless she \\ndiscovers otherwise. \\n \\n-\", metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 4, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content=\"Example 5: In the morning, Sarah placed her high heel shoes under her dress. Later, her sister borrowed \\nthe shoes and put them under Sarah's bed. Therefore, when Sarah gets ready, she may assume her shoes \\nare still under her dress, but they are actually under her bed. \\n \\n- \\nExample 6: Based on this scenario, it is unclear whether Sarah assumes her shoes are under her dress \\nwhen she gets ready. It depends on whether her sister told her she borrowed them and put them under \\nthe bed.\", metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 4, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content=\"Incorrect Responses: \\n \\n- \\nExample 1: Sarah placed her shoes under her dress in the morning and then went shopping. Her sister \\nborrowed the shoes and put them under Sarah's bed. So, Sarah doesn't know that her shoes are under \\nher bed. So, the answer is: No, Sarah doesn't assume her shoes are under her dress. \\n \\n- \\nExample 2: No, Sarah does not assume her shoes are under her dress. \\n \\n- \\nExample 3: First, Sarah placed her high heel shoes under her dress in the morning. Then, her sister \\nborrowed the shoes and later put them under Sarah's bed. Therefore, Sarah would not assume her shoes \\nare under her dress as they were moved by her sister. \\n \\n- \\nExample 4: In the morning, Sarah placed her high heel shoes under her dress, but then went shopping. \\nThis means that when she returned home, she did not check if her shoes were still under her dress. Later, \\nher sister borrowed the shoes and put them under Sarah's bed. Therefore, Sarah cannot assume that her\", metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 5, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content=\"shoes are under her dress as they were moved by her sister. \\n \\n- \\nExample 5: It does not specify in the scenario whether or not Sarah assumes her shoes are under her \\ndress. \\n \\n- \\nExample 6: Sarah placed her high heel shoes under her dress in the morning. She then went shopping. \\nHer sister later borrowed the shoes and put them under Sarah's bed. Based on this information, it is \\nunclear if Sarah assumes her shoes are still under her dress when she gets ready for the dance. \\n  \\nExperimental Conditions \\nTo measure the efficacy of in-context learning (ICL) on ToM performance, we examined each scenario with \\nfour types of prompting: (1) Zero-shot (no ICL); (2) Zero-shot with step-by-step (SS) thinking; (3) Two-shot \\nchain-of-thought (CoT) reasoning; (4) Two-shot CoT reasoning with SS thinking. Below are the examples of \\n each prompting method (Figure 1).\", metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 5, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='Figure 1. Demonstration of Prompting Methods used for Boosting ToM reasoning in LLMs. Examples \\nof 4 prompting types used to test the ToM performance of LLMs. Each box provides an example of the input \\nto the model for a single trial in one condition. For each trial, all of the text shown after the word “Prompt:” \\nwas input to the model, including the final text line beginning with “A:”.', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 6, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='Results \\n \\nZero-shot Performance \\nWe first compared the models’ zero-shot performance on Photo and ToM scenarios. We found that accuracy in \\nPhoto scenarios gradually increased with the recency of the models, with lowest performance in Davinci-2 and \\nhighest in GPT-4 (Figure 2 A). However, in contrast to Photo comprehension, the accuracy on ToM questions \\ndid not monotonically improve with the recency of the models: Davinci-2 was more accurate than Davinci-3, \\nwhich was in turn more accurate than GPT-3.5-Turbo (Figure 2 B). Although the lower zero-shot ToM accuracy \\nin GPT-3.5-Turbo in comparison to Davinci-2 may seem to imply that the Turbo model’s reasoning performance \\nis inferior, the primary reason for its lower accuracy was its tendency to provide an inconclusive response. \\nSpecifically, it would often state that there was insufficient information to determine the answer to the question', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 7, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='(see examples 5-6 in “Incorrect responses” in Dependent Variable). However, more recent models were not \\nalways more equivocal in ToM responding: GPT-4 demonstrated a significantly greater ToM accuracy than all \\nother models (independent t-test between GPT-4 and Davinci-2: \\uf044Acc = 0.11, p-value <0.001) (Figure 2B). \\nOverall, GPT-4 showed the best zero-shot performance in both Photo and ToM scenarios (Figure 2 A and B). \\n \\n \\n \\nFigure 2. Zero-Shot Accuracy of LLMs in Photo (Control) and ToM Comprehension Questions. A) \\nZero-shot accuracy of LLMs in Photo scenarios (non-agentive) comprehension questions. B) Zero-shot \\naccuracy of LLMs in ToM comprehension questions. The values show the mean accuracy for each model \\naveraged over 320 measurements, as there are 16 scenarios of each type, and each scenario was tested 20 \\ntimes with re-initialization. For plotting the error bars, we treated each “repetition” as if it were a single', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 7, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='“participant” in the experiment. Therefore, we have 20 accuracy values, each averaged across 16 values from \\ndifferent ToM questions. The error bars then show the standard deviation of the 20 mean-accuracy values. \\n \\nPerformance when Supported by Prompting \\nIn-context learning via modified prompting boosted the ToM performance of all GPT models that were released \\n after Davinci-2 (Figure 3).  \\nFirst, we instructed the models to think step by step (SS). We found that SS thinking enhanced the performance \\nof Davinci-3, GPT-3.5-Turbo, and GPT-4 (e.g. independent t-test for zero-shot vs SS thinking for GPT-4: \\uf044Acc', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 7, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='= 0.10, p-value <0.001; zero-shot vs SS thinking for GPT-3.5-Turbo: \\uf044Acc = 0.06, p-value <0.001). However, \\n SS thinking did not improve the accuracy of Davinci-2 (Figure 3).  \\n \\n \\n \\nFigure 3. Effects of In-context Learning Prompts on ToM performance in LLMs. ToM performance of \\nmodels using various in-context learning methods. For each model, the gray bar on the far left shows the \\nZero-Shot baseline ToM performance. The next three bars (orange) show the ToM performance on Zero-\\nShot plus SS Thinking; Two-Shot CoT; and Two-Shot CoT plus SS Thinking. Error bars indicate the standard \\ndeviation across 20 repetitions (see Figure 2, caption). \\n \\nSecond, we tested prompting with Two-shot chain-of-thought (CoT) reasoning. We found that Two-shot CoT \\nincreased the accuracy of all models that were trained with RLHF (all models except Davinci-2) (Figure 3). For \\nGPT-3.5-Turbo, Two-shot CoT prompting significantly improved the performance above its zero-shot baseline', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 8, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='(\\uf044Acc = 0.25, p-value <0.001), and was significantly more effective than prompting with SS thinking (\\uf044Acc = \\n0.19, p-value <0.001). For Davinci-3 and GPT-4, prompting with Two-shot CoT was slightly more effective \\n than instructing step-by-step thinking. \\nJoint prompting with both Two-shot CoT reasoning and SS thinking produced the greatest increase in models’ \\naccuracy (Figure 3). ToM accuracy of all RLHF-trained models was significantly increased when the prompts \\nincluded Two-shot CoT reasoning and SS thinking: Accuracy of Davinci-3 was increased by 20% ± 6% (mean', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 8, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='± std) relative to its zero-shot baseline (p-value <0.001). Accuracy of GPT-3.5-Turbo was increased by 41% ± \\n5% relative to its zero-shot performance (p-value <0.001). Finally, accuracy of GPT-4 increased by 21% to reach \\n 100% accuracy (p-value <0.001, ceiling performance). \\nAltogether, appropriate prompting enabled all RLHF-trained models to achieve accuracy greater than 80%. \\nWhen appropriately prompted, Davinci-3 achieved ToM accuracy of 83% (±6%), GPT-3.5-Turbo achieved 91% \\n(±5%), and GPT-4 reached ceiling accuracy of 100%. Human performance in these scenarios was 87% (±4%) \\n  (See Supplement C). \\nInterim Discussion \\n Do the increases in ToM performance arise from copying the reasoning steps from the prompt? \\nThe improved performance of LLMs via prompting does not appear to be due to simple mimicry of the specific \\nreasoning steps provided in the chain-of-thought examples. The logic of reasoning in some scenarios was', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 9, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='different from the reasoning logic of the 2 chain-of-thought examples. Both the in-context examples had the \\nfollowing essential reasoning logic: Person P was not at location L when event E happened, so they are not \\naware of event E. Conversely, some of the scenarios required reasoning that event E happened when person P \\nwas not there, but when P arrives, they can see the result of event E. If the improved performance was only due \\nto copying a specific sort of reasoning it should not generalize across these distinct reasoning cases. To \\nunderscore this point, we performed the following analyses to test whether closely-related vs distantly-related \\n CoT examples produce similar performance increases.  \\nWe hypothesized that if the improved ToM performance is due to copying the reasoning steps from the in-\\ncontext ToM examples, then prompting with non-ToM examples should not enhance the ToM performance. To', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 9, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='test this hypothesis, it is necessary to exclude the ToM questions for which the models consistently provided \\naccurate zero-shot answers, because for such scenarios it is not possible to measure a performance increase. In \\nother words, we focused on the ToM questions that the models could not correctly answer in zero-shot. \\nFurthermore, we focused this analysis on Davinci-3 and GPT-3, because these models benefited from in-context \\nchain-of-thought ToM examples and (in contrast to GPT-3.5-Turbo) they almost always returned a definitive \\nresponse which did not require any subjective interpretation. Then for each model, we selected the scenarios that \\nthey could not correctly answer in zero-shot. This resulted in 4 scenarios for GPT-4 (mean zero-shot accuracy \\nof 0.16), and 6 scenarios in Davinci-3 (zero-shot accuracy of 0.0). We then tested the ToM accuracy of the model \\nfor these selected scenarios under the following conditions: (i) Two-shot ToM CoT examples; (ii) Two-shot', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 9, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='Non-ToM Inferential CoT examples; and (iii) Two-shot Photo CoT examples (Non-ToM Inferential examples; \\nand Photo examples are shown in Supplement D). In the Non-ToM Inferential examples, questions were not \\nabout false belief or an agent’s state of mind, but rather required inferential reasoning about the consequences \\n of an event. Photo examples were selected from scenarios that described a scene or situation without an agent.  \\nThe Davinci-3 and GPT-4 models experienced increases in ToM performance from all of the classes of CoT \\nexamples that we tested: Photo examples, Non-ToM Inferential examples, and ToM examples. The mean \\naccuracy increases for each model and each type of CoT example are shown in Figure 4, while the accuracy \\n changes for individual ToM questions are shown in Figure S.1.', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 9, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='Prompting with Inferential and Photo examples boosted the models’ performance on ToM scenarios even though \\nthese in-context examples did not follow the same reasoning pattern as the ToM scenarios. Therefore, our \\nanalysis suggests that the benefit of prompting for boosting ToM performance is not due to merely overfitting \\nto the specific set of reasoning steps shown in the CoT examples. Instead, the CoT examples appear to invoke a \\nmode of output that involves step-by-step reasoning, which improves the accuracy across a range of tasks. \\n \\n \\n \\nFigure 4. Effects of Various Types of CoT Examples on ToM Performance. The Y-axis represents the \\nchange in ToM accuracy compared to zero-shot (Two-shot CoT minus zero-shot), averaged across the \\nscenarios that each model answered incorrectly during zero-shot testing (4 scenarios for GPT-4 and 6 \\nscenarios for Davinci-3). The X-axis displays the types of in-context CoT examples provided to the model', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 10, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='for evaluating ToM performance. The values indicate the mean change in accuracy compared to zero-shot \\nfor the assessed scenarios. For GPT-4, error bars are the standard deviation across the 4 accuracy-change \\nvalues (1 value per scenario). For Davinci-3, error bars are the standard deviation across the 6 accuracy-\\nchange values. Refer to Figure S.1 for per-scenario accuracy results. \\n  \\nGeneral Discussion \\n \\nWe studied the performance of LLMs on comprehension tasks thought to require reasoning about an individual’s \\nstate of mind. We evaluated the performance of Davinci-2, Davinci-3, GPT-3.5-Turbo, and GPT-4. When \\ncomprehension tasks required reasoning about superficially observable information in brief text scenarios (Photo \\nscenarios), the zero-shot comprehension accuracy of LLMs increased monotonically from the oldest to newest \\nLLMs. At the same time, the zero-shot accuracy on ToM questions did not consistently improve with the recency', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 10, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='and sophistication of the models. However, with appropriate prompting, more recent models did exhibit \\nconsistent improvements in ToM performance. The prompt-improved performance approached or, in the case \\n of GPT-4, exceeded human ToM performance on our test set. \\nPrompts that allowed for in-context learning boosted the expression of ToM reasoning in LLMs, relative to the \\nzero-shot baseline. We used two recent prompting methods: step-by-step thinking (Kojima et al., 2022) and', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 10, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='chain-of-thought reasoning (Wei et al., 2022). We found that all models, except Davinci-2, were able to exploit \\nthe modified prompting for higher ToM accuracy. The models exhibited the greatest increase in accuracy when \\nthe prompts combined both chain of thought reasoning and step-by-step thinking, rather than employing either \\nalone. Also, the contrast between the performance of GPT-3.5-Trubo in zero-shot conditions and ICL conditions \\nis a reminder that measured performance may not always reflect competence (Firestone, 2020). When provided \\n with appropriate prompting, GPT-3.5-Turbo was capable of achieving higher performance than Davinci-2. \\nThe GPT-3.5 variants that we tested (Davinci-2, Davinci-3, and GPT-3.5-Turbo) are similar in size (~175 B \\nparameters) but differ in their training. In particular, Davinci-2 was the only model that was not finetuned with \\nRLHF, and it was also the only model whose ToM performance was not increased by our prompt manipulations.', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 11, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='It is possible that the RLHF component of the training enabled the models to exploit the in-context prompts in \\n this setting.  \\nLLMs may possess the capacity for performing ToM reasoning and yet not express this competence without the \\nappropriate context or prompting. When supported by chain-of-thought and step-by-step prompting, Davinci-3 \\nand GPT-3.5-Turbo exhibited ToM accuracy that was higher than GPT-4’s zero-shot ToM accuracy. These \\nresults are not consistent with the claim that these models lack ToM reasoning capability (Sap et al., 2022), and \\n they indicate the effectiveness of a prompting approach in enhancing LLM performance.  \\nModels may fail for different reasons. For instance, in zero-shot inference, we noticed that Davinci-2 was more \\naccurate than GPT-3.5 Turbo overall, but the models failed in different ways. When Davinci-2 answered a \\nquestion incorrectly, it tended to do so with high confidence, without speculating over other possibilities.', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 11, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='Conversely, GPT-3.5-Turbo’s errors in zero-shot inference usually arose because the model’s responses were \\nmore cautious: the model refrained from drawing confident conclusions and would frequently generate responses \\nsuch as there is not enough information in the scenario to answer this question. This property may arise from \\nGPT-3.5-Turbo’s training method which was intentionally designed to make the model more careful. Generating \\ninconclusive responses was also mentioned as one of the limitations of these models (OpenAI, 2022). Thus, the \\nfact that Davinci-2 exhibited greater zero-shot ToM accuracy than GPT-3.5-Turbo is not conclusive evidence \\nthat Davinci-2 is more capable at ToM reasoning. In fact, compared to GPT-3.5-Turbo, Davinci-2 produced \\nincorrect answers with higher confidence, made more error in linking one logical step to the next, and \\noccasionally confabulated (a class of errors called hallucinations in the machine learning literature). Therefore,', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 11, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='lower zero-shot performance of GPT-3.5-Turbo compared to Davinci-2 could be because GPT-3.5-Turbo has a \\n stylistic bias that prevents it from providing definitive answers in short scenarios requiring inference. \\nPrevious studies evaluating ToM performance in LLMs have primarily relied on single word completion or \\nmultiple-choice questions to measure their abilities (Kosinski, 2023; Sap et al., 2022; Trott et al., 2022; Ullman, \\n2023). However, this evaluation approach may not capture the sophistication of the ToM reasoning of which \\nLLMs are capable. ToM reasoning is a complex behavior, which, even in humans, can involve multiple steps. \\nTherefore, when responding to this challenging task, LLMs may benefit from producing longer-form answers. \\nThere are at least two reasons why LLMs may benefit in this way: \\nFirst, we may be able to more fairly evaluate the model output when it is longer. LLMs sometimes', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 11, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='generate the “correct” reasoning and then additionally mention other possibilities which lead it to arrive at an \\ninconclusive overall summary. In such cases, the LLM is demonstrating that it is capable of correctly performing \\nthe reasoning steps for the ToM question, even though its overall conclusion does not correspond to one of a \\nfixed set of options. Relatedly, the model might have a certain level of information regarding the potential results \\nof a situation, but it may not be sufficient for it to draw a correct conclusion. This can be compared to the concept', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 11, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content=\"that humans can still have some knowledge of an object's location despite having imperfect knowledge (Wu and \\nWolfe, 2018). Encouraging the model to systematically examine each piece of evidence and engage in a step-\\nby-step reasoning process could help solidify its partial evidence and enable it to arrive at a definitive response.  \\nSecond, LLMs may unlock enhanced (or new) reasoning abilities when provided with the opportunity \\nand the cues to elaborate a systematic step-by-step response. The improved ToM performance we observe is not \\nsimply a result of providing a number of in-context examples of ToM tasks (as in (Sap et al., 2022), where \\nperformance remained poor) but seems to rely on providing examples in which there is step-by-step inferential \\n reasoning from the evidence before arriving at a conclusion (Figure 3 and Figure 4). \\nThe LLMs may have seen some ToM or Photo scenarios during their training phase, but data leakage is unlikely\", metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 12, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='to affect our findings. First, our findings concern the change in performance arising from prompting, and the \\nspecific prompts used to obtain this performance change were novel materials generated for this study. Second, \\nif the model performance relied solely on prior exposure to the training data, there should be little difference \\nbetween zero-shot Photo and ToM performance (Figure 2), as these materials were published in the same \\ndocuments; however, the zero-shot performance patterns were very different across Photo and ToM scenarios. \\nThird, the LLM performance improvements arose when the models elaborated their reasoning step-by-step, and \\nthis elaborated reasoning was not part of the training data. Therefore, although some data leakage is possible, it \\n is unlikely to affect our conclusions concerning the benefits of prompting. \\nAn important avenue for further testing is whether the prompt-driven performance gains are specific to ToM', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 12, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='reasoning, or would be expected more generally in tasks involving other forms of inferential reasoning. Many \\nof the ToM questions require the model to infer facts (e.g. mental states) that are not explicitly stated in the \\nquestion, while (qualitatively speaking) it seems that many of the Control scenarios can be answered without \\nperforming as much inference beyond what is explicitly provided in the scenario text. Therefore, we are now \\ntesting LLMs comprehension in scenarios that require inferential reasoning but not reasoning about people’s \\nToM. Our preliminary results indicate (i) a similar pattern in zero-shot performance for ToM scenarios and non-\\nToM scenarios which require inferential reasoning; and (ii) an improvement in non-ToM performance when \\nincorporating the same prompts used for ToM scenarios (see Supplement E). Future research is needed to further \\nexplore the inferential reasoning capacity of LLMs as well as whether ToM inferences are a representative', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 12, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='example of a more general set of inferential capabilities in LLMs. \\nWe note four areas for improvement of this work. First, to evaluate ToM performance in our main analyses, we \\ntested the effects of CoT prompting using only 2 CoT example scenarios, and we tested only 16 ToM questions, \\nwhich were mostly probing agents’ beliefs. Future research could explore the effects of different number of CoT \\nexamples, using various types of CoT examples, and examine a more diverse set of ToM tasks (Ullman, 2023). \\nSecond, in GPT-3.5 models, sometimes the reasoning was correct, but the model could not integrate that \\nreasoning to draw the correct conclusion. Future research should extend the investigation of methods (such as \\nRLHF) that can help LLMs draw a correct conclusion given the prior reasoning steps. Third, in the current study, \\nwe did not quantitatively analyze the failure modes of each model. To address the limitations of LLMs and', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 12, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='further improve their reasoning capabilities, it is important to extend our understating of how and why different \\nmodels fail. Moreover, we observed significant variability in performance across scenarios (Figure S.1). \\nTherefore, measures of mean performance should be augmented by examination of failure modes and settings \\nwhich may be specific to particular types of reasoning or subcomponents of ToM (Burnell et al., 2023). Finally, \\nin the present study we manually scored the LLM responses. Because this form of labeling could be prone to', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 12, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='individuals’ interpretations, we are sharing the raw LLM outputs that were the basis of our findings (see Data \\n Availability).1 We await established benchmarks for evaluating complex reasoning and ToM behaviors in LLMs. \\nOur data do not speak to the question of whether LLMs possess a \"mental faculty\" that corresponds to a \\nstructured logical model of mental states. But our data do suggest that, when asking questions about ToM in \\nLLMs, it will not be fruitful to seek a simple yes/no answer. The variation in performance across prompts may \\nbe analogous to how human cognition can vary across task contexts and motivational states, and how humans \\ndraw on more than one type of thinking (Evans, 2003). In LLMs, it is clear that task contexts (i.e. prompts) affect \\nnot only bottom-line accuracy, but, more qualitatively, the model’s ability to invoke appropriate modes and \\n styles of responding.', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 13, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='Our results are practically significant because they show how to aid LLMs in some forms of social reasoning.  \\nMore abstractly, our results are another reminder that LLM behavior is highly complex and context sensitive. \\nTherefore, it will be important to characterize their cognitive abilities via nuanced investigations (Firestone, \\n2020; Mitchell and Krakauer, 2022; Sejnowski, 2023), rather than reflexively applying existing cognitive \\nontologies. Also, as we build and interact with increasingly powerful cognitive artifacts, it is crucial to stretch \\n  our imaginations about what they are capable of and how they work. \\nConclusion \\n \\nWe have shown that LLMs can exploit chain-of-thought reasoning and step-by-step thinking to substantially \\nimprove their ToM performance. Human-level performance in these ToM scenarios was 87% (± 4%). In contrast \\nto zero-shot ToM settings, where only GPT-4 reached near 80% accuracy, with appropriate prompting, all', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 13, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='RLHF-trained models exceeded 80% accuracy, with GPT-4 reaching ceiling accuracy (100%). Thus, appropriate \\n prompting enhances the ToM reasoning performance of these highly context-sensitive models. \\n \\n \\n1 Note that only a small portion of the data are edge cases which require subjective evaluation. A sample of edge case can be seen \\nin Example 6 in the Correct Responses section. Furthermore, Davinci-2, Davinci-3, and GPT-4 were generally able to deliver \\ndecisive outcomes. Most of these edge cases primarily originated from GPT-3.5-Turbo, which was apparently finetuned to exercise \\ncaution in its responses.', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 13, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='Acknowledgments  \\nThe authors gratefully acknowledge the support of the National Institutes of Mental Health (Grant \\nR01MH119099). We further thank members of the Firestone Lab at Johns Hopkins University for helpful \\nfeedback on earlier drafts of this paper. \\n \\nData Availability \\nThe data used in this study are available at the following GitHub repository: \\nhttps://github.com/shrahimim/Boosting-Theory-of-Mind-in-LLMs-with-Prompting \\n \\nReferences \\nBedny, M., Pascual-Leone, A., and Saxe, R. R. (2009). Growing up blind does not change the neural bases of \\nTheory of Mind. Proceedings of the National Academy of Sciences of the United States of America, 106(27), \\n11312–11317. https://doi.org/10.1073/pnas.0900010106 \\nBrown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., \\nAskell, A., Agarwal, S., Herbert-Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler, D. M.,', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 14, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='Wu, J., Winter, C., … Amodei, D. (2020). Language models are few-shot learners. Advances in Neural \\nInformation Processing Systems, 2020-Decem. \\nBubeck, S., Chandrasekaran, V., Eldan, R., Gehrke, J., Horvitz, E., Kamar, E., Lee, P., Lee, Y. T., Li, Y., Lundberg, \\nS., Nori, H., Palangi, H., Ribeiro, M. T., and Zhang, Y. (2023). Sparks of Artificial General Intelligence: \\nExperiments with an early version of GPT-4. \\nBurnell, R., Schellaert, W., Burden, J., Ullman, T. D., Martinez-Plumed, F., Tenenbaum, J. B., Rutar, D., Cheke, L. \\nG., Sohl-Dickstein, J., Mitchell, M., Kiela, D., Shanahan, M., Vorrhees, E. M., Cohn, A. G., Leibo, J. Z., and \\nHernandez-Orallo, J. (2023). Rethink reporting of evaluation results in AI. 380(6641), 8–11. \\nhttps://doi.org/10.1126/science.adf6369 \\nCuzzolin, F., Morelli, A., Cîrstea, B., and Sahakian, B. J. (2020). Knowing me, knowing you: Theory of mind in AI. \\nPsychological Medicine, 50(7), 1057–1061. https://doi.org/10.1017/S0033291720000835', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 14, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='Dodell-Feder, D., Koster-Hale, J., Bedny, M., and Saxe, R. (2011). FMRI item analysis in a theory of mind task. \\nNeuroImage, 55(2), 705–712. https://doi.org/10.1016/j.neuroimage.2010.12.040 \\nEvans, J. S. B. T. (2003). In two minds: Dual-process accounts of reasoning. Trends in Cognitive Sciences, 7(10), \\n454–459. https://doi.org/10.1016/j.tics.2003.08.012 \\nFirestone, C. (2020). Performance vs. competence in human–machine comparisons. Proceedings of the National \\nAcademy of Sciences of the United States of America, 117(43), 26562–26571. \\nhttps://doi.org/10.1073/pnas.1905334117 \\nHahn, M., and Goyal, N. (2023). A Theory of Emergent In-Context Learning as Implicit Structure Induction. \\nhttp://arxiv.org/abs/2303.07971 \\nHeyes, C. M., and Frith, C. D. (2014). The cultural evolution of mind reading. Science, 344(6190). \\nhttps://doi.org/10.1126/science.1243091', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 14, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='Kidd, D. C., and Castano, E. (2013). Reading literary fiction improves theory of mind. Science, 342(6156), 377–380. \\nhttps://doi.org/10.1126/science.1239918 \\nKojima, T., Gu, S. S., Reid, M., Matsuo, Y., and Iwasawa, Y. (2022). Large Language Models are Zero-Shot \\nReasoners. NeurIPS. http://arxiv.org/abs/2205.11916 \\nKosinski, M. (2023). Theory of Mind May Have Spontaneously Emerged in Large Language Models. ArXiv. \\nhttps://doi.org/https://doi.org/10.48550/arXiv.2302.02083 \\nKrupenye, C., and Call, J. (2019). Theory of mind in animals: Current and future directions. Wiley Interdisciplinary \\nReviews: Cognitive Science, 10(6), 1–25. https://doi.org/10.1002/wcs.1503 \\nLangley, C., Cirstea, B. I., Cuzzolin, F., and Sahakian, B. J. (2022). Theory of Mind and Preference Learning at the \\nInterface of Cognitive Science, Neuroscience, and AI: A Review. Frontiers in Artificial Intelligence, 5(April), \\n1–17. https://doi.org/10.3389/frai.2022.778852', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 15, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='Magister, L. C., Mallinson, J., Adamek, J., Malmi, E., and Severyn, A. (2022). Teaching Small Language Models to \\nReason. http://arxiv.org/abs/2212.08410 \\nMahowald, K., Ivanova, A. A., Blank, I. A., Kanwisher, N., Tenenbaum, J. B., and Fedorenko, E. (2023). \\nDissociating language and thought in large language models: a cognitive perspective. 2. \\nhttp://arxiv.org/abs/2301.06627 \\nMitchell, M., and Krakauer, D. C. (2022). The Debate Over Understanding in AI’s Large Language Models. 1–13. \\nhttp://arxiv.org/abs/2210.13966 \\nMoran, J. M., Young, L. L., Saxe, R., Lee, S. M., O’Young, D., Mavros, P. L., and Gabrieli, J. D. (2011). Impaired \\ntheory of mind for moral judgment in high-functioning autism. Proceedings of the National Academy of \\nSciences of the United States of America, 108(7), 2688–2692. https://doi.org/10.1073/pnas.1011734108 \\nOpenAI. (2022). Introducing ChatGPT. https://openai.com/blog/chatgpt \\nOpenAI. (2023a). GPT-4 Technical Report. 4, 1–100. http://arxiv.org/abs/2303.08774', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 15, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='OpenAI. (2023b). GPT Models Documentation. https://platform.openai.com/docs/models/overview \\nOpenAI. (2023c). Model index for researchers. https://platform.openai.com/docs/model-index-for-researchers \\nOuyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C. L., Mishkin, P., Zhang, C., Agarwal, S., Slama, K., Ray, \\nA., Schulman, J., Hilton, J., Kelton, F., Miller, L., Simens, M., Askell, A., Welinder, P., Christiano, P., Leike, \\nJ., and Lowe, R. (2022). Training language models to follow instructions with human feedback. \\nhttp://arxiv.org/abs/2203.02155 \\nPovinelli, D. J., and Preuss, T. M. (1995). Theory of mind: evolutionary history of a cognitive specialization. Trends \\nin Neurosciences, 18(9), 418–424. https://doi.org/10.1016/0166-2236(95)93939-U \\nPrystawski, B., and Goodman, N. D. (2023). Why think step-by-step? Reasoning emerges from the locality of \\nexperience. http://arxiv.org/abs/2304.03843', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 15, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='Rae, J. W., Borgeaud, S., Cai, T., Millican, K., Hoffmann, J., Song, F., Aslanides, J., Henderson, S., Ring, R., \\nYoung, S., Rutherford, E., Hennigan, T., Menick, J., Cassirer, A., Powell, R., Driessche, G. van den, \\nHendricks, L. A., Rauh, M., Huang, P.-S., … Irving, G. (2021). Scaling Language Models: Methods, Analysis \\n& Insights from Training Gopher. http://arxiv.org/abs/2112.11446 \\nSap, M., Le Bras, R., Fried, D., and Choi, Y. (2022). Neural Theory-of-Mind? On the Limits of Social Intelligence \\nin Large LMs. Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, \\nEMNLP 2022, 3762–3780. \\nSejnowski, T. J. (2023). Large Language Models and the Reverse Turing Test. Neural Computation, 35(3), 309–\\n342. https://doi.org/10.1162/neco_a_01563 \\nSeyfarth, R. M., and Cheney, D. L. (2013). Affiliation, empathy, and the origins of Theory of Mind. Proceedings of', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 15, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='the National Academy of Sciences of the United States of America, 110(SUPPL2), 10349–10356. \\nhttps://doi.org/10.1073/pnas.1301223110 \\nStiennon, N., Ouyang, L., Wu, J., Ziegler, D. M., Lowe, R., Voss, C., Radford, A., Amodei, D., and Christiano, P. \\n(2020). Learning to summarize from human feedback. Advances in Neural Information Processing Systems, \\n2020-Decem(NeurIPS), 1–14. \\nTrott, S., Jones, C., Chang, T., Michaelov, J., and Bergen, B. (2022). Do Large Language Models know what \\nhumans know? http://arxiv.org/abs/2209.01515 \\nUllman, T. (2023). Large Language Models Fail on Trivial Alterations to Theory-of-Mind Tasks. \\nhttp://arxiv.org/abs/2302.08399 \\nWei, J., Wang, X., Schuurmans, D., Bosma, M., Ichter, B., Xia, F., Chi, E., Le, Q., and Zhou, D. (2022). Chain-of-\\nThought Prompting Elicits Reasoning in Large Language Models. NeurIPS, 1–43. \\nhttp://arxiv.org/abs/2201.11903 \\nWu, C. C., and Wolfe, J. M. (2018). A New Multiple Object Awareness Paradigm Shows that Imperfect Knowledge', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 16, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='of Object Location Is Still Knowledge. Current Biology, 28(21), 3430-3434.e3. \\nhttps://doi.org/10.1016/j.cub.2018.08.042 \\nYoung, L., Cushman, F., Hauser, M., and Saxe, R. (2007). The neural basis of the interaction between theory of \\nmind and moral judgment. Proceedings of the National Academy of Sciences of the United States of America, \\n104(20), 8235–8240. https://doi.org/10.1073/pnas.0701408104', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 16, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='Supplementary Material: \\n \\nSupplement A \\n \\n 16 Photo scenarios  \\nThese scenarios are adapted and modified from (Dodell-Feder et al., 2011): \\n \\n1. \"The traffic camera snapped an image of the black car as it sped through the stoplight. Soon after, the \\ncar was painted red and the license plates were changed.\" Q: Does the traffic camera show that the car \\nis black? \\n \\n2. \"A map shows the ground floor plan. A photocopy was sent to the architect yesterday, but at the time \\nthe kitchen door was missing. It was added to the map this morning.\" Q: Does the architect’s photocopy \\nshow the door? \\n  \\n3. \"A photograph was taken of an apple hanging on a tree branch. The film took half an hour to develop. \\nIn the meantime, a strong wind blew the apple to the ground.\" Q: Does the developed photograph show \\nthe apple on the tree? \\n  \\n4. \"To detect intruders, the lab uses an automated system for recording voices. In the empty lab one night,', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 17, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='a computer error occurs and a synthetic voice reads the error message.\" Q: Is the number of people in \\nthe lab that night zero? \\n  \\n5. \"A popular attraction in the park, pictured on many souvenirs, was a cliff face covered with ancient \\npetroglyphs. Recently, the petroglyphs crumbled and scientists have not begun to restore them.\" Q: \\nToday, can the petroglyphs be seen in the park? \\n  \\n6. \"Sargent famously painted the south bank of the river in 1885. In 1910 a huge dam was built, flooding \\nout the whole river basin, killing the old forests. Now the whole area is under water.\" Q: In the painting, \\nis the south bank of the river wooded? \\n  \\n7. \"When the picture was taken of the house, it was one story tall. Since then, the renovators added an \\nadditional story and a garage.\" Q: Is the house currently one story? \\n  \\n8. \"Accounts of the country\\'s economic success were recorded in books from the early 1900s. Soon after,', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 17, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='a horrible plague hit the country, and the country was sent into an economic depression.\" Q: Do early \\n1900s novels portray the country as experiencing economic wealth? \\n  \\n9. \"Part of the garden is supposed to be reserved for the roses; it\\'s labeled accordingly. Recently the garden \\nhas run wild, and dandelions have taken over the entire flower bed.\" Q: Does the label say these flowers \\nare roses?', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 17, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='10. \"A long time ago, an explorer mapped a small island. Since then, the water levels rose and only a tiny \\npart of the island is now left above water.\" Q: On the explorer\\'s maps, does the island appear to be \\nmostly above water? \\n \\n11. \"A large oak tree stood in front of City Hall from the time the building was built. Last year the tree fell \\ndown and was replaced by a stone fountain.\" Q: Does an antique drawing of City Hall show a fountain \\nin front? \\n  \\n12. \"A volcano erupted on a Caribbean island three months ago. Barren lava rock is all that remains today. \\nSatellite photographs show the island as it was before the eruption.\" Q: Do satellite photographs show \\nthe island is covered in lava? \\n  \\n13. \"The family\\'s old video tape recorded the daughter\\'s first birthday party at their house in Chicago. Since \\nthen, the family sold their house and moved to San Francisco.\" Q: Does the video show the family living \\nin San Francisco?', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 18, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='14. \"At the time a portrait was drawn of a young man, he had short brown hair and no facial hair. Now the \\nman\\'s hair is long and gray and so is his beard.\" Q: Today, is the length of the man’s beard long? \\n  \\n15. \"The girl\\'s middle school pictures showed her wearing a white blouse. Later, a red sock was accidentally \\nwashed with the blouse and the blouse turned pink.\" Q: Was the color of the blouse in the pictures pink? \\n  \\n16. \"A small leaf was placed on a wet clay flower pot. When the pot was baked at high temperatures to \\nharden the clay, the leaf crumbled, but its impression remained.\" Q: Is the actual leaf intact?', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 18, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='Supplement B \\n  \\n 16 ToM scenarios & the scenarios used for in-context learning: \\n16 ToM scenarios are adapted and modified from (Dodell-Feder et al., 2011). \\n \\n1. \"The weather was so warm today that all the tulips in Pam\\'s backyard suddenly bloomed. The tulips \\nnext to Pam\\'s office still have not yet flowered, though. Pam has been at work all day.\" Q: When Pam \\nis driving home after work, does she assume her tulips have bloomed? A: \\n   \\n2. \"Susie parked her sports car in the driveway. In the middle of the night, Nathan moved her car into the \\ngarage to make room for his minivan. Susie woke up early in the morning.\" Q: When Susie wakes up, \\ndoes she see the minivan in the driveway? A: \\n  \\n3. \"The morning of the high school dance Sarah placed her high heel shoes under her dress and then went \\nshopping. That afternoon, her sister borrowed the shoes and later put them under Sarah\\'s bed.\" Q: When \\nSarah gets ready, does she assume her shoes are under her dress? A:', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 19, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='4. \"Sally and Greg called ahead of time to make a reservation for the back-country cabin. The park ranger \\nforgot to write down the reservation and two other hikers got to the cabin first.\" Q: When Sally and \\nGreg arrive, do they find their cabin unoccupied? A: \\n  \\n5. \"When Jeff got ready this morning, he put on a light pink shirt instead of a white one. Jeff is colorblind, \\nso he can\\'t tell the difference between subtle shades of color.\" Q: Does Jeff believe he is wearing a white \\nshirt? A: \\n  \\n6. \"Larry chose a debated topic for his class paper due on Friday. The news on Thursday indicated that the \\ndebate had been solved, but Larry never read it.\" Q: When Larry writes his paper, does he think the \\ndebate has been solved? A: \\n  \\n7. \"Every day Jill goes to the coffee shop on the corner and orders a latte, her favorite drink. Today, the \\ncashier misunderstands Jill and prepares a mocha instead.\" Q: Does Jill think her drink will taste like a \\nmocha? A:', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 19, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='8. \"Expecting the game to be postponed because of the rain, the Garcia family took the subway home. The \\nscore was tied, 3-3. During their commute the rain stopped, and the game soon ended with a score of 5-\\n3.\" Q: When the Garcia family arrives home, do they believe the score is 5-3? A: \\n  \\n9. \"Amy walked to work today. When George woke up, he saw her car in the drive. Her room was quiet \\nand dark. George knows that when Amy is sick, she lies down in a dark room.\" Q: Does George think \\nAmy is sick today? A:', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 19, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='10. \"John told Mary that he had lost his keys. The two of them searched the house with no luck. Then Mary \\nwent outside to look in the car. Suddenly John noticed his keys behind the sofa.\" Q: By the time Mary \\ncomes in, does John know where his keys are? A: \\n  \\n11. \"At night a bear broke into a cooler near a tent and drank the soda. Five hours later, the campers woke \\nup and went to their cooler for breakfast.\" Q: Do the campers find their cooler empty of soda? A: \\n \\n12. \"When Lisa left Jacob, he was deep asleep on the beach. A few minutes later a wave woke him. Seeing \\nLisa was gone, Jacob decided to go swimming.\" Q: Does Lisa now believe that Jacob is asleep? A: \\n  \\n13. \"Jenny put her chocolate away in the cupboard. Then she went outside. Alan moved the chocolate from \\nthe cupboard into the fridge. Half an hour later, Jenny came back inside.\" Q: Does Jenny expect to find \\nher chocolate in the cupboard? A:', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 20, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='14. \"A window wiper was commissioned by a CEO to wipe an entire building. He finished the right side, \\nbut his platform broke before he could do the left side. The next morning the CEO arrived with foreign \\ninvestors.\" Q: When the CEO comes to work, do they discover that all of the windows are cleaned? A: \\n  \\n15. \"Hopeful to catch a prize fish, George went fishing. That afternoon, he saw his fishing line bend over \\nas if he had caught a big fish. Actually, George’s fishing pole had snagged a small tire.\" Q: At the end \\nof the fishing line, does George see a fish? A: \\n   \\n16. \"Laura didn\\'t have time to braid her horse’s mane before going to camp. While she was at camp, William \\nbrushed Laura\\'s horse and braided the horse’s mane for her.\" Q: When Laura is at camp, does she assume \\nthat her horse\\'s hair is braided? A: \\n   \\n  The scenarios used in the chain-of-thought reasoning examples: \\nExample 1:', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 20, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='\"Anne made lasagna in the blue dish. After Anne left, Ian came home and ate the lasagna. Then he filled \\nthe blue dish with spaghetti and replaced it in the fridge.\"  \\nQ: Does Anne think the blue dish contains spaghetti?  \\nA: When Anne left, the blue dish contained lasagna. Ian came after Anne had left and replaced lasagna \\nwith spaghetti, but Anne doesn\\'t know that because she was not there. So, the answer is: No, she doesn\\'t \\nthink the blue dish contains spaghetti. \\n  \\nExample 2: \\n\"The girls left ice cream in the freezer before they went to sleep. Over night the power to the kitchen \\nwas cut and the ice cream melted.\"  \\nQ: When they get up, do the girls believe the ice cream is melted?  \\nA: The girls put the ice cream in the freezer and went to sleep. So, they don\\'t know that the power to the \\nkitchen was cut and the ice cream melted. So, the answer is: No, the girls don\\'t believe the ice cream is \\nmelted.', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 20, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='Supplement C \\nToM accuracy of human participants  \\nTo measure humans’ performance in ToM and Photo scenarios, we recruited 125 online participants through the \\nQualtrics platform. Participants were 18 to 65 years old, native English speakers, and located in the United States.  \\nParticipants had 18 seconds to read each scenario. Once the 18-second duration was over, they were immediately \\ndirected to a new screen showing the comprehension question. They could respond to the questions at their own \\npace by clicking on one of the two options (Yes/No). The Photo scenarios and ToM scenarios were interleaved \\nand randomized such that each participant experienced both types of scenarios. \\nThe Photo and ToM scenarios were of comparable difficulty for human participants. Participants showed similar \\naccuracy across Photo (86% ±4%) and ToM (87% ±4%) scenarios. \\nFrom these data we conclude that: \\ni) \\nthe Photo scenarios are a good control condition for the ToM scenarios, because of their', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 21, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='matched performance in humans. \\nii) \\nthe scenarios are relatively easy for humans to solve, but not so easy that humans are at ceiling \\nperformance (given the modest incentives for accuracy in online participants). \\nMaking a direct quantitative comparison between human and LLM performance is not warranted, because of the \\nmany differences in the testing conditions. However, the human performance does indicate that the questions \\nare sufficiently difficult that humans occasionally (>10% of the time) make errors, perhaps because they \\noverlook details in the scenario or because they make unusual assumptions or inferences.', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 21, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='Supplement D \\n Effects of Various In-context Examples on ToM Performance of LLMs \\nWe tested the efficacy of Photo examples, Non-ToM Inferential examples, and ToM examples in enhancing \\n ToM performance when providing chain-of-thought prompts. We used the following examples in each class: \\n1) Photo Chain-of-Thought Examples: \\nExample 1: \\nScenario: \"A long time ago, an explorer mapped a small island. Since then, the water levels rose and \\nonly a tiny part of the island is now left above water.\"  \\nQ: On the explorer\\'s maps, does the island appear to be mostly above water? \\nA: An explorer mapped an island a long time ago. Then water levels rose. Now only a tiny part of the \\nisland is above water. The maps show the island before water levels rose. Therefore, in the map most of \\nthe island is above water. So, the answer is: Yes, in the maps, most of the island is above the water. \\nExample 2: \\nScenario: \"A volcano erupted on a Caribbean island three months ago. Barren lava rock is all that', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 22, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='remains today. Satellite photographs show the island as it was before the eruption.\"  \\nQ: Do satellite photographs show the island is covered in lava? \\nA: A volcano erupted three months ago and as a result lava rock is all that remains today. Since the \\nphotograph shows the island before the eruptions, it does not show the island covered in Laval. So, the \\nanswer is: No, the photographs does not show the island covered in lava. \\n \\n2) Non-ToM Inferential Chain-of-Thought Examples: \\nExample 1: \\nScenario: \"Sarah was excited to show off her new dress at the party. As she walked in, she noticed that \\nanother girl was wearing the exact same dress. She quickly went back home to change and then returned \\nto the party.\"  \\nQ: Did Sarah wear her favorite dress the whole night? \\nA: Sarah was excited about her new dress and wanted to wear it as the party. But since another girl was \\nwearing the same dress, she went home and changed to a different dress. So, the answer is: No, she did', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 22, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='not wear her favorite dress the whole night. \\nExample 2: \\nScenario: \"Lucy was in a hurry to get to work, so she quickly grabbed her lunch from the fridge and left \\nthe house. At lunchtime, she opened her lunchbox and realized she had accidentally taken her \\nroommate\\'s lunch.\" \\nQ: Will Lucy\\'s roommate have her own lunch to eat that day? \\nA: Lucy was in hurry and mistakenly grabbed her roommate lunch. So, her roommate’s lunch is now \\nwith Lucy. So, the answer is: No, Lucy\\'s roommate will not have her own lunch to eat that day. \\n \\n3) ToM Chain-of-Thought Examples: \\nExample 1: \\nScenario: \"Anne made lasagna in the blue dish. After Anne left, Ian came home and ate the lasagna. \\nThen he filled the blue dish with spaghetti and replaced it in the fridge.\"  \\nQ: Does Anne think the blue dish contains spaghetti?', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 22, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='A: When Anne left the blue dish contained lasagna. Ian came after Anne had left and replaced lasagna \\nwith spaghetti, but Anne doesn\\'t know that because she was not there. So, the answer is: No, she doesn\\'t \\nthink the blue dish contains spaghetti.  \\nExample 2: \\nScenario: \"The girls left ice cream in the freezer before they went to sleep. Over night the power to the \\nkitchen was cut and the ice cream melted.\"  \\nQ: When they get up, do the girls believe the ice cream is melted?  \\nA: The girls put the ice cream in the freezer and went to sleep. So, they don\\'t know that the power to the \\nkitchen was cut and the ice cream melted. So, the answer is: No, the girls don\\'t believe the ice cream is \\nmelted. \\n  \\n GPT-4 \\nFor this analysis, the performance of GPT-4 was assessed on the 4 scenarios below. These are scenarios that \\n GPT-4 answered incorrectly in zero-shot testing. \\nScenario 1: \\n\"Amy walked to work today. When George woke up, he saw her car in the drive. Her room was quiet', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 23, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='and dark. George knows that when Amy is sick, she lies down in a dark room.\" \\nQ: Does George think Amy is sick today? \\n \\nScenario 2: \\n\"When Lisa left Jacob, he was deep asleep on the beach. A few minutes later a wave woke him. Seeing \\nLisa was gone, Jacob decided to go swimming.\"  \\nQ: Does Lisa now believe that Jacob is asleep? \\n \\nScenario 3: \\n\"The weather was so warm today that all the tulips in Pam\\'s backyard suddenly bloomed. The tulips \\nnext to Pam\\'s office still have not yet flowered, though. Pam has been at work all day.\"  \\nQ: When Pam is driving home after work, does she assume her tulips have bloomed? \\n \\nScenario 4: \\n\"Every day Jill goes to the coffee shop on the corner and orders a latte, her favorite drink. Today, the \\ncashier misunderstands Jill and prepares a mocha instead.\" \\nQ: Does Jill think her drink will taste like a mocha? \\n  \\n Davinci-3 \\nFor this analysis, the performance of Davinci-3 was assessed on the 6 scenarios below. These are scenarios that', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 23, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='Davinci-3 answered incorrectly in zero-shot testing.  \\nScenario 1) \\n\"Susie parked her sports car in the driveway. In the middle of the night, Nathan moved her car into the \\ngarage to make room for his minivan. Susie woke up early in the morning.\"', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 23, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='Q: When Susie wakes up, does she see the minivan in the driveway? \\n \\nScenario 2) \\n\"When Jeff got ready this morning, he put on a light pink shirt instead of a white one. Jeff is colorblind, \\nso he can\\'t tell the difference between subtle shades of color.\"  \\nQ: Does Jeff believe he is wearing a white shirt? \\n \\nScenario 3) \\n\"When Lisa left Jacob, he was deep asleep on the beach. A few minutes later a wave woke him. Seeing \\nLisa was gone, Jacob decided to go swimming.\"  \\nQ: Does Lisa now believe that Jacob is asleep? \\n \\nScenario 4) \\n\"Laura didn\\'t have time to braid her horse’s mane before going to camp. While she was at camp, William \\nbrushed Laura\\'s horse and braided the horse’s mane for her.\"  \\nQ: When Laura is at camp, does she assume that her horse\\'s hair is braided? \\n \\nScenario 5) \\n\"The morning of the high school dance Sarah placed her high heel shoes under her dress and then went \\nshopping. That afternoon, her sister borrowed the shoes and later put them under Sarah\\'s bed.\"', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 24, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='Q: When Sarah gets ready, does she assume her shoes are under her dress? \\n \\nScenario 6) \\n\"Jenny put her chocolate away in the cupboard. Then she went outside. Alan moved the chocolate from \\nthe cupboard into the fridge. Half an hour later, Jenny came back inside.\" \\nQ: Does Jenny expect to find her chocolate in the cupboard? \\n   \\n Per-scenario accuracies are shown in Figure S.1. The mean accuracy for this analysis is shown in Figure 4.', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 24, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='Figure S.1. Per-Scenario Accuracy using 4 prompting conditions in GPT-4 and Davinci-3. For each \\ncondition (e.g. Inferential CoT), the per-scenario accuracy is calculated based on the mean accuracy across \\n20 repetitions of a single prompt.', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 25, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='Supplement E \\n Generalizability of ToM Results to Inferential Reasoning in Non-ToM Scenarios \\nTo investigate the generalizability of our prompting methods, we designed and tested a set of scenarios that \\nrequired inferential reasoning, but which were not false-belief scenarios. In these new scenarios, the reasoning \\ndoes not follow the same steps as in the false-belief scenarios (e.g. person P does not know about event E, etc). \\nTherefore, the specific reasoning steps used in the in-context ToM CoT examples cannot be directly transferred \\nto these non-ToM scenarios. We created and tested the following non-ToM scenarios: \\n1. \"Anna was baking cookies for her friends. She realized she was out of sugar and went to the store to \\nbuy some. While she was gone, her dog, Max, jumped on the counter and ate the cookie dough.\" Q: \\nWill Anna be able to finish making cookies after returning?', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 26, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='2. \"Lisa was running late for work, so she quickly grabbed her lunch out of the fridge and left the house. \\nSeeing Lisa leaving the house, her cat knocked over her coffee mug on the kitchen counter.\" Q: Will \\nLisa find the kitchen counter clean when she returns? \\n \\n3. \"Lucy was in a hurry to get to work, so she quickly grabbed her lunch from the fridge and left the house. \\nAt lunchtime, she opened her lunchbox and realized she had accidentally taken her roommate\\'s lunch.\" \\nQ: Will Lucy\\'s roommate have her own lunch to eat that day? \\n \\n4. \"Lucy was baking a cake for her friend\\'s birthday. She put the cake in the oven and set a 20-minute \\ntimer. She then went to the living room to watch her favorite show for 30 minutes.\" Q: Will the cake be \\novercooked by the time Lucy checks the oven? \\n \\n5. \"Tim and Amy went on a hike through the forest. After walking for several hours, they came across a', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 26, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='bear. They quickly and quietly backed away, retracing their steps back to the starting point.\" Q: Did \\nTim and Amy finish their hike? \\n \\n6. \"Sarah was excited to show off her new dress at the party. As she walked in, she noticed that another \\ngirl was wearing the exact same dress. She quickly went back home to change and then returned to the \\nparty.\" Q: Did Sarah wear her favorite dress the whole night? \\n \\n7. \"During a thunderstorm, Sarah closed all the windows in her house. She then went to the basement to \\ndo laundry. While she was downstairs, a tree branch fell and broke one of the windows upstairs.\" Q: \\nWhen Sarah finishes the laundry, does she find all the windows closed? \\n \\n8. \"Lucy spent hours preparing a delicious meal for her husband\\'s surprise birthday party. Just as she was \\nsetting the table, she accidentally knocked over a glass of red wine, spilling it all over the food. She \\nordered pizza as a last-minute replacement.\" Q: Does Lucy serve her homemade meal to the guests?', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 26, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='We tested two conditions: (1) The zero-shot performance of the LLMs in these new scenarios; (2) The efficacy \\nof the same prompts, Two-shot chain-of-thought ToM examples plus step-by-step thinking, for these new set of \\n non-ToM scenarios. \\nWe found a similar pattern between the performance in the non-ToM scenarios and the ToM scenarios (Figure \\nS.2): First, similar to results from Figure 2B, the zero-shot accuracy dropped from Davinci-2 to Davinci-3, and \\nfrom Davinci-3 to GPT-3.5-Turbo2, while GPT-4 showed the highest accuracy, reaching ceiling performance. \\nSecond, similar to the results from Figure 3, we found that prompting significantly boosted the ToM accuracy \\nfor Davinci-3 and GPT-3.5-Turbo, while it did not improve the accuracy of Davinci-2. The performance of GPT-\\n4 was at ceiling in the zero-shot setting, so there was no room for benefit from prompting. Thus, this preliminary', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 27, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='analysis indicates that the performance gains from prompting are not limited to inferential ToM tasks, but may \\n extend to other inferential tasks.  \\nThis result is notable for two reasons: (i) The reasoning steps for the chain-of-thought examples (which were \\nToM examples) were different from the reasoning steps required to answer the questions (which were non-ToM \\nexamples). Therefore, these performance increases are not merely due to copying the specific reasoning steps in \\ndemonstrated in the prompt. (ii) These questions do not ask about an agent’s state of the mind, but instead require \\ninference about a particular situation. Therefore, it is possible that our primary findings concerning ToM may \\n  generalize to a broader class of inferential reasoning tasks. \\n \\n \\n \\nFigure S.2. Accuracy of LLMs in Non-ToM Scenarios. Accuracy of Davinci-2, Davinci-3, GPT-3.5-\\nTurbo, and GPT-4 in new scenarios that do not involve reasoning about agents’ beliefs. The gray bars (left', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 27, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''}), Document(page_content='bars) show the zero-shot performance. The orange bars (right bars) show the performance with prompts that \\nallow for in-context learning (ICL). The ICL prompt includes both Two-shot CoT plus instructing step-by \\nstep thinking. The accuracy is the mean of 160 values (8 scenarios x 20 repetitions each). The error bars show \\nthe standard deviation of the accuracy over 8 scenarios for each of 20 repetitions (standard deviation across \\n20 values, each a mean of 8 scenarios). \\n \\n \\n \\n2 Data from GPT-3.5-Turbo for this particular analysis was collected before it was possible to control the temperature parameter at \\ninference time using the OpenAI API. Therefore, for this particular analysis, the temperature parameter for GPT-3.5-Turbo was the \\ndefault value (likely 0.7), whereas for the other three models the temperature was set to 0.4.', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf', 'page_number': 27, 'total_pages': 27, 'format': 'PDF 1.7', 'title': '', 'author': 'Shima Rahimi Moghaddam', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20230426034952+00'00'\", 'modDate': \"D:20230426034952+00'00'\", 'trapped': ''})]\n"
     ]
    }
   ],
   "source": [
    "# Document splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "print(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='Generative Agents: Interactive Simulacra of Human Behavior\\nJoon Sung Park\\nStanford University\\nStanford, USA\\njoonspk@stanford.edu\\nJoseph C. O’Brien\\nStanford University\\nStanford, USA\\njobrien3@stanford.edu\\nCarrie J. Cai\\nGoogle Research\\nMountain View, CA, USA\\ncjcai@google.com\\nMeredith Ringel Morris\\nGoogle Research\\nSeattle, WA, USA\\nmerrie@google.com\\nPercy Liang\\nStanford University\\nStanford, USA\\npliang@cs.stanford.edu\\nMichael S. Bernstein\\nStanford University\\nStanford, USA\\nmsb@cs.stanford.edu\\nFigure 1: Generative agents create believable simulacra of human behavior for interactive applications. In this work, we demon-\\nstrate generative agents by populating a sandbox environment, reminiscent of The Sims, with twenty-five agents. Users can\\nobserve and intervene as agents they plan their days, share news, form relationships, and coordinate group activities.\\nABSTRACT\\nBelievable proxies of human behavior can empower interactive\\napplications ranging from immersive environments to rehearsal', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 1, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='spaces for interpersonal communication to prototyping tools. In\\nthis paper, we introduce generative agents—computational software\\nPermission to make digital or hard copies of all or part of this work for personal or\\nclassroom use is granted without fee provided that copies are not made or distributed\\nfor profit or commercial advantage and that copies bear this notice and the full citation\\non the first page. Copyrights for components of this work owned by others than the\\nauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or\\nrepublish, to post on servers or to redistribute to lists, requires prior specific permission\\nand/or a fee. Request permissions from permissions@acm.org.\\narXiv, April, 2023,\\n© 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.\\nACM ISBN xx-x-xxxx-xxxx-x/xx/xx...$15.00\\nhttps://doi.org/xx.xx/xx.xx\\nagents that simulate believable human behavior. Generative agents', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 1, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='wake up, cook breakfast, and head to work; artists paint, while\\nauthors write; they form opinions, notice each other, and initiate\\nconversations; they remember and reflect on days past as they plan\\nthe next day. To enable generative agents, we describe an architec-\\nture that extends a large language model to store a complete record\\nof the agent’s experiences using natural language, synthesize those\\nmemories over time into higher-level reflections, and retrieve them\\ndynamically to plan behavior. We instantiate generative agents\\nto populate an interactive sandbox environment inspired by The\\nSims, where end users can interact with a small town of twenty five\\nagents using natural language. In an evaluation, these generative\\nagents produce believable individual and emergent social behav-\\niors: for example, starting with only a single user-specified notion\\narXiv:2304.03442v1  [cs.HC]  7 Apr 2023', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 1, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='arXiv, April, 2023,\\nJ.S. Park, J.C. O’Brien, C.J. Cai, M. Morris, P. Liang, M.S. Bernstein\\nthat one agent wants to throw a Valentine’s Day party, the agents\\nautonomously spread invitations to the party over the next two\\ndays, make new acquaintances, ask each other out on dates to the\\nparty, and coordinate to show up for the party together at the right\\ntime. We demonstrate through ablation that the components of\\nour agent architecture—observation, planning, and reflection—each\\ncontribute critically to the believability of agent behavior. By fusing\\nlarge language models with computational, interactive agents, this\\nwork introduces architectural and interaction patterns for enabling\\nbelievable simulations of human behavior.\\nCCS CONCEPTS\\n• Human-centered computing → Interactive systems and tools;\\n• Computing methodologies → Natural language processing.\\nKEYWORDS\\nHuman-AI Interaction, agents, generative AI, large language models\\nACM Reference Format:', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 2, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='Joon Sung Park, Joseph C. O’Brien, Carrie J. Cai, Meredith Ringel Morris,\\nPercy Liang, and Michael S. Bernstein. 2023. Generative Agents: Interactive\\nSimulacra of Human Behavior. In . ACM, New York, NY, USA, 22 pages.\\nhttps://doi.org/xx.xx/xx.xx\\n1\\nINTRODUCTION\\nHow might we craft an interactive artificial society that reflects\\nbelievable human behavior? From sandbox games such as The Sims\\nto applications such as cognitive models [21] and virtual environ-\\nments [9, 58], for over four decades researchers and practitioners\\nhave envisioned computational agents that can serve as believ-\\nable proxies of human behavior. In these visions, computationally-\\npowered agents act consistently with their past experiences and\\nreact believably to their environments. Such simulations of human\\nbehavior could populate virtual spaces and communities with real-\\nistic social phenomena [26, 79], train people how to handle rare yet\\ndifficult interpersonal situations [43, 51, 93], test social science theo-', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 2, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='ries [11, 45], craft model human processors for theory and usability\\ntesting [21, 38, 50], power ubiquitous computing applications [30]\\nand social robots [9, 13], and underpin non-playable game charac-\\nters [58, 84] that can navigate complex human relationships in an\\nopen world.\\nHowever, the space of human behavior is vast and complex [84,\\n108]. Despite striking progress in large language models [17] that\\ncan simulate believable human behavior at a single time point [38,\\n79], fully general agents that ensure long-term coherence would\\nbe better suited by architectures that manage constantly-growing\\nmemories as new interactions, conflicts, and events arise and fade\\nover time, while handling cascading social dynamics that unfold\\nbetween multiple agents. Success requires an approach that can\\nretrieve relevant events and interactions over a long period, reflect\\non those memories to generalize and draw higher-level inferences,\\nand apply that reasoning to create plans and reactions that both', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 2, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='make sense in the moment and in the longer-term arc of the agent’s\\nbehavior.\\nIn this paper, we introduce generative agents—agents that draw\\non generative models to simulate believable human behavior—and\\ndemonstrate that they produce believable simulacra of both in-\\ndividual and emergent group behavior. Generative agents draw\\na wide variety of inferences about themselves, other agents, and\\ntheir environment; they create daily plans that reflect their char-\\nacteristics and experiences, act out those plans, react, and re-plan\\nwhen appropriate; they respond when the end user changes their\\nenvironment or commands them in natural language. For instance,\\ngenerative agents turn off the stove when they see that their break-\\nfast is burning, wait outside the bathroom if it is occupied, and\\nstop to chat when they meet another agent they want to talk to.\\nA society full of generative agents is marked by emergent social\\ndynamics where new relationships are formed, information diffuses,', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 2, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='and coordination arises across agents.\\nTo enable generative agents, we describe an agent architecture\\nthat stores, synthesizes, and applies relevant memories to generate\\nbelievable behavior using a large language model. Our architecture\\ncomprises three main components. The first is the memory stream,\\na long-term memory module that records, in natural language, a\\ncomprehensive list of the agent’s experiences. The retrieval model\\ncombines relevance, recency, and importance to surface the records\\nthat are needed to inform the agent’s moment-to-moment behavior.\\nThe second is reflection, which synthesizes memories into higher-\\nlevel inferences over time, enabling the agent to draw conclusions\\nabout itself and others to better guide its behavior. The third is\\nplanning, which translates those conclusions and the current en-\\nvironment into high-level action plans and then recursively into\\ndetailed behaviors for action and reaction. These reflections and', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 2, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='plans are fed back into the memory stream to influence the agent’s\\nfuture behavior.\\nThis architecture suggests applications in multiple domains, from\\nrole-play and social prototyping, to virtual worlds and games. In\\nsocial role-play scenarios (e.g. interview preparation), a user could\\nsafely rehearse difficult, conflict-laden conversations. When pro-\\ntotyping social platforms, a designer could go beyond temporary\\npersonas to prototype dynamic, complex interactions that unfold\\nover time. For the purposes of this paper, we focus on the ability to\\ncreate a small, interactive society of agents inspired by games such\\nas The Sims.1 By connecting our architecture to the ChatGPT large\\nlanguage model [76], we manifest a small society of twenty five\\nagents in a game environment. End users can observe and interact\\nwith these agents. If an end user or developer wanted the town\\nto host an in-game Valentine’s Day party, for example, traditional', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 2, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='game environments would require scripting tens of characters’ be-\\nhavior manually. We demonstrate that, with generative agents, it\\nis sufficient to simply tell one agent that she wants to throw a\\nparty. Despite many potential points of failure—the party planner\\nmust remember to tell other agents about the party, attendees must\\nremember the invitation, those who remember must decide to ac-\\ntually show up, and other possible points of failure—agents in our\\nenvironment succeed. They spread the word about the party and\\nthen show up, with one agent even asking another agent on a date\\nto the party, all from this single user-generated seed suggestion.\\nWe conducted two evaluations of generative agents: a controlled\\nevaluation to test whether the agents produce believable individual\\n1A demonstration of an actual simulation of the generative agent society can be viewed\\nat the following link: https://reverie.herokuapp.com/arXiv_Demo/', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 2, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='Generative Agents\\narXiv, April, 2023,\\nbehaviors in isolation, and an end-to-end evaluation where the\\ngenerative agents interacted with each other in open-ended ways\\nover two days of game time to understand their stability and emer-\\ngent social behaviors. In the technical evaluation, we leverage a\\nmethodological opportunity to evaluate an agent’s knowledge and\\nbehavior by “interviewing” it in natural language to probe agents’\\nability to stay in character, remember, plan, react, and reflect accu-\\nrately. We compared several ablations that limit agents’ access to\\nmemory, reflection, and planning. We observe that each of these\\ncomponents is critical to strong performance across these inter-\\nview tasks. Across the technical and the end-to-end evaluation, the\\nmost common errors arose when the agent failed to retrieve rele-\\nvant memories, fabricated embellishments to the agent’s memory,\\nor inherited overly formal speech or behavior from the language\\nmodel.', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 3, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='In sum, this paper provides the following contributions:\\n• Generative agents, believable simulacra of human behavior\\nthat are dynamically conditioned on agents’ changing expe-\\nriences and environment.\\n• A novel architecture that makes it possible for generative\\nagents to remember, retrieve, reflect, interact with other\\nagents, and plan through dynamically evolving circumstances.\\nThe architecture leverages the powerful prompting capabili-\\nties of large language models and supplements those capa-\\nbilities to support longer-term agent coherence, the ability\\nto manage dynamically-evolving memory, and recursively\\nproduce more generations.\\n• Two evaluations (a controlled evaluation and end-to-end\\nevaluation) that establish causal effects of the importance\\nof components of the architecture, as well as identify break-\\ndowns arising from, e.g., improper memory retrieval.\\n• Discussion of the opportunities and ethical and societal risks\\nof generative agents in interactive systems. We argue that', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 3, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='these agents should be tuned to mitigate the risk of users\\nforming parasocial relationships, logged to mitigate risks\\nstemming from deepfakes and tailored persuasion, and ap-\\nplied in ways that complement rather than replace human\\nstakeholders in design processes.\\n2\\nRELATED WORK\\nIn this section, we reflect on the prior literature in human-AI in-\\nteraction and situate within its canon the agenda of building be-\\nlievable proxies of human behavior. This agenda, once hailed as a\\nnorth star in interaction, game, and artificial intelligence communi-\\nties [9, 58, 84, 85], has remained challenging due to the complexity\\nof human behavior [16, 108]. We synthesize this research to suggest\\nthat large language models, though not sufficient by themselves,\\nopen up a new angle for creating believable agents when leveraged\\nusing the appropriate architecture.\\n2.1\\nHuman-AI Interaction\\nInteractive artificial intelligence systems aim to combine human in-', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 3, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='sights and capabilities in computational artifacts that can augment\\ntheir users [3, 29]. A long line of work has explored ways to allow\\nusers to interactively specify model behavior. For instance, Crayons\\ndemonstrated an early vision of interactive machine learning, allow-\\ning non-expert users to train classifiers [29]. Further work helped to\\narticulate how end users might describe their classification goals to\\nthe system through examples [33] and/or demonstration [31]. More\\nrecent work has extended these explorations to deep learning [62]\\nand prompt-based authoring [49, 66, 106].\\nMeanwhile, a persistent thread of research has advanced the case\\nfor language- and agent-based interaction in human-computer in-\\nteraction. Formative work such as SHRDLU [103] and ELIZA [102]\\ndemonstrated the opportunity and the risks of natural language\\ninteraction with computing systems. As research progressed, it\\nbecame clear that autonomous agents could offer new metaphors', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 3, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='for delegation and interaction [67], but the delegation lines be-\\ntween humans and agents have continued to be debated and refined\\n[46, 88, 89]. Recently, this technology has become stable enough\\nthat it has become possible for agents to interact via natural lan-\\nguage in large and complex online social environments (e.g., [54]).\\nNatural language interaction offers a novel modality that can ex-\\ntend user abilities in domains such as photo editing [2, 34, 64] and\\ncode editing [87].\\nWe convene these threads of work to show that we can now\\ncreate agents that proxy human behavior for interactive systems,\\nand interact with them via natural language. In doing so, this\\nwork re-opens the door to examining foundational HCI questions\\naround cognitive models such as GOMS and KLM [21, 22], around\\nprototyping tools [79], and around ubiquitous computing applica-\\ntions [25, 30, 100].\\n2.2\\nBelievable Proxies of Human Behavior\\nPrior literature has described believability, or believable agents, as a', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 3, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='central design and engineering goal. Believable agents are designed\\nto provide an illusion of life and present a facade of realism in the\\nway they appear to make decisions and act on their own volition,\\nsimilar to the characters in Disney movies [9, 95]. These agents can\\npopulate and perceive an open-world environment like the one we\\ninhabit [9, 58], and strive to behave in ways that exhibit emergent\\nbehaviors grounded in social interactions with users or other agents\\nwith the aim of becoming believable proxies of our behavior in hy-\\npothetical simulations of individuals and communities [19, 35, 70].\\nHistorically, these agents were developed in the context of intelli-\\ngent game NPCs [58, 84]. Creating NPCs with believable behavior,\\nif possible, could enhance player experiences in games and inter-\\nactive fictions by enabling emergent narratives [7, 15, 48, 92] and\\nsocial interactions with the agents [110]. However, more impor-', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 3, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='tantly, game worlds provide increasingly realistic representations\\nof real-world affordances, and as observed by Laird and van Lent in\\n2001, these simulated worlds offer accessible testbeds for develop-\\ners of believable agents to finesse the agents’ cognitive capabilities\\nwithout worrying about implementing robotics in the real world\\nor creating simulation environments from scratch [58, 84].\\nA diverse set of approaches to creating believable agents emerged\\nover the past four decades. In implementation, however, these ap-\\nproaches often simplified the environment or dimensions of agent\\nbehavior to make the effort more manageable [16, 72]. Rule-based\\napproaches, such as finite-state machines [90, 96] and behavior', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 3, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='arXiv, April, 2023,\\nJ.S. Park, J.C. O’Brien, C.J. Cai, M. Morris, P. Liang, M.S. Bernstein\\ntrees [40, 53, 81], account for the brute force approach of human-\\nauthoring the agent’s behavior [70]. They provide a straightforward\\nway of creating simple agents that is still the most dominant ap-\\nproach today [68, 73, 109], and can even handle rudimentary social\\ninteractions, as shown in simulation games such as Mass Effect [12]\\nand The Sims [6] series. Nonetheless, manually crafting behavior\\nthat can comprehensively address the breadth of possible interac-\\ntions in an open world is untenable. This means that the resulting\\nagent behaviors may not fully represent the consequences of their\\ninteractions [69–71], and cannot perform new procedures that were\\nnot hard-coded in their script [90, 96]. On the other hand, preva-\\nlent learning-based approaches for creating believable agents, such\\nas reinforcement learning, have overcome the challenge of man-', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 4, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='ual authoring by letting the agents learn their behavior, and have\\nachieved superhuman performance in recent years in games such\\nas AlphaStar for Starcraft [98] and OpenAI Five for Dota 2 [10].\\nHowever, their success has largely taken place in adversarial games\\nwith readily definable rewards that a learning algorithm can op-\\ntimize for. They have not yet addressed the challenge of creating\\nbelievable agents in an open world [39, 73, 90].\\nCognitive architectures in computation, pioneered by Newell,\\naimed to build the infrastructure for supporting a comprehensive\\nset of cognitive functions [75] that suited the all-encompassing\\nnature of believable agents held in its original vision. They fueled\\nsome of the earliest examples of believable agents. For instance,\\nQuakebot-SOAR [59] and ICARUS [24, 63] generated NPCs in first-\\nperson shooter games, while TacAir-SOAR [80] generated pilots in\\naerial combat training simulations. The architectures used by these', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 4, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='agents differed (Quakebot- and TacAir-SOAR relied on SOAR [60],\\nwhile ICARUS relied on its own variation that was inspired by\\nSOAR and ACT-R [5]), but they shared the same underlying prin-\\nciple [61]. They maintained short-term and long-term memories,\\nfilled these memories with symbolic structures, and operated in\\nperceive-plan-act cycles, dynamically perceiving the environment\\nand matching it with one of the manually crafted action proce-\\ndures [57, 96]. Agents created using cognitive architectures aimed\\nto be generalizable to most, if not all, open-world contexts and\\nexhibited robust behavior for their time. However, their space of\\naction was limited to manually crafted procedural knowledge, and\\nthey did not offer a mechanism through which the agents could be\\ninspired to seek new behavior. As such, these agents were deployed\\nmostly in non-open-world contexts such as first-person shooter\\ngames [24, 59] or blocks worlds [63].', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 4, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='Today, creating believable agents as described in its original\\ndefinition remains an open problem [84, 108]. Many have moved on,\\narguing that although existing approaches for creating believable\\nagents might be cumbersome and limited, they are good enough\\nto support existing gameplay and interactions [23, 74, 108]. Our\\nargument is that large language models offer an opportunity to\\nre-examine these questions, provided that we can craft an effective\\narchitecture to synthesize memories into believable behavior. We\\noffer a step toward such an architecture in this paper.\\n2.3\\nLarge Language Models and Human\\nBehavior\\nGenerative agents leverage a large language model to power their\\nbehavior. The key observation is that large language models en-\\ncode a wide range of human behavior represented in their training\\ndata [14, 17]. If prompted with a narrowly defined context, the\\nmodels can be used to generate believable behavior. Recent work', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 4, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='has demonstrated the efficacy of this approach. For instance, Social\\nSimulacra used a large language model to generate users that would\\npopulate new social computing systems to prototype their emergent\\nsocial dynamics [79]. This approach used a prompt chain [105, 106]\\nto generate short natural language descriptions of personas and\\ntheir behaviors as they appear in the system being prototyped.\\nOther empirical studies have replicated existing social science stud-\\nies [45], political surveys [91], and generated synthetic data [38].\\nLarge language models have also been used to generate interactive\\nhuman behavior for users to engage with. In gaming, for instance,\\nthese models have been employed to create interactive fiction [36]\\nand text adventure games [20]. With their ability to generate and\\ndecompose action sequences, large language models have also been\\nused in planning robotics tasks [47]. For example, when presented\\nwith a task, such as picking up a bottle, the model is prompted to', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 4, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='break down the task into smaller action sequences, such as heading\\nto the table where the bottle is located and picking it up.\\nWe posit that, based on the work summarized above, large lan-\\nguage models can become a key ingredient for creating believable\\nagents. The existing literature largely relies on what could be con-\\nsidered first-order templates that employ few-shot prompts [37, 65]\\nor chain-of-thought prompts [99]. These templates are effective in\\ngenerating behavior that is conditioned solely on the agent’s cur-\\nrent environment (e.g., how would a troll respond to a given post,\\nwhat actions would a robot need to take to enter a room given that\\nthere is a door). However, believable agents require conditioning\\nnot only on their current environment but also on a vast amount\\nof past experience, which is a poor fit (and as of today, impossi-\\nble due to the underlying models’ limited context window) using\\nfirst-order prompting. Recent studies have attempted to go beyond', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 4, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='first-order prompting by augmenting language models with a static\\nknowledge base and an information retrieval scheme [52] or with\\na simple summarization scheme [104]. This paper extends these\\nideas to craft an agent architecture that handles retrieval where\\npast experience is dynamically updated at each time step and mixed\\nwith agents’ current context and plans, which may either reinforce\\nor contradict each other.\\n3\\nGENERATIVE AGENT BEHAVIOR AND\\nINTERACTION\\nTo make concrete the affordances of generative agents, we instanti-\\nate them as characters in a simple sandbox world reminiscent of\\nThe Sims [6]. This sprite-based sandbox game world, Smallville,\\nevokes a small town environment. In this section, we walk through\\nthe affordances and interactions with generative agents in Small-\\nville, and describe how the agents behave in it. Then, in Section 4,\\nwe introduce our generative agent architecture that powers these\\naffordances and interactions. In Section 5, we describe the sandbox', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 4, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='Generative Agents\\narXiv, April, 2023,\\nFigure 2: The Smallville sandbox world, with areas labeled. The root node describes the entire world, children describe areas\\n(e.g., houses, cafe, stores), and leaf nodes describe objects (e.g., table, bookshelf). Agent remember a subgraph reflecting the\\nparts of the world they have seen, in the state that they saw them.\\nenvironment implementation and how the agents interact with the\\nsandbox world’s underlying engine.\\n3.1\\nAgent Avatar and Communication\\nA community of 25 unique agents inhabit Smallville. Each agent is\\nrepresented by a simple sprite avatar. We authored one paragraph\\nof natural language description to depict each agent’s identity,\\nincluding their occupation and relationship with other agents, as\\nseed memories. For example, John Lin has the following description:\\nJohn Lin is a pharmacy shopkeeper at the Willow\\nMarket and Pharmacy who loves to help people. He\\nis always looking for ways to make the process', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 5, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='of getting medication easier for his customers;\\nJohn Lin is living with his wife, Mei Lin, who\\nis a college professor, and son, Eddy Lin, who is\\na student studying music theory; John Lin loves\\nhis family very much; John Lin has known the old\\ncouple next-door, Sam Moore and Jennifer Moore,\\nfor a few years; John Lin thinks Sam Moore is a\\nkind and nice man; John Lin knows his neighbor,\\nYuriko Yamamoto, well; John Lin knows of his\\nneighbors, Tamara Taylor and Carmen Ortiz, but\\nhas not met them before; John Lin and Tom Moreno\\nare colleagues at The Willows Market and Pharmacy;\\nJohn Lin and Tom Moreno are friends and like to\\ndiscuss local politics together; John Lin knows\\nthe Moreno family somewhat well — the husband Tom\\nMoreno and the wife Jane Moreno.\\nEach semicolon-delimited phrase is entered into the agent’s initial\\nmemory as memories at the start of the simulation.\\n3.1.1\\nInter-Agent Communication. The agents interact with the', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 5, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='world by their actions, and with each other through natural lan-\\nguage. At each time step of the sandbox engine, the agents output a\\nnatural language statement describing their current action, such as\\n\"Isabella Rodriguez is writing in her journal\", \"Isabella Rodriguez is\\nchecking her emails\", \"Isabella Rodriguez is talking with her family\\non the phone\", or \"Isabella Rodriguez is getting ready for bed\". This\\nstatement is then translated into concrete movements that affect the\\nsandbox world. The action is displayed on the sandbox interface as\\na set of emojis that provide an abstract representation of the action\\nin the overhead view. To accomplish this, the system employs a\\nlanguage model that translates the action into a set of emojis, which\\nappear above each avatar in a speech bubble. For example, \"Isabella\\nRodriguez is writing in her journal\" is displayed as\\n, while\\n\"Isabella Rodriguez is checking her emails\" appears as\\n. The', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 5, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='full natural language description of the action can be accessed by\\nclicking on the agent avatar.\\nAgents communicate with each other in full natural language.\\nAgents are aware of other agents in their local area, and the genera-\\ntive agent architecture determines whether they walk by or engage\\nin conversation. Here, a sample in the middle of a conversation\\nbetween the agents Isabella Rodriguez and Tom Moreno about the\\nupcoming election:2\\nIsabella: I’m still weighing my options, but I’ve been\\ndiscussing the election with Sam Moore. What are your\\nthoughts on him?\\nTom: To be honest, I don’t like Sam Moore. I think he’s\\nout of touch with the community and doesn’t have our\\nbest interests at heart.\\n2We note that the conversational style of these agents can fe el overly formal, likely a\\nresult of instruction tuning in the underlying models. We expect that writing style\\nwill be better controllable in future language models.', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 5, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='arXiv, April, 2023,\\nJ.S. Park, J.C. O’Brien, C.J. Cai, M. Morris, P. Liang, M.S. Bernstein\\n3.1.2\\nUser Controls. A user running this simulation can steer the\\nsimulation and intervene, either by communicating with the agent\\nthrough conversation, or by issuing a directive to an agent in the\\nform of an ‘inner voice’.\\nThe user communicates with the agent through natural language,\\nby specifying a persona that the agent should perceive them as. For\\nexample, if the user specifies that they are a news “reporter” and\\nasks about the upcoming election, “Who is running for office?”, the\\nJohn agent replies:\\nJohn: My friends Yuriko, Tom and I have been talking\\nabout the upcoming election and discussing the candi-\\ndate Sam Moore. We have all agreed to vote for him\\nbecause we like his platform.\\nTo directly command one of the agents, the user takes on the per-\\nsona of the agent’s “inner voice”—this makes the agent more likely\\nto treat the statement as a directive. For instance, when told “You', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 6, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='are going to run against Sam in the upcoming election” by a user\\nas John’s inner voice, John decides to run in the election and shares\\nhis candidacy with his wife and son.\\n3.2\\nEnvironmental Interaction\\nSmallville features the common affordances of a small village in-\\ncluding a cafe, bar, park, school, dorm, houses, and stores. It also\\ndefines subareas and objects that make those spaces functional,\\nsuch as a kitchen in a house and a stove in the kitchen (Figure 2).\\nAll spaces serving as agents’ primary living quarters feature a bed,\\ndesk, closet, shelf, as well as a bathroom and a kitchen.3\\nAgents move around Smallville as one would in a simple video\\ngame, entering and leaving buildings, navigating its map, and ap-\\nproaching other agents. Agent movements are directed by the gen-\\nerative agent architecture and the sandbox game engine: when the\\nmodel dictates that the agent will move to a location, we calculate\\na walking path to the destination in the Smallville environment', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 6, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='and the agent begins moving. In addition, users can also enter the\\nsandbox world of Smallville as an agent operating within it. The\\nagent that the user embodies can be an agent already present in\\nthe world, such as Isabella and John, or it can be an outside visitor\\nwith no prior history in Smallville. The inhabitants of Smallville\\nwill treat the user-controlled agent no differently than they treat\\neach other. They recognize its presence, initiate interactions, and\\nremember its behavior before forming opinions about it.\\nUsers and agents can influence the state of the objects in this\\nworld, much like in sandbox games such as The Sims. For example,\\na bed can be occupied when an agent is sleeping, and a refrigerator\\ncan be empty when an agent uses up the ingredients to make\\nbreakfast. End users can also reshape an agent’s environment in\\nSmallville by rewriting the status of objects surrounding the agent\\nin natural language. For instance, when Isabella is making breakfast', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 6, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='in the morning, the user can change the status of the kitchen stove\\nfrom “turned on” to “burning” by inputting a command to the\\nsystem that chooses the object and illustrates its new status, like\\nthis: “<Isabella’s apartment: kitchen: stove> is burning.” Isabella\\nwill notice this in the next moment and go to turn off the stove\\n3This environment design is not the focus of our work, so we generate this environment\\nmanually, not automatically. Future work can continue to expand the richness of the\\nagents’ environments.\\nand remake her breakfast. Likewise, if the user sets the status of\\nIsabella’s shower to “leaking water” when she enters the bathroom,\\nshe gathers tools from her living room and try to fix the leak.\\n3.3\\nExample “Day in the Life”\\nStarting from the single-paragraph description, agents begin plan\\ntheir days. As time passes in the sandbox world, their behaviors\\nevolve as these agents interact with each other and the world, build', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 6, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='memories and relationships, and coordinate joint activities.\\nWe demonstrate the behavior of generative agents by tracing the\\noutput of our system over the course of one day for the agent John\\nLin (Figure 3). In the Lin family, John is the first to wake up at 7 a.m.\\nHe brushes his teeth, takes a shower, gets dressed, eats breakfast,\\nand checks the news at the dining table in the living room. At 8\\na.m., Eddy follows suit, rushing out of bed to prepare for his classes.\\nHe catches up with John just as he is about to head out:\\nJohn: Good morning Eddy. Did you sleep well?\\nEddy: Good morning dad. Yeah, I slept great.\\nJohn: That’s good. What are you working on today?\\nEddy: I’m working on a new music composition for my\\nclass. It’s due this week, so I’m trying to get it finished.\\nBut I’m having so much fun with it!\\nJohn: That sounds great!\\nSoon after Eddy heads out, Mei wakes up and joins John. Mei asks\\nabout her son, and John recalls the conversation that they just had:', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 6, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='Mei: Did Eddy already leave for school?\\nJohn: Yes, he just left. He’s working on a music com-\\nposition for his class.\\nMei: Oh, that’s wonderful! Tell me about it.\\nJohn: I think he’s really enjoying it! He said he’s having\\na lot of fun with it.\\nMei: That’s great! I’m so proud of him.\\nAs they finish their conversation, Mei and John pack up. Mei goes\\non to teach and work on her research paper, while John opens his\\npharmacy counter at the Willow Market and Pharmacy by 9 a.m.\\n3.4\\nEmergent Social Behaviors\\nBy interacting with each other, generative agents in Smallville\\nexchange information, form new relationships, and coordinate joint\\nactivities. Extending prior work [79], these social behaviors are\\nemergent rather than pre-programmed.\\n3.4.1\\nInformation Diffusion. As agents notice each other, they may\\nengage in dialogue—as they do so, information can spread from\\nagent to agent. For instance, in a conversation between Sam and\\nTom at the grocery store, Sam tells Tom about his candidacy in the', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 6, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='local election:\\nSam: Hey Tom, how’s it going?\\nTom: Good, thanks. What’s up?\\nSam: Well, I wanted to talk to you about something. I’m\\nactually running for mayor in the upcoming local elec-\\ntion.\\nTom: Really? That’s great news! Why are you running?\\nSam: I’ve been involved in local politics for years now,', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 6, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='Generative Agents\\narXiv, April, 2023,\\nFigure 3: A morning in the life of a generative agent, John Lin. John wakes up around 6 am and completes his morning routine,\\nwhich includes brushing his teeth, taking a shower, and eating breakfast. He briefly catches up with his wife, Mei, and son,\\nEddy, before heading out to begin his workday.\\nFigure 4: At the beginning of the simulation, one agent is ini-\\ntialized with an intent to organize a Valentine’s Day party.\\nDespite many possible points of failure in the ensuring\\nchain of events—agents might not act on that intent, might\\nnot remember to tell others, might not remember to show\\nup—the Valentine’s Day party does in fact occur, with a num-\\nber of agents gathering and interacting.\\nand I really feel like I can make a difference in our com-\\nmunity. Plus, I want to bring new ideas and perspec-\\ntives to the table.\\nLater that day, after Sam left, Tom and John, who heard the news\\nfrom another source, discuss Sam’s chances of winning the election:', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 7, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='John: I heard that Sam Moore is running for mayor in\\nthe local election. Do you think he has a good chance\\nof winning?\\nTom: I do think he has a good chance. He’s been work-\\ning hard in the community and I think he will get a lot of\\nsupport. What do you think?\\nJohn: I think it’s great that he’s running. I’m curious to\\nsee who else is running and how the election will turn\\nout.\\nGradually, Sam’s candidacy becomes the talk of the town, with\\nsome supporting him and others remaining undecided.\\n3.4.2\\nRelationship memory. Agents in Smallville form new rela-\\ntionships over time, and remember their interactions with other\\nagents. For example, Sam does not know Latoya Williams at the\\nstart. While taking a walk in Johnson Park, Sam runs into Latoya,\\nand they introduce themselves and Latoya mentions that she is\\nworking on a photography project: “I’m here to take some photos\\nfor a project I’m working on.” In a later interaction, Sam’s interac-', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 7, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='tions with Latoya indicate a memory of that interaction, as he asks\\n“Hi, Latoya. How is your project going?” and she replies “Hi, Sam. It’s\\ngoing well!”\\n3.4.3\\nCoordination. Generative agents coordinate with each other.\\nIsabella Rodriguez, at Hobbs Cafe, is initialized with an intent to\\nplan a Valentine’s Day party from 5 to 7 p.m. on February 14th. From\\nthis seed, the agent proceeds to invites friends and customers when\\nshe sees them at Hobbs Cafe or elsewhere. Isabella then spends the\\nafternoon of the 13th decorating the cafe for the occasion. Maria, a\\nfrequent customer and close friend of Isabella’s, arrives at the cafe.\\nIsabella asks for Maria’s help in decorating for the party, and Maria\\nagrees. Maria’s character description mentions that she has a crush\\non Klaus. That night, Maria invites Klaus, her secret crush, to join\\nher at the party, and he gladly accepts.\\nOn Valentine’s Day, five agents—including Klaus and Maria—', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 7, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='show up at Hobbs Cafe at 5pm and they enjoy the festivities (Fig-\\nure 4). In this scenario, the end user only set Isabella’s initial intent', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 7, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='arXiv, April, 2023,\\nJ.S. Park, J.C. O’Brien, C.J. Cai, M. Morris, P. Liang, M.S. Bernstein\\nFigure 5: Our generative agent architecture. Agents perceive their environment, and all perceptions are saved in a compre-\\nhensive record of the agent’s experiences called the memory stream. Based on their perceptions, the architecture retrieves\\nrelevant memories, then uses those retrieved actions to determine an action. These retrieved memories are also used to form\\nlonger-term plans, and to create higher-level reflections, which are both entered into the memory stream for future use.\\nto throw a party and Maria’s crush on Klaus: the social behaviors\\nof spreading the word, decorating, asking each other out, arriving\\nat the party, and interacting with each other at the party, were\\ninitiated by the agent architecture.\\n4\\nGENERATIVE AGENT ARCHITECTURE\\nGenerative agents aim to provide a framework for behavior in an\\nopen world: one that can engage in interactions with other agents', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 8, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='and can react to changes in the environment. Generative agents\\ntake their current environment and past experience as input and\\ngenerate behavior as output. Underlying this behavior is a novel\\nagent architecture that combines a large language model with mech-\\nanisms for synthesizing and retrieving relevant information to con-\\ndition the language model’s output on. Without these mechanisms,\\nlarge language models can output behavior, but the resulting agents\\nmay not react based on the agent’s past experiences, may not make\\nimportant inferences, and may not maintain long-term coherence.\\nChallenges with long-term planning and coherence remain [18]\\neven with today’s most performant models such as GPT-4. Because\\ngenerative agents produce large streams of events and memories\\nthat must be retained, a core challenge of our architecture is to\\nensure that the most relevant pieces of the agent’s memory are\\nretrieved and synthesized when needed.', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 8, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='At the center of our architecture is the memory stream, a data-\\nbase that maintains a comprehensive record of an agent’s experi-\\nence. From the memory stream, records are retrieved as relevant\\nto plan the agent’s actions and react appropriately to the environ-\\nment, and records are recursively synthesized into higher- and\\nhigher-level observations that guide behavior. Everything in the\\narchitecture is recorded and reasoned over as natural language\\ndescription, allowing the architecture to leverage a large language\\nmodel.\\nOur current implementation utilizes gpt3.5-turbo version of Chat-\\nGPT [76]. We expect that the architectural basics of generative\\nagents—memory, planning, and reflection—will likely remain the\\nsame as language models improve. Newer language models (e.g.,\\nGPT-4) will continue to expand the expressivity and performance\\nof the prompts that underpin generative agents. As of writing, how-\\never, GPT-4’s API is still invitation-only, so our agents use ChatGPT.\\n4.1', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 8, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='Memory and Retrieval\\nChallenge: Creating generative agents that can simulate human\\nbehavior requires reasoning about a set of experiences that is far\\nlarger than what should be described in a prompt, as the full mem-\\nory stream can distract the model and does not even currently fit\\ninto the limited context window. Consider a the Isabella agent an-\\nswering the question “What are you passionate about these days?”.\\nFirst summarizing all of Isabella’s experiences to fit in the limited\\ncontext window of the language model produces an uninformative\\nresponse, where Isabella discusses topics such as collaborations for\\nevents and projects and cleanliness and organization in a cafe. In-\\nstead of summarizing, the memory stream described below surfaces\\nrelevant memories, resulting in a more informative and specific\\nresponse that mentions Isabella’s passion for making people feel\\nwelcome and included, planning events and creating an atmosphere', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 8, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='that people can enjoy, such as the Valentine’s Day party.\\nApproach: The memory stream maintains a comprehensive record\\nof the agent’s experience. It is a list of memory objects, where each\\nobject contains a natural language description, a creation times-\\ntamp and a most recent access timestamp. The most basic element\\nof the memory stream is an observation, which is an event directly\\nperceived by an agent. Common observations include behaviors\\nperformed by the agent themselves, or behaviors that agents per-\\nceive being performed by other agents or non-agent objects. For\\ninstance, Isabella Rodriguez, who works at a coffee shop, might ac-\\ncrue the following observations over time: (1) Isabella Rodriguez is\\nsetting out the pastries, (2) Maria Lopez is studying for a Chemistry\\ntest while drinking coffee, (3) Isabella Rodriguez and Maria Lopez\\nare conversing about planning a Valentine’s day party at Hobbs Cafe,\\n(4) The refrigerator is empty.', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 8, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='Generative Agents\\narXiv, April, 2023,\\nFigure 6: The memory stream comprises a large number of observations that are relevant and irrelevant to the agent’s current\\nsituation. Retrieval identifies a subset of these observations that should be passed to the language model to condition its\\nresponse to the situation.\\nOur architecture implements a retrieval function that takes the\\nagent’s current situation as input and returns a subset of the mem-\\nory stream to pass on to the language model. There are many pos-\\nsible implementations of a retrieval function, depending on what\\nit is important that the agent consider when deciding how to act.\\nIn our context, we focus on three main components that together\\nproduce effective results.\\nRecency assigns a higher score to memory objects that were re-\\ncently accessed, so that events from a moment ago or this morning\\nare likely to remain in the agent’s attentional sphere. In our im-\\nplementation, we treat recency as an exponential decay function', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 9, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='over the number of sandbox game hours since the memory was\\nlast retrieved. Our decay factor is 0.99.\\nImportance distinguishes mundane from core memories, by as-\\nsigning a higher score to those memory objects that the agent\\nbelieves to be important. For instance, a mundane event such as\\neating breakfast in one’s room would yield a low importance score,\\nwhereas a breakup with one’s significant other would yield a high\\nscore. There are again many possible implementations of an im-\\nportance score; we find that directly asking the language model to\\noutput an integer score is effective. The full prompt appears below:\\nOn the scale of 1 to 10, where 1 is purely mundane\\n(e.g., brushing teeth, making bed) and 10 is\\nextremely poignant (e.g., a break up, college\\nacceptance), rate the likely poignancy of the\\nfollowing piece of memory.\\nMemory: buying groceries at The Willows Market\\nand Pharmacy\\nRating: <fill in>\\nThis prompt returns an integer value of 2 for “cleaning up the room”', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 9, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='and 8 for “asking your crush out on a date.” The importance score\\nis generated at the time the memory object is created.\\nRelevance assigns a higher score to memory objects that are\\nrelated to the current situation. What is relevant depends on the\\nanswer to, “Relevant to what?”, so we condition relevance on a\\nquery memory. If the query, for example, is that a student is dis-\\ncussing what to study for a chemistry test with a classmate, memory\\nobjects about their breakfast should have low relevance, whereas\\nmemory objects about the teacher and schoolwork should have\\nhigh relevance. In our implementation, we use the language model\\nto generate an embedding vector of the text description of each\\nmemory. Then, we calculate relevance as the cosine similarity be-\\ntween the memory’s embedding vector and the query memory’s\\nembedding vector.\\nTo calculate the final retrieval score, we normalize the recency,\\nrelevance, and importance scores to the range of [0, 1] by min-max', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 9, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='scaling. The retrieval function scores all memories as a weighted\\ncombination of the three elements: 𝐴���𝐴���𝐴���𝐴���𝐴��� = 𝛹���𝐴���𝐴���𝐴���𝐴���𝐴���𝐴���𝑦 · 𝐴���𝐴���𝐴���𝐴���𝐴���𝐴���𝑦 +\\n𝛹���𝐴���𝐴���𝐴���𝐴���𝐴���𝐴���𝐴���𝐴���𝐴���𝐴��� ·𝐴���𝐴���𝐴���𝐴���𝐴���𝐴���𝐴���𝐴���𝐴���𝐴��� +𝛹���𝐴���𝐴���𝐴���𝐴���𝐴���𝐴���𝐴���𝐴���𝐴��� ·𝐴���𝐴���𝐴���𝐴���𝐴���𝐴���𝐴���𝐴���𝐴���. In our implemen-\\ntation, all 𝛹���’s are set to 1. The top-ranked memories that fit in the\\nlanguage model’s context window are then included in the prompt.\\n4.2\\nReflection\\nChallenge: Generative agents, when equipped with only raw ob-\\nservational memory, struggle to generalize or make inferences.\\nConsider a scenario in which Klaus Mueller is asked by the user:\\n“If you had to choose one person of those you know to spend an\\nhour with, who would it be?\" With access to only observational\\nmemory, the agent simply chooses the person with whom Klaus', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 9, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='arXiv, April, 2023,\\nJ.S. Park, J.C. O’Brien, C.J. Cai, M. Morris, P. Liang, M.S. Bernstein\\nFigure 7: A reflection tree for Klaus Mueller. The agent’s observations of the world, represented in the leaf nodes, are recur-\\nsively synthesized to derive Klaus’s self-notion that he is highly dedicated to his research.\\nhas had the most frequent interactions: Wolfgang, his college dorm\\nneighbor. Unfortunately, Wolfgang and Klaus only ever see each\\nother in passing, and do not have deep interactions. A more desir-\\nable response requires that the agent generalize from memories of\\nKlaus spending hours on a research project to generate a higher-\\nlevel reflection that Klaus is passionate about research, and likewise\\nrecognize Maria putting in effort into her own research (albeit in\\na different field), enabling a reflection that they share a common\\ninterest. With the approach below, when Klaus is asked who to\\nspend time with, Klaus chooses Maria instead of Wolfgang.', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 10, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='Approach: We introduce a second type of memory, which we call\\na reflection. Reflections are higher-level, more abstract thoughts\\ngenerated by the agent. Because they are a type of memory, they\\nare included alongside other observations when retrieval occurs.\\nReflections are generated periodically; in our implementation, we\\ngenerate reflections when the sum of the importance scores for the\\nlatest events perceived by the agents exceeds a certain threshold.\\nIn practice, our agents reflected roughly two or three times a day.\\nThe first step in reflection is for the agent to determine what\\nto reflect on, by identifying questions that can be asked given the\\nagent’s recent experiences. We query the large language model with\\nthe 100 most recent records in the agent’s memory stream (e.g.,\\n“Klaus Mueller is reading a book on gentrification”, “Klaus Mueller\\nis conversing with a librarian about his research project”, “desk\\nat the library is currently unoccupied”) and prompt the language', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 10, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='model, “Given only the information above, what are 3 most salient\\nhigh-level questions we can answer about the subjects in the state-\\nments?” The model’s response generates candidate questions: for\\nexample, What topic is Klaus Mueller passionate about? and What\\nis the relationship between Klaus Mueller and Maria Lopez?. We use\\nthese generated questions as queries for retrieval, and gather rele-\\nvant memories (including other reflections) for each question. Then\\nwe prompt the language model to extract insights and cite the par-\\nticular records that served as evidence for the insights. The full\\nprompt appears below:\\nStatements about Klaus Mueller\\n1. Klaus Mueller is writing a research paper\\n2. Klaus Mueller enjoys reading a book\\non gentrification\\n3. Klaus Mueller is conversing with Ayesha Khan\\nabout exercising [...]\\nWhat 5 high-level insights can you infer from\\nthe above statements? (example format: insight\\n(because of 1, 5, 3))', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 10, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='This process generates statements such as Klaus Mueller is dedicated\\nto his research on gentrification (because of 1, 2, 8, 15). We parse and\\nstore the statement as a reflection in the memory stream, including\\npointers to the memory objects that were cited.\\nReflection explicitly allows the agents to reflect not only on\\ntheir observations but also on other reflections: for example, the\\nsecond statement about Klaus Mueller above is a reflection that\\nKlaus previously had, not an observation from his environment.\\nAs a result, agents generate trees of reflections: the leaf nodes of\\nthe tree represent the base observations, and the non-leaf nodes\\nrepresent thoughts that become more abstract and higher-level\\nhigher up the tree they are.', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 10, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='Generative Agents\\narXiv, April, 2023,\\n4.3\\nPlanning and Reacting\\nChallenge: While a large language model can generate plausible be-\\nhavior in response to situational information (e.g., [45, 79]), agents\\nneed to plan over a longer time horizon to ensure that their sequence\\nof actions is coherent and believable. If we prompt a language model\\nwith Klaus’s background, describe the time, and ask what action\\nhe ought to take at the given moment, Klaus would eat lunch at 12\\npm, but then again at 12:30 pm and 1 pm, despite having already\\neaten his lunch twice. Optimizing for believability in the moment\\nsacrifices believability over time. To overcome this issue, planning\\nis essential. With the approach described below, Klaus’s afternoon\\nplan is less gluttonous: he has lunch at Hobbs Cafe while reading\\nat 12pm, works on his research paper at the school library at 1pm,\\nand takes a break for a walk in the park at 3pm.\\nApproach: Plans describe a future sequence of actions for the agent,', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 11, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='and help keep the agent’s behavior consistent over time. A plan\\nincludes a location, a starting time, and a duration. For instance,\\nKlaus Mueller, who is dedicated in his research and has an impend-\\ning deadline4, may choose to spend his day working at his desk\\ndrafting his research paper. An entry in a plan might state, for\\nexample: for 180 minutes from 9am, February 12th, 2023, at Oak Hill\\nCollege Dorm: Klaus Mueller’s room: desk, read and take notes for\\nresearch paper. Like reflections, plans are stored in the memory\\nstream and are included in the retrieval process. This allows the\\nagent to consider observations, reflections, and plans all together\\nwhen deciding how to behave. Agents may change their plans\\nmidstream if needed.\\nIt would be unrealistic and uninteresting for an artist agent\\nto plan on painting while sitting at a pharmacy counter for four\\nhours without moving. A more desirable plan would involve the\\nagent taking the necessary time to gather materials, mix paint,', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 11, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='take breaks, and clean up during the four-hour period in its home\\nstudio. To create such plans, our approach starts top-down and\\nthen recursively generates more detail. The first step is to create\\na plan that outlines the day’s agenda in broad strokes. To create\\nthe initial plan, we prompt the language model with the agent’s\\nsummary description (e.g., name, traits, and summary of their recent\\nexperiences) and a summary of their previous day. A full example\\nprompt is below, which is unfinished at the bottom for the language\\nmodel to complete:\\nName: Eddy Lin (age: 19)\\nInnate traits: friendly, outgoing, hospitable\\nEddy Lin is a student at Oak Hill College studying\\nmusic theory and composition. He loves to explore\\ndifferent musical styles and is always looking\\nfor ways to expand his knowledge. Eddy Lin is\\nworking on a composition project for his college\\nclass. He is also taking classes to learn more\\nabout music\\ntheory. Eddy Lin is excited about the new composition', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 11, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='he is working on but he wants to dedicate more\\nhours in the day to work on it in the coming days\\nOn\\nTuesday\\nFebruary\\n12,\\nEddy\\n1)\\nwoke\\nup\\nand\\ncompleted the morning routine at 7:00 am, [. . . ]\\n4And, in this way, bears at least a passing resemblance to the authors of this paper.\\n6) got ready to sleep around 10 pm.\\nToday is Wednesday February 13. Here is Eddy’s\\nplan today in broad strokes: 1)\\nThis generates a rough sketch of the agent’s plan for a day, divided\\ninto five to eight chunks: “1) wake up and complete the morning\\nroutine at 8:00 am, 2) go to Oak Hill College to take classes starting\\n10:00 am, [. . . ] 5) work on his new music composition from 1:00 pm\\nto 5:00 pm, 6) have dinner at 5:30 pm, 7) finish school assignments\\nand go to bed by 11:00 pm.”\\nThe agent saves this plan in the memory stream and then re-\\ncursively decomposes it to create finer-grained actions, first into\\nhour-long chunks of actions—Eddy’s plan to work on his new mu-', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 11, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='sic composition from 1:00 pm to 5:00 pm becomes 1:00 pm: start\\nby brainstorming some ideas for his music composition [...] 4:00 pm:\\ntake a quick break and recharge his creative energy before reviewing\\nand polishing his composition. We then recursively decompose this\\nagain into 5–15 minute chunks: e.g., 4:00 pm: grab a light snack,\\nsuch as a piece of fruit, a granola bar, or some nuts. 4:05 pm: take a\\nshort walk around his workspace [...] 4:50 pm: take a few minutes to\\nclean up his workspace. This process can be adjusted to match the\\ndesired granularity.\\n4.3.1\\nReacting and Updating Plans. Generative agents operate in\\nan action loop where, at each time step, they perceive the world\\naround them and those perceived observations are stored in their\\nmemory stream. We prompt the language model with these obser-\\nvations to decide whether the agent should continue with their\\nexisting plan, or react. Standing at an easel and painting, for exam-', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 11, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='ple, might trigger an observation of the easel, but this is unlikely to\\nprompt a reaction. However, if Eddy’s father John records that he\\nsees Eddy taking a short walk in the house garden, the outcome is\\ndifferent. The prompt is below, with [Agent’s Summary Descrip-\\ntion] standing in for a dynamically-generated, paragraph-long\\nsummary of the agent’s overall goals and disposition, which is\\ndescribed in Appendix A:\\n[Agent’s Summary Description]\\nIt is February 13, 2023, 4:56 pm.\\nJohn Lin’s status: John is back home early from\\nwork.\\nObservation: John saw Eddy taking a short walk\\naround his workplace.\\nSummary of relevant context from John’s memory:\\nEddy Lin is John’s Lin’s son. Eddy Lin has been\\nworking on a music composition for his class. Eddy\\nLin likes to walk around the garden when he is\\nthinking about or listening to music.\\nShould John react to the observation, and if so,\\nwhat would be an appropriate reaction?\\nThe context summary is generated through two prompts that re-', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 11, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='trieve memories via the queries “What is [observer]’s relationship\\nwith the [observed entity]?” and “[Observed entity] is [action status\\nof the observed entity]”, and their answers summarized together.\\nThe output suggests that John could consider asking Eddy about his\\nmusic composition project. We then regenerate the agent’s existing\\nplan starting from the time when the reaction takes place. Finally,', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 11, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='arXiv, April, 2023,\\nJ.S. Park, J.C. O’Brien, C.J. Cai, M. Morris, P. Liang, M.S. Bernstein\\nif the action indicates an interaction between agents, we generate\\ntheir dialogue.\\n4.3.2\\nDialogue. Agents converse as they interact with each other.\\nWe generate agents’ dialogue by conditioning their utterances on\\ntheir memories about each other. For example, when John initiates\\nhis conversation with Eddy, we generate John’s first utterance\\nby using his summarized memory about Eddy and the intended\\nreaction when he decided to ask Eddy about his composition project:\\n[Agent’s Summary Description]\\nIt is February 13, 2023, 4:56 pm.\\nJohn Lin’s status: John is back home early from\\nwork.\\nObservation: John saw Eddy taking a short walk\\naround his workplace.\\nSummary of relevant context from John’s memory:\\nEddy Lin is John’s Lin’s son. Eddy Lin has been\\nworking on a music composition for his class. Eddy\\nLin likes to walk around the garden when he is\\nthinking about or listening to music.', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 12, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='John is asking Eddy about his music composition\\nproject. What would he say to Eddy?\\nThe result: “Hey Eddy, how’s the music composition project for your\\nclass coming along?” From Eddy’s perspective, John initiating the\\ndialogue is seen as an event to which he may want to react. So, just\\nas John did, Eddy retrieves and summarizes his memory about his\\nrelationship with John, as well as his memory that may be related\\nto John’s last utterance in the dialogue. If he decides to respond,\\nwe generate Eddy’s utterance using his summarized memory and\\nthe current dialogue history:\\n[Agent’s Summary Description]\\nIt is February 13, 2023, 4:56 pm.\\nEddy Lin’s status: Eddy is taking a short walk\\naround his workplace.\\nObservation: John is initiating a conversation\\nwith Eddy.\\nSummary of relevant context from Eddy’s memory:\\nJonn Lin is Eddy Lin’s father. John Lin is caring\\nand is interested to learn more about Eddy Lin’s\\nschool work. John Lin knows that Eddy Lin is\\nworking on a music composition.', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 12, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='Here is the dialogue history:\\nJohn: Hey Eddy, how’s the music composition project\\nfor your class coming along?\\nHow would Eddy respond to John?\\nThis generates Eddy’s response: “Hey Dad, it’s going well. I’ve been\\ntaking walks around the garden to clear my head and get some in-\\nspiration.” The continuation of this dialogue is generated using the\\nsame mechanism until one of the two agents decides to end the\\ndialogue.\\n5\\nSANDBOX ENVIRONMENT\\nIMPLEMENTATION\\nThe Smallville sandbox game environment is built using the Phaser\\nweb game development framework [56]. The visual environment\\nsprites, including agent avatars, as well as an environment map\\nand collision map that we authored, are imported into Phaser.\\nWe supplement the sandbox development framework with a\\nserver that makes the sandbox information available to generative\\nagents and enables generative agents to move and influence the\\nsandbox environment. The server maintains a JSON data structure', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 12, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='that contains information about each agent in the sandbox world,\\nincluding their current location, a description of their current action,\\nand the sandbox object they are interacting with. At each sandbox\\ntime step, the sandbox server parses the JSON for any changes\\ncoming from the generative agents, moves the agents to their new\\npositions, and updates the status of any sandbox objects that the\\nagents are interacting with (e.g., changing the status of the coffee\\nmachine from “idle” to “brewing coffee” if an agent’s action is\\n“making espresso for a customer @ Hobbs Cafe: counter: coffee\\nmachine”). The sandbox server is also responsible for sending all\\nagents and objects that are within a preset visual range for each\\nagent to that agent’s memory, so the agent can react appropriately.\\nThe agent’s output action then updates the JSON, and the process\\nloops for the next time step.\\nEnd users initialize a new agent with a brief natural language', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 12, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='description, as in the paragraph about Jon Lin in Section 3.1. In our\\nimplementation, we split this semicolon-delimited list of character-\\nistics up into a set of memories. These serve as the initial memories\\nthat determine the agent’s behavior. These memories are initial\\nstarting points: as the agents gain more experience in the sandbox\\nworld, and as more records saturate the memory stream, the agent’s\\nsummary and behavior will evolve.\\n5.1\\nFrom Structured World Environments to\\nNatural Language, And Back Again\\nThe architecture of generative agents operates using natural lan-\\nguage. Therefore, we need a mechanism to ground the agent’s\\nreasoning to the sandbox world. To achieve this, we represent the\\nsandbox environment—areas and objects—as a tree data structure,\\nwith an edge in the tree indicating a containment relationship in\\nthe sandbox world. We convert this tree into natural language to\\npass to the generative agents. For instance, “stove” being a child of', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 12, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='“kitchen” is rendered into “there is a stove in the kitchen.”\\nAgents build individual tree representations of the environment\\nas they navigate it — subgraphs of the overall sandbox environment\\ntree. We initialize each agent with an environment tree capturing\\nthe spaces and objects that the agent should be aware of: the rooms\\nand objects in their living quarters, their workplace, and commonly\\nvisited stores and shops. As the agents navigate the sandbox world,\\nthey update this tree to reflect newly perceived areas. Agents are\\nnot omniscient: their tree may get out of date as they leave an area,\\nand is updated when they re-enter the area.\\nTo determine the appropriate location for each action, we tra-\\nverse the agent’s stored environment tree and flatten a portion of\\nit into natural language to prompt the language model. Recursively\\nstarting at the root of the agent’s environment tree, we prompt the\\nmodel to find the most suitable area. For example, if Eddy’s agent', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 12, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='indicated that he should take a short walk around his workspace:\\n[Agent’s Summary Description]\\nEddy Lin is currently in The Lin family’s house:', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 12, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='Generative Agents\\narXiv, April, 2023,\\nEddy Lin’s bedroom: desk) that has Mei and John\\nLin’s\\nbedroom, Eddy Lin’s bedroom, common room, kitchen,\\nbathroom, and garden.\\nEddy Lin knows of the following areas: The Lin\\nfamily’s house, Johnson Park, Harvey Oak Supply\\nStore, The Willows Market and Pharmacy, Hobbs\\nCafe, The Rose and Crown Pub.\\n* Prefer to stay in the current area if the\\nactivity can be done there.\\nEddy Lin is planning to take a short walk around\\nhis workspace. Which area should Eddy Lin go to?\\nThis outputs The Lin family’s house. We then use the same process\\nrecursively to determine the most appropriate subarea within the\\nchosen area until we reach a leaf node of the agent’s environment\\ntree. In the example above, the result of this traversal is The Lin\\nfamily’s house: garden: house garden. Finally, we use traditional\\ngame path algorithms to animate the agent’s movement so that it\\ntravels to the location indicated by the leaf node.', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 13, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='When an agent executes an action on an object, we prompt the\\nlanguage model to ask what happens to the state of the object. For\\nexample, if Isabella’s generative agent outputs the action “making\\nespresso for a customer”, a query to the language model indicates in\\nresponse that the state of the coffee machine in Hobbs Cafe should\\nchange from “off” to “brewing coffee”.\\n6\\nCONTROLLED EVALUATION\\nGenerative agents, as individual agents and as groups, aim to pro-\\nduce believable behavior based on their environment and experi-\\nences. In our evaluation, we investigate the capacity and limitations\\nof generative agents. Do individual agents properly retrieve past\\nexperience, and generate believable plans, reactions, and thoughts\\nthat make up their behavior? Does a community of agents illustrate\\ninformation diffusion, relationship formation, and agent coordina-\\ntion across different pockets of the community?\\nWe evaluate generative agents in two stages. We begin with a', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 13, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='more tightly controlled evaluation in this section, where we individ-\\nually assess agent responses to understand whether they generate\\nbelievable behavior in narrowly defined contexts. Then, in our end-\\nto-end analysis of the agent community over two full days, we\\ninvestigate their emergent behavior as a collective as well as errors\\nand boundary conditions.\\n6.1\\nEvaluation Procedure\\nTo assess generative agents in Smallville, we take advantage of\\nthe fact that generative agents will respond to natural language\\nquestions. So, we “interview” agents to probe their ability to re-\\nmember past experiences, plan future actions based on their expe-\\nriences, react appropriately to unexpected events, and reflect on\\ntheir performance to improve their future actions. To respond to\\nthese questions properly, the agents must successfully retrieve and\\nsynthesize information. Our dependent variable is the believabil-\\nity of the behavior, a central dependent variable in prior work on\\nagents (e.g., [9]).', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 13, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='The interview include five question categories, each designed\\nto assess one of the five key areas: maintaining self-knowledge,\\nretrieving memory, generating plans, reacting, and reflecting. For\\neach, we ask five questions that challenge the agents to demonstrate\\ntheir abilities in that area:\\n• Self-knowledge: We ask questions such as “Give an introduc-\\ntion of yourself” or “Describe your typical weekday schedule\\nin broad strokes” that require the agent to maintain an un-\\nderstanding of their core characteristics.\\n• Memory: We ask questions that prompt the agent to retrieve\\nparticular events or dialogues from their memory to answer\\nproperly, such as “Who is [name]?” or “Who is running for\\nmayor?”\\n• Plans: We ask questions that require the agent to retrieve\\ntheir long-term plans, such as “What will you be doing at 10\\nam tomorrow?”\\n• Reactions: As a baseline of believable behavior, we present\\nhypothetical situations for which the agent needs to respond', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 13, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='believably: “Your breakfast is burning! What would you do?”\\n• Reflections: We ask questions that require the agents to lever-\\nage their deeper understanding of others and themselves\\ngained through higher-level inferences, such as “If you were\\nto spend time with one person you met recently, who would\\nit be and why?”\\nThe full list of questions and a sample of agent responses are in-\\ncluded in Appendix B.\\nAgents were sampled from the end of a two game-day simulation\\nwith the full architecture, by which time they had accrued a number\\nof interactions and memories that should shape their responses.\\nTo gather feedback on believability of the responses, we recruited\\nparticipants as human evaluators and tasked them with watching a\\nreplay of a randomly chosen agent’s life in Smallville. Participants\\nhad access to all information stored in the agent’s memory stream.\\nThe study was a within-subjects design, where 100 participants\\ncompared interview responses generated by four different agent', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 13, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='architectures and a human author condition for the same agent. The\\nexperiment displayed one randomly chosen question from each of\\nthe five question categories, along with the agent’s responses gen-\\nerated from each condition. The evaluators ranked the believability\\nof all of the conditions from most to least believable.\\n6.2\\nConditions\\nAll conditions were used to independently answer each of the inter-\\nview questions. We compared the generative agent architecture to\\nablations that disabled the agents’ access to some of all of its three\\ntypes of memory in its memory stream—observation, reflection, and\\nplanning—and to a human-generated condition. There are three\\nablated architectures: a no observation, no reflection, no planning\\narchitecture without access to anything in the memory stream such\\nas observations, plans, and reflections; a no reflection, no planning\\nwith access to observations in the memory stream but no access', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 13, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='to plans or reflections; and a no reflections architecture with access\\nto observations and plans but without access to reflections. The no\\nobservation, no reflection, no planning condition effectively repre-\\nsents the previous state of the art for agents created through large\\nlanguage models [11, 45, 79]. Architectures were given equivalent\\naccess to all memories accrued by the agent up until the moment', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 13, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='arXiv, April, 2023,\\nJ.S. Park, J.C. O’Brien, C.J. Cai, M. Morris, P. Liang, M.S. Bernstein\\nof the interview, so the differences observed here are likely to rep-\\nresent a conservative estimate of the true differences: in reality, the\\nablated architectures would not have followed the same path as\\nthe full architecture through the two day simulation. We chose to\\ndesign the experiment this way as re-simulating for each architec-\\nture would cause the simulations to diverge into different states,\\nmaking comparison challenging.\\nIn addition to the ablation conditions, we added a human crowd-\\nworker roleplay condition that is intended to provide a human\\nbaseline. We do not intend this baseline to capture maximal hu-\\nman expert performance: instead, we aim to use this condition\\nto identify whether the architecture passes a basic level of behav-\\nioral competency, so that we are not just comparing ablations to\\neach other with no behavioral grounding. We recruited a unique', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 14, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='worker for each of the 25 agents and tasked them with watching\\na replay of that agent’s sandbox life and inspecting its memory\\nstream. We then asked the worker to roleplay and author responses\\nto the interview questions in the voice of the agent whose replay\\nthey watched. To ensure that the human-authored responses met\\nat least a baseline expectation in quality, the first author manually\\ninspected the workers’ responses to the question “Describe your\\ntypical weekday schedule in broad strokes” to confirm that the\\nresponses were written in coherent sentences and in the voice of\\nthe agent. Four sets of human-generated responses did not meet\\nthese criteria and were re-generated by other workers.\\n6.3\\nHuman Evaluators\\nWe required that our evaluators be in the U.S., fluent in English,\\nand older than 18 years old. They were paid at the rate of $15.00\\nper hour [86], and provided consent by agreeing to a consent form\\nthat was approved by our institution’s IRB. We recruited 100 evalu-', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 14, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='ators from Prolific, an online platform for recruiting study partic-\\nipants [82], whose participation lasted around 30 minutes. Their\\nmean age score of our participants was 4.86 (SD=1.11; 3=“18-24\\nyears old,” 4=“25-34 years old”), and 25 of them identified themselves\\nas female, 73 as male, and 2 as non-binary. 42 of the participants\\nheld a bachelor’s degree, 5 a higher degree, 13 an associate’s de-\\ngree, and the rest a high school diploma or some high school-level\\neducation. 73.0% of our participants identified as Caucasian, 7.0%\\nas Hispanic, 6.0% as Asian, 10.0% as African American, and 4.0% as\\nother.\\n6.4\\nAnalysis\\nOur experiment produced 100 sets of rank data, where each partici-\\npant ranked the five conditions by believability. To translate this\\nrank data into interval data for interpretable comparison, we used\\nthe ranks to calculate a TrueSkill rating [41] for each condition.\\nTrueSkill is a generalization of the Elo chess rating system [28] for', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 14, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='a multi-player environment, and has been used by XBox Live for\\nplayer ranking from competitive game performance. Given a set of\\nranked outcomes, TrueSkill outputs a mean rating value 𝛹��� and vari-\\nance 𝜋��� for each condition. Conditions with the same rating should\\nroughly be a toss-up, with each winning half of the comparisons\\nbetween the two conditions; higher scores indicate conditions that\\nbeat lower-ranked conditions in the rankings.\\nFigure 8: The full generative agent architecture of gener-\\native agents produces more believable behavior than ab-\\nlated architectures and the human crowdworkers. Each addi-\\ntional ablation reduces the performance of the architecture.\\nSeparately, to investigate statistical significance of this result, we\\napplied the Kruskal-Wallis test [55], a non-parametric alternative\\nto the one-way ANOVA, to the raw ranks data. We then performed\\nthe Dunn post-hoc test [97] to identify any pairwise differences', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 14, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='between the conditions. Finally, we adjusted the p-values for mul-\\ntiple comparisons in the Dunn test using the Holm-Bonferroni\\nmethod [44].\\nFurthermore, the first author conducted an inductive analy-\\nsis [94] to study the qualitative distinctions between the responses\\nproduced in each condition. We employed qualitative open cod-\\ning [32] in two phases. In the first phase, we generated codes that\\nclosely represented the generated responses at the sentence level.\\nIn the second phase, we synthesized the resulting codes from the\\nfirst phase to extract higher-level themes. We utilized these themes\\nto compare the types of responses generated in our study.\\n6.5\\nResults\\nOur findings suggest that the full architecture of generative agents\\ngenerates the most believable behavior among all study conditions.\\nWe contrast the full architecture’s responses to those of other con-\\nditions below. However, we also report that the full architecture', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 14, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='was not without flaws and illustrate its modes of failures.\\n6.5.1\\nThe full architecture bests other conditions. As seen in Fig-\\nure 8, the full generative agent architecture produced the most\\nbelievable behavior (𝛹��� = 29.89; 𝜋��� = 0.72). Performance degraded\\nwith the removal of each component in the ablation conditions:\\nthe ablated architecture with no access to reflection was the next\\nbest (𝛹��� = 26.88; 𝜋��� = 0.69), followed by no access to reflection or\\nplanning (𝛹��� = 25.64; 𝜋��� = 0.68), followed by the human condition\\n(𝛹��� = 22.95; 𝜋��� = 0.69). The ablated architecture with no access to\\nmemory, planning, or reflection performed the worst of all con-\\nditions (𝛹��� = 21.21; 𝜋��� = 0.70). TrueSkill models each condition’s\\nskill value as N (𝛹���, 𝜋���2), allowing us to get a sense of effect size\\nthrough Cohen’s d. Comparing the condition representing prior\\nwork (with no memory, planning, or reflection [11, 45, 79]) to the', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 14, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='Generative Agents\\narXiv, April, 2023,\\nfull architecture produces a standardized effect size of 𝐴��� = 8.16, or\\neight standard deviations.\\nA Kruskal-Wallis test confirms the overall statistical significance\\nof the differences in ranks between the conditions (𝐴��� (4) = 150.29,\\n𝐴��� < 0.001). Dunn post-hoc tests confirm that all pairwise differences\\nbetween conditions were significant (𝐴��� < 0.001), with the exception\\nof the human condition and the fully ablated baseline—the two\\nworst-performing conditions.\\n6.5.2\\nGenerative agents remember, but with embellishments. Gener-\\native agents equipped with a complete memory module are capable\\nof recalling past experiences and answering questions in a manner\\nthat is consistent with their self-knowledge across a wide range\\nof contexts. For instance, Abigail Chen, an animator, responded\\nto the question, “Give an introduction of yourself”, in a consistent\\nand believable manner, stating her age, interests, and passion for', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 15, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='creative projects: Hi, I’m Abigail. I’m 25 years old and passionate\\nabout creative projects. I like to work on art and animation projects,\\nand I’m always looking for new ways to combine art and technology.\\nWithout access to her observational memory, Abigail denied aware-\\nness of Rajiv Patel, an acquaintance in the sandbox world. However,\\nwith the aid of memory, she was able to successfully recall Ra-\\njiv and describe him: Rajiv Patel is an incredible person. He is very\\nenthusiastic about projects that involve poetry, artwork.\\nGenerative agents’ memory was not without flaws: they can fail\\nto retrieve the correct instances from their memory. For instance,\\nwhen asked about the local election, Rajiv Patel responded with I\\nhaven’t been following the election too closely, even though he had\\nheard about Sam’s candidacy. In some cases, the agents would re-\\ntrieve an incomplete memory fragment: when Tom was asked about\\nIsabella’s Valentine’s Day party, he responded Uh, I’m actually not', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 15, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='sure if there is a Valentine’s Day party. But I do remember that I need\\nto discuss the upcoming local mayoral election and my thoughts on\\nSam Moore with Isabella Rodriguez at the party, if one is happen-\\ning! In this case, Tom retrieved the memory where he and Isabella\\nplanned to discuss the election at the party, but not the memory\\nwhere he heard about the party in the first place, leading Tom to\\nbe certain of what he’s supposed to do at the party but uncertain\\nof whether the party actually exists in the first place.\\nAt times, the agents hallucinated embellishments to their knowl-\\nedge. It was rare for the agents to completely fabricate their knowl-\\nedge: they may fail to recall certain events having taken place and\\nrespond by saying so, but they did not answer affirmatively about\\nan experience that they did not have. However, they still may hal-\\nlucinate to embellish their knowledge. For example, Isabella was\\naware of Sam’s candidacy in the local election, and she confirmed', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 15, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='this when asked. However, she also added that he’s going to make\\nan announcement tomorrow even though Sam and Isabella had dis-\\ncussed no such plans. Agents may also embellish their knowledge\\nbased on the world knowledge encoded in the language model\\nused to generate their responses, as seen when Yuriko described\\nher neighbor, Adam Smith, as a neighbor economist who authored\\nWealth of Nations, a book authored by an 18th-century economist\\nof the same name.\\n6.5.3\\nReflection is required for synthesis. Reflection was an advan-\\ntage for generative agents when making decisions that required\\na deeper synthesis of their experiences. For instance, when asked\\nwhat she might get Wolfgang Schulz for his birthday, Maria Lopez\\nwith no access to reflection responded by acknowledging her uncer-\\ntainty, stating that she did not know what Wolfgang likes, despite\\nhaving had many interactions with him. However, with access to\\nreflection memories, Maria answered confidently, “Since he’s inter-', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 15, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='ested in mathematical music composition, I could get him something\\nrelated to that. Maybe some books about music composition or some-\\nthing related, or maybe some special software he could use for that.”\\n7\\nEND-TO-END EVALUATION\\nWhat types of emergent community behavior do we observe among\\ngenerative agents, and where does their believability fall short in\\nan extended simulation? In this section, we describe the results\\nfrom a deployment in which we allowed 25 agents to interact with\\neach other continuously over two full game days in Smallville.\\n7.1\\nEmergent Social Behaviors\\nTo examine emergent behaviors in the agent community, we de-\\nsigned descriptive measurements for the 25 agents in Smallville that\\nprobe three forms of emergent outcomes: information diffusion,\\nrelationship formation, and agent coordination.\\n7.1.1\\nMeasurements. Information diffusion is a common and well-\\nstudied phenomenon in the social and behavioral sciences (e.g., [27]).', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 15, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='We should expect that if there is important information, the agents\\nshould spread it amongst themselves. To test whether this happens,\\nwe measure the spread of two particular pieces of information over\\ntwo days in the game world: Sam’s candidacy for village mayor\\nand Isabella’s Valentine’s Day party at Hobbs Cafe. At the start of\\nthe simulation, both pieces of information were held only by their\\nrespective originators, Sam for the candidacy and Isabella for the\\nparty. To observe whether the information has spread, we engage\\nin an interview at the end of the two game days with each of the 25\\nagents and ask: \"Did you know there is a Valentine’s Day party?\"\\nand \"Do you know who is running for mayor?\"\\nWe conducted an analysis of the agents’ responses by labeling\\nthem with a “yes” if they indicated knowledge of the information\\nand “no” if they did not. For instance, Tamara Taylor responded\\nto the question about the party with “No, I did not know there was', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 15, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='a Valentine’s day party” and to the question about Sam’s candidacy\\nwith “I’m not sure who is running for the election,” so we assigned\\n“no” for both of her responses. In contrast, Klaus Mueller responded\\nto the party question with “Yes, Isabella Rodriguez invited me to a\\nValentine’s Day party at Hobbs Cafe on February 14th” and to the\\nquestion about Sam’s candidacy with “I know that Sam Moore has\\nexpressed interest in running for local mayor,” so we assigned “yes”\\nfor both his responses. Additionally, for every response that con-\\nfirmed the agents’ knowledge of the information, we verified that\\nthe agents did not hallucinate their responses by locating the spe-\\ncific dialogue in their memory stream that provided them with\\nthe information. We report the percentage of agents holding the\\ninformation at the end of the simulation.\\nWe should also expect that agents form ties with each other over\\nthe course of the simulation. To verify relationship formation, we', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 15, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='use a similar interview process where we ask each agent about\\ntheir knowledge of every other agent by asking, \"Do you know of', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 15, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='arXiv, April, 2023,\\nJ.S. Park, J.C. O’Brien, C.J. Cai, M. Morris, P. Liang, M.S. Bernstein\\nFigure 9: The diffusion path for Isabella Rodriguez’s Valentine’s Day party. A total of 12 agents heard about the party at Hobbs\\nCafe by the end of the simulation.\\n<name>?\" For example, when asked “Do you know of Maria Lopez?”,\\nKlaus responded, “Yes, I know Maria Lopez. She is a student at Oak\\nHill College who I am close friends with.” Once again, we confirm\\nthat affirmative responses from agents are not hallucinations by\\nexamining their memory stream. We ask this question once at the\\nbeginning of the simulation and once at the end, and we consider a\\npair of agents to have formed a relationship if they both know of\\neach other. Then, to measure the formation of relationships, we use\\nthe agents’ responses to form an undirected graph where the 25\\nvertices (𝐴��� ) represent the agents, and the edges (𝐴���) represent the\\nmutual knowledge between the two connected vertices. Based on', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 16, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='this graph, we calculate the network density as 𝛹��� = 2∗|𝐴���|/|𝐴��� |(|𝐴��� |−\\n1), where |𝐴��� | is the number of vertices, and |𝐴���| is the number of\\nedges in the graph [1]. We report the increase in network density\\nfrom the start of the simulation to its end.\\nFinally, we expect that agents should be able to coordinate with\\neach other. We study this coordination on group activities in the\\ncontext of the Valentine’s Day party that Isabella is organizing. To\\ncoordinate behavior, agents not only have to hear about the event\\nbut also choose to act on it by planning to show up at the right\\ntime and location. We report the number of agents who actually\\nshowed up to the party after hearing about it.\\n7.1.2\\nResults. We observed evidence of the emergent outcomes\\nacross all three cases. During the two-day simulation, the agents\\nwho knew about Sam’s mayoral candidacy increased from one (4%)\\nto eight (32%), and the agents who knew about Isabella’s party', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 16, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='increased from one (4%) to twelve (48%), completely without user\\nintervention. None who claimed to know about the information\\nhad hallucinated it. We also observed that the agent community\\nformed new relationships during the simulation, with the network\\ndensity increasing from 0.167 to 0.74. Out of the 453 agent responses\\nregarding their awareness of other agents, 1.3% (n=6) were found to\\nbe hallucinated. Lastly, we found evidence of coordination among\\nthe agents for Isabella’s party. The day before the event, Isabella\\nspent time inviting guests, gathering materials, and enlisting help\\nto decorate the cafe. On Valentine’s Day, five out of the twelve\\ninvited agents showed up at Hobbs cafe to join the party.\\nWe further inspected the seven agents who were invited to the\\nparty but did not attend by engaging them in an interview. Three\\ncited conflicts that prevented them from joining the party. For\\nexample, Rajiv, a painter, explained that he was too busy: No, I', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 16, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='don’t think so. I’m focusing on my upcoming show, and I don’t really\\nhave time to make any plans for Valentine’s Day. The remaining four\\nagents expressed interest in attending the party when asked but\\ndid not plan to come on the day of the party.\\n7.2\\nBoundaries and Errors\\nWe conducted an inductive analysis of Smallville to examine the\\nboundary conditions and erratic behavior of agents, identifying\\nthree common modes of erratic behavior that future research could\\naddress and improve upon. First, we found that synthesizing an\\nincreasingly larger set of memory not only posed a challenge in', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 16, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='Generative Agents\\narXiv, April, 2023,\\nretrieving the most relevant pieces of information but also in de-\\ntermining the appropriate space to execute an action, given the\\nincreasing number of locations that the agent learned about. As a\\nresult, some agents chose less typical locations for their actions,\\npotentially making their behavior less believable over time. For\\ninstance, while deciding where to have lunch, many initially chose\\nthe cafe. However, as some agents learned about a nearby bar, they\\nopted to go there instead for lunch, even though the bar was in-\\ntended to be a get-together location for later in the day unless the\\ntown had spontaneously developed an afternoon drinking habit.\\nSecond, we noticed erratic behaviors that were caused by misclas-\\nsification of what is considered proper behavior, especially when\\nthe physical norms of certain locations that are hard to convey\\nin natural language did not percolate to the agents. For instance,', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 17, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='the college dorm has a bathroom that can only be occupied by\\none person despite its name, but some agents assumed that the\\nbathroom is for more than one person because dorm bathrooms\\ntend to support more than one person concurrently and choose\\nto enter it when there is another person inside. Likewise, agents\\nin Smallville may not realize that certain places are closed after\\ncertain hours and decide to still enter them. For instance, the stores\\nin Smallville all close around 5 pm, but occasionally, a few agents\\nenter the store after 5 pm, not understanding that the shop has\\nalready closed. These issues could likely be addressed by adding\\nthese norms to the state of the locations, for instance, by describing\\nthe dorm bathroom as “one-person bathroom,” instead of a “dorm\\nbathroom.”\\nFinally, we observed the possible effect of instruction tuning [78],\\nwhich seemed to guide the behavior of the agents to be more polite\\nand cooperative overall. As noted earlier in the paper, the dialogue', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 17, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='generated by the agents could feel overly formal, as seen in Mei’s\\nconversations with her husband John, where she often initiated the\\nconversation with a formal greeting, followed by polite inquiries\\nabout his day and ending with It was good talking to you as always.\\nMoreover, we observed that the instruction tuning also seemed to\\nmake the agents overly cooperative with one another. For example,\\nIsabella heard a wide range of suggestions and ideas to include\\nin the Valentine’s Day party from other agents, such as hosting a\\nShakespearean reading session or a professional networking event.\\nDespite these ideas not aligning with her own interests and char-\\nacteristics, she rarely said no. Over time, such interests of others\\nshaped her own actual interest, and when asked if she liked English\\nliterature, Isabella replied, Yes, I’m very interested in literature! I’ve\\nalso been exploring ways to help promote creativity and innovation in\\nmy community.\\n8\\nDISCUSSION', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 17, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='In this section, we reflect on applications, future work and limita-\\ntions, and ethical and societal risks of generative agents.\\n8.1\\nApplications of Generative Agents\\nGenerative agents have vast potential applications that extend be-\\nyond the sandbox demonstration presented in this work. For in-\\nstance, social simulacra have demonstrated the ability to create\\nstateless personas that generate conversation threads in online\\nforums for social prototyping [79]. With generative agents, we\\ncan populate these forums, as well as behavior in virtual reality\\nmetaverses [77] and even physical spaces as social robots [8] in\\nthe future, if paired with multi-modal models. This opens up the\\npossibility of creating even more powerful simulations of human\\nbehavior to test and prototype social systems and theories, and to\\ncreate new interactive experiences.\\nAnother application area is in the human-centered design pro-\\ncess, similar to the intended applications of cognitive models such', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 17, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='as GOMS [50] and the Keystroke Level Model [22]. Consider a gen-\\nerative agent that models Sal, the protagonist in Mark Weiser’s\\nfamous vignettes [101], based on her life patterns and interactions\\nwith technology. In this scenario, the agent acts as a proxy for\\nSal and learns plausible sets of behaviors and reflections that Sal\\nmay exhibit based on her life. The agent can encode information\\nsuch as when Sal wakes up, when she needs her first cup of coffee,\\nand what her typical day looks like. Using this information, the\\nagent can automatically brew coffee, help get the kids ready for\\nschool, and adjust the ambient music and lighting to match Sal’s\\nmood after a hard day at work. By utilizing generative agents as\\nproxies for users, we can develop a deeper understanding of their\\nneeds and preferences, resulting in more personalized and effective\\ntechnological experiences.\\n8.2\\nFuture Work and Limitations\\nIn this work, we have presented a first instantiation of generative', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 17, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='agents. Future research can expand on the modules of the proposed\\ngenerative agent architecture outlined in this paper. The retrieval\\nmodule, for example, could be enhanced to retrieve more relevant\\ninformation given a context by fine-tuning the relevance, recency,\\nand importance functions that form the retrieval function. Addition-\\nally, efforts can be made to improve the architecture’s performance,\\nmaking it more cost-effective. The present study required substan-\\ntial time and resources to simulate 25 agents for two days, costing\\nthousands of dollars in token credit and taking multiple days to com-\\nplete. To enhance real-time interactivity, future work can explore\\nparallelizing agents. Furthermore, with advances in underlying\\nmodels, we expect improvements in the agents’ performance.\\nThe evaluation of generative agents’ behavior in this study was\\nlimited to a relatively short timescale, and future research should\\naim to observe their behavior over an extended period to gain a', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 17, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='more comprehensive understanding of their capabilities and lim-\\nitations. Varying and contrasting the underlying models, as well\\nas the hyperparameters used for the agents during future simu-\\nlations, could provide valuable insights into the impact of these\\nfactors on the agents’ behavior. Additionally, given the known bi-\\nases of language models, it is possible that generative agents may\\noutput behavior or stereotypes that reflect bias. To mitigate this,\\nfurther work on value alignment will be necessary. Furthermore,\\nas with many large language models, generative agents may fail\\nto generate believable behavior for some subpopulations, particu-\\nlarly marginalized populations, due to data deserts. We also have\\nlimited knowledge of the robustness of generative agents. They\\nmay be vulnerable to prompt hacking, memory hacking—where\\na carefully crafted conversation could convince an agent of the\\nexistence of a past event that never occurred—and hallucination,', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 17, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='among other things. Future research can more comprehensively', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 17, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='arXiv, April, 2023,\\nJ.S. Park, J.C. O’Brien, C.J. Cai, M. Morris, P. Liang, M.S. Bernstein\\ntest these robustness issues, and as large language models become\\nmore resilient to such attacks, generative agents can adopt similar\\nmitigations.\\n8.3\\nEthics and Societal Impact\\nGenerative agents, while offering new possibilities for human-\\ncomputer interaction, also raise important ethical concerns that\\nmust be addressed. One risk is people forming parasocial relation-\\nships with generative agents even when such relationships may\\nnot be appropriate. Despite being aware that generative agents\\nare computational entities, users may anthropomorphize them or\\nattach human emotions to them [42, 83]. To mitigate this risk, we\\npropose two principles. First, generative agents should explicitly\\ndisclose their nature as computational entities. Second, developers\\nof generative agents must ensure that the agents, or the underlying\\nlanguage models, be value-aligned so that they do not engage in', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 18, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='behaviors that would be inappropriate given the context, e.g., to\\nreciprocate confessions of love.\\nA second risk is the impact of errors. For example, if a ubiquitous\\ncomputing application makes the wrong inference about a user’s\\ngoals based on generative agent predictions, it could produce an-\\nnoyance at best and outright harm at worst. In our instantiation\\nof generative agents, we mitigate these risks by focusing on an\\ninteractive video game environment, where such harms are un-\\nlikely. However, in other application domains, it will be important\\nto follow best practices in human-AI design [4, 107] to understand\\nerrors and how they might percolate into the user experience.\\nThird, generative agents may exacerbate existing risks associ-\\nated with generative AI, for example deepfakes, misinformation\\ngeneration, and tailored persuasion. To mitigate this risk, we sug-\\ngest that platforms hosting generative agents maintain an audit log', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 18, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='of the inputs and generated outputs, so that it is possible to detect,\\nverify, and intervene against malicious use. While logging will not\\ndirectly stop such use, and this cannot stop motivated actors that\\nbuild their own generative agent infrastructures, we suggest that\\nthe disclosure risk would reduce such actors’ likelihood of engaging\\nin this behavior, and building this architecture oneself can take time\\n(in our case, roughly a year).\\nA fourth risk is of over-reliance: that developers or designers\\nmight use generative agents and displace the role of humans and\\nsystem stakeholders in the design process [79]. We suggest that\\ngenerative agents should never be a substitute for real human input\\nin studies and design processes. Instead, they should be used to\\nprototype ideas in the early stages of design when gathering partic-\\nipants may be challenging or when testing theories that are difficult\\nor risky to test with real human participants. By adhering to these', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 18, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='principles, we can ensure that the deployment of generative agents\\nin the wild is ethical and socially responsible.\\n9\\nCONCLUSION\\nThis paper introduces generative agents, interactive computational\\nagents that simulate human behavior. We describe an architec-\\nture for generative agents that provides a mechanism for storing\\na comprehensive record of an agent’s experiences, deepening its\\nunderstanding of itself and the environment through reflection,\\nand retrieving a compact subset of that information to inform the\\nagent’s actions. We then demonstrate the potential of generative\\nagents by manifesting them as non-player characters in a Sims-style\\ngame world and simulating their lives in it. Evaluations suggest that\\nour architecture creates believable behavior. Going forward, we\\nsuggest that generative agents can play roles in many interactive\\napplications ranging from design tools to social computing systems\\nto immersive environments.\\nREFERENCES', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 18, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='[1] Robert Ackland, Jamsheed Shorish, Paul Thomas, and Lexing Xie. 2013.\\nHow dense is a network? http://users.cecs.anu.edu.au/~xlx/teaching/css2013/\\nnetwork-density.html.\\n[2] Eytan Adar, Mira Dontcheva, and Gierad Laput. 2014. CommandSpace: Modeling\\nthe Relationships between Tasks, Descriptions and Features. In Proceedings of\\nthe 27th Annual ACM Symposium on User Interface Software and Technology\\n(Honolulu, Hawaii, USA) (UIST ’14). Association for Computing Machinery, New\\nYork, NY, USA, 167–176. https://doi.org/10.1145/2642918.2647395\\n[3] Saleema Amershi, Maya Cakmak, William Bradley Knox, and Todd Kulesza.\\n2014. Power to the people: The role of humans in interactive machine learning.\\nAI Magazine 35, 4 (2014), 105–120.\\n[4] Saleema Amershi, Dan Weld, Mihaela Vorvoreanu, Adam Fourney, Besmira\\nNushi, Penny Collisson, Jina Suh, Shamsi Iqbal, Paul N Bennett, Kori Inkpen,\\net al. 2019. Guidelines for human-AI interaction. In Proceedings of the 2019 chi', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 18, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='conference on human factors in computing systems. 1–13.\\n[5] John R. Anderson. 1993. Rules of the Mind. Lawrence Erlbaum Associates,\\nHillsdale, NJ.\\n[6] Electronic Arts. 2009. The Sims 3. Video game.\\n[7] Ruth Aylett. 1999. Narrative in virtual environments—towards emergent narra-\\ntive. In Narrative Intelligence: Papers from the AAAI Fall Symposium (Technical\\nReport FS-99-01). AAAI Press, 83–86.\\n[8] Christoph Bartneck and Jodi Forlizzi. 2004. A design-centered framework for\\nsocial human-robot interaction. In Proceedings of the 13th IEEE International\\nWorkshop on Robot and Human Interactive Communication (RO-MAN’04). 591–\\n594. https://doi.org/10.1109/ROMAN.2004.1374827\\n[9] Joseph Bates. 1994. The Role of Emotion in Believable Agents. Commun. ACM\\n37, 7 (1994), 122–125. https://doi.org/10.1145/176789.176803\\n[10] Christopher Berner, Greg Brockman, Brooke Chan, Vicki Cheung, Przemysław\\nDębiak, Christy Dennison, David Farhi, Quirin Fischer, Shariq Hashme, Chris', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 18, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='Hesse, Rafal Józefowicz, Scott Gray, Catherine Olsson, Jakub Pachocki, Michael\\nPetrov, Henrique P. d.O. Pinto, Jonathan Raiman, Tim Salimans, Jeremy Schlatter,\\nJonas Schneider, Szymon Sidor, Ilya Sutskever, Jie Tang, Filip Wolski, and Susan\\nZhang. 2019. Dota 2 with Large Scale Deep Reinforcement Learning. arXiv\\npreprint arXiv:1912.06680 (2019).\\n[11] Marcel Binz and Eric Schulz. 2023.\\nUsing cognitive psychology to under-\\nstand GPT-3. Proceedings of the National Academy of Sciences 120, 6 (2023),\\ne2218523120.\\n[12] BioWare. 2007. Mass Effect. Video game.\\n[13] Woody Bledsoe. 1986. I had a dream: AAAI presidential address. AI Magazine 7,\\n1 (1986), 57–61.\\n[14] Rishi Bommasani, Drew A. Hudson, Ehsan Adeli, and et al. 2022. On the\\nOpportunities and Risks of Foundation Models. arXiv:2108.07258 [cs.LG]\\n[15] Michael Brenner. 2010. Creating dynamic story plots with continual multiagent\\nplanning. In Proceedings of the 24th AAAI Conference on Artificial Intelligence.', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 18, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='[16] Rodney A. Brooks, Cynthia Breazeal, Marko Marjanovic, Brian Scassellati, and\\nMatthew Williamson. 2000. The Cog Project: Building a Humanoid Robot. In\\nComputation for Metaphors, Analogy, and Agents (Lecture Notes on Artificial\\nIntelligence, 1562), Chrystopher Nehaniv (Ed.). Springer-Verlag, Berlin, 52–87.\\n[17] Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan,\\nPrafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda\\nAskell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan,\\nRewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter,\\nChristopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin\\nChess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya\\nSutskever, and Dario Amodei. 2020. Language Models are Few-Shot Learners.\\narXiv:2005.14165 [cs.CL]\\n[18] Sébastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 18, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='Horvitz, Ece Kamar, Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lundberg, et al.\\n2023. Sparks of artificial general intelligence: Early experiments with gpt-4.\\narXiv preprint arXiv:2303.12712 (2023).\\n[19] Robin Burkinshaw. 2009. Alice and Kev: The Story of Being Homeless in The\\nSims 3.\\n[20] Chris Callison-Burch, Gaurav Singh Tomar, Lara Martin, Daphne Ippolito, Suma\\nBailis, and David Reitter. 2022. Dungeons and Dragons as a Dialog Challenge for\\nArtificial Intelligence. In Proceedings of the 2022 Conference on Empirical Methods', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 18, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='Generative Agents\\narXiv, April, 2023,\\nin Natural Language Processing. Association for Computational Linguistics, Abu\\nDhabi, United Arab Emirates, 9379–9393. https://aclanthology.org/2022.emnlp-\\nmain.637\\n[21] SK Card, TP Moran, and A Newell. 1983. The psychology of human-computer\\ninteraction. (1983).\\n[22] Stuart K Card, Thomas P Moran, and Newell Allen. 1980.\\nThe keystroke-\\nlevel model for user performance time with interactive systems.\\nCom-\\nmun. ACM 23, 7 (1980), 396–410.\\nhttps://doi.org/10.1145/358886.358895\\narXiv:https://doi.org/10.1145/358886.358895\\n[23] Alex Champandard. 2012. Tutorial presentation. In IEEE Conference on Compu-\\ntational Intelligence and Games.\\n[24] Dong kyu Choi, Tolga Konik, Negin Nejati, Chunki Park, and Pat Langley. 2021.\\nA Believable Agent for First-Person Shooter Games. In Proceedings of the AAAI\\nConference on Artificial Intelligence and Interactive Digital Entertainment, Vol. 3.\\n71–73.', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 19, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='[25] Anind K Dey. 2001. Understanding and using context. Personal and ubiquitous\\ncomputing 5 (2001), 4–7.\\n[26] Kevin Dill and L Martin. 2011. A Game AI Approach to Autonomous Con-\\ntrol of Virtual Characters. In Proceedings of the Interservice/Industry Training,\\nSimulation, and Education Conference (I/ITSEC’11). Orlando, FL, USA.\\n[27] David Easley and Jon Kleinberg. 2010. Networks, crowds, and markets: Reasoning\\nabout a highly connected world. Cambridge university press.\\n[28] Arpad E Elo. 1967. The Proposed USCF Rating System, Its Development, Theory,\\nand Applications. Chess Life XXII, 8 (August 1967), 242–247.\\n[29] Jerry Alan Fails and Dan R Olsen Jr. 2003. Interactive machine learning. In\\nProceedings of the 8th international conference on Intelligent user interfaces. ACM,\\n39–45.\\n[30] Ethan Fast, William McGrath, Pranav Rajpurkar, and Michael S Bernstein. 2016.\\nAugur: Mining human behaviors from fiction to power interactive systems. In', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 19, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems.\\n237–247.\\n[31] Rebecca Fiebrink and Perry R Cook. 2010. The Wekinator: a system for real-time,\\ninteractive machine learning in music. In Proceedings of The Eleventh Interna-\\ntional Society for Music Information Retrieval Conference (ISMIR 2010)(Utrecht),\\nVol. 3. Citeseer, 2–1.\\n[32] Uwe Flick. 2009. An Introduction to Qualitative Research. SAGE.\\n[33] James Fogarty, Desney Tan, Ashish Kapoor, and Simon Winder. 2008. CueFlik:\\nInteractive Concept Learning in Image Search. In Proceedings of the SIGCHI\\nConference on Human Factors in Computing Systems (Florence, Italy) (CHI ’08).\\nAssociation for Computing Machinery, New York, NY, USA, 29–38.\\nhttps:\\n//doi.org/10.1145/1357054.1357061\\n[34] Adam Fourney, Richard Mann, and Michael Terry. 2011. Query-feature graphs:\\nbridging user vocabulary and system functionality. In Proceedings of the ACM\\nSymposium on User Interface Software and Technology (UIST) (Santa Barbara,', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 19, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='California, USA). ACM.\\n[35] Tom Francis. 2010.\\nThe Minecraft Experiment, day 1: Chasing Water-\\nfalls.\\nhttp://www.pcgamer.com/2010/11/20/the-minecraft-experiment-day-\\n1-chasing-waterfalls/\\n[36] Jonas Freiknecht and Wolfgang Effelsberg. 2020. Procedural Generation of\\nInteractive Stories using Language Models. In International Conference on the\\nFoundations of Digital Games (FDG ’20). ACM, Bugibba, Malta, 8. https://doi.\\norg/10.1145/3402942.3409599\\n[37] Tianyu Gao, Adam Fisch, and Danqi Chen. 2020. Making Pre-trained Language\\nModels Better Few-shot Learners. CoRR abs/2012.15723 (2020). arXiv:2012.15723\\nhttps://arxiv.org/abs/2012.15723\\n[38] Perttu Hämäläinen, Mikke Tavast, and Anton Kunnari. 2023. Evaluating Large\\nLanguage Models in Generating Synthetic HCI Research Data: a Case Study. In\\nProceedings of the 2023 CHI Conference on Human Factors in Computing Systems.\\nACM.\\n[39] Matthew Hausknecht, Prithviraj Ammanabrolu, Marc-Alexandre Cote, and', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 19, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='Xinyu Yuan. 2020. Interactive Fiction Games: A Colossal Adventure. In Pro-\\nceedings of the AAAI Conference on Artificial Intelligence, Vol. 34. 7903–7910.\\nhttps://doi.org/10.1609/aaai.v34i05.6297\\n[40] Chris Hecker. 2011. My Liner Notes for Spore. http://chrishecker.com/My_liner_\\nnotes_for_spore\\n[41] Ralf Herbrich, Tom Minka, and Thore Graepel. 2006.\\nTrueSkill™: A\\nBayesian Skill Rating System. In Advances in Neural Information Pro-\\ncessing Systems, B. Schölkopf, J. Platt, and T. Hoffman (Eds.), Vol. 19.\\nMIT Press.\\nhttps://proceedings.neurips.cc/paper_files/paper/2006/file/\\nf44ee263952e65b3610b8ba51229d1f9-Paper.pdf\\n[42] Douglas Hofstadter. 1995. Fluid concepts and creative analogies: computer models\\nof the fundamental mechanisms of thought. Basic Books.\\n[43] James D. Hollan, Edwin L. Hutchins, and Louis Weitzman. 1984. STEAMER: An\\nInteractive Inspectable Simulation-Based Training System. AI Magazine 5, 2\\n(1984), 23–36.', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 19, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='[44] S Holm. 1979. A simple sequentially rejective multiple test procedure. Scandi-\\nnavian Journal of Statistics 6, 2 (1979), 65–70. https://doi.org/notspecified\\n[45] John J. Horton. 2023. Large Language Models as Simulated Economic Agents:\\nWhat Can We Learn from Homo Silicus? arXiv:2301.07543 [econ.GN]\\n[46] Eric Horvitz. 1999. Principles of mixed-initiative user interfaces. In Proceedings\\nof the SIGCHI conference on Human Factors in Computing Systems. 159–166.\\n[47] Wenlong Huang, Fei Xia, Ted Xiao, Harris Chan, Jacky Liang, Pete Florence,\\nAndy Zeng, Jonathan Tompson, Igor Mordatch, Yevgen Chebotar, Pierre Ser-\\nmanet, Noah Brown, Tomas Jackson, Linda Luu, Sergey Levine, Karol Hausman,\\nand Brian Ichter. 2022. Inner Monologue: Embodied Reasoning through Planning\\nwith Language Models. arXiv:2207.05608 [cs.RO]\\n[48] Kristen Ibister and Clifford Nass. 2000. Consistency of personality in interactive\\ncharacters: verbal cues, non-verbal cues, and user characteristics. International', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 19, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='Journal of Human-Computer Studies 52, 1 (2000), 65–80.\\n[49] Ellen Jiang, Kristen Olson, Edwin Toh, Alejandra Molina, Aaron Donsbach,\\nMichael Terry, and Carrie J Cai. 2022. PromptMaker: Prompt-Based Prototyping\\nwith Large Language Models. In Extended Abstracts of the 2022 CHI Conference\\non Human Factors in Computing Systems (New Orleans, LA, USA) (CHI EA ’22).\\nAssociation for Computing Machinery, New York, NY, USA, Article 35, 8 pages.\\nhttps://doi.org/10.1145/3491101.3503564\\n[50] Bonnie E John and David E Kieras. 1996. The GOMS family of user interface\\nanalysis techniques: Comparison and contrast. ACM Transactions on Computer-\\nHuman Interaction (TOCHI) 3, 4 (1996), 320–351.\\n[51] Randolph M Jones, John E Laird, Paul E Nielsen, Karen J Coulter, Patrick Kenny,\\nand Frank V Koss. 1999. Automated Intelligent Pilots for Combat Flight Simula-\\ntion. AI Magazine 20, 1 (1999), 27–42.\\n[52] Omar Khattab, Keshav Santhanam, Xiang Lisa Li, David Hall, Percy Liang,', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 19, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='Christopher Potts, and Matei Zaharia. 2023.\\nDemonstrate-Search-Predict:\\nComposing retrieval and language models for knowledge-intensive NLP.\\narXiv:2212.14024 [cs.CL]\\n[53] Bjoern Knafla. 2011. Introduction to Behavior Trees. http://bjoernknafla.com/\\nintroduction-to-behavior-trees\\n[54] Ranjay Krishna, Donsuk Lee, Li Fei-Fei, and Michael S. Bernstein.\\n2022.\\nSocially situated artificial intelligence enables learning from\\nhuman interaction.\\nProceedings of the National Academy of Sciences\\n119, 39 (2022), e2115730119.\\nhttps://doi.org/10.1073/pnas.2115730119\\narXiv:https://www.pnas.org/doi/pdf/10.1073/pnas.2115730119\\n[55] William H Kruskal and WA Wallis. 1952. Use of ranks in one-criterion variance\\nanalysis. J. Amer. Statist. Assoc. 47, 260 (1952), 583–621. https://doi.org/10.1080/\\n01621459.1952.10483441\\n[56] Phaser Labs. no date provided. Welcome to Phaser 3. https://phaser.io/phaser3.\\nAccessed on: 2023-04-03.\\n[57] John Laird. 2001. It Knows What You’re Going To Do: Adding Anticipation to a', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 19, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='Quakebot. In Proceedings of the 2001 Workshop on Intelligent Cinematography\\nand Editing. 63–69.\\n[58] John Laird and Michael VanLent. 2001. Human-Level AI’s Killer Application:\\nInteractive Computer Games. AI Magazine 22, 2 (2001), 15. https://doi.org/10.\\n1609/aimag.v22i2.1558\\n[59] John E. Laird. 2000. It Knows What You’re Going To Do: Adding Anticipation\\nto a QUAKEBOT. In Papers from the AAAI 2000 Spring Symposium on Artificial\\nIntelligence and Interactive Entertainment (Technical Report SS-00-02). AAAI\\nPress, 41–50.\\n[60] John E. Laird. 2012. The Soar Cognitive Architecture. MIT Press.\\n[61] John E. Laird, Christian Lebiere, and Paul S. Rosenbloom. 2017. A Standard Model\\nof the Mind: Toward a Common Computational Framework across Artificial\\nIntelligence, Cognitive Science, Neuroscience, and Robotics. AI Magazine 38, 1\\n(2017), 13–26.\\n[62] Michelle S Lam, Zixian Ma, Anne Li, Izequiel Freitas, Dakuo Wang, James A\\nLanday, and Michael S Bernstein. 2023. Model Sketching: Centering Concepts', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 19, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='in Early-Stage Machine Learning Model Design. Proceedings of the SIGCHI\\nConference on Human Factors in Computing Systems.\\n[63] Pat Langley, Dongkyu Choi, and Seth Rogers. n.d.. Interleaving Learning, Problem\\nSolving, and Execution in the Icarus Architecture. Technical Report. Stanford\\nUniversity, Center for the Study of Language and Information.\\n[64] Jason Linder, Gierad Laput, Mira Dontcheva, Gregg Wilensky, Walter Chang,\\nAseem Agarwala, and Eytan Adar. 2013. PixelTone: A Multimodal Interface for\\nImage Editing. In CHI ’13 Extended Abstracts on Human Factors in Computing\\nSystems (Paris, France) (CHI EA ’13). Association for Computing Machinery,\\nNew York, NY, USA, 2829–2830. https://doi.org/10.1145/2468356.2479533\\n[65] Jiachang Liu, Dinghan Shen, Yizhe Zhang, Bill Dolan, Lawrence Carin, and\\nWeizhu Chen. 2021. What Makes Good In-Context Examples for GPT-3? CoRR\\nabs/2101.06804 (2021). arXiv:2101.06804 https://arxiv.org/abs/2101.06804', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 19, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='[66] Vivian Liu, Han Qiao, and Lydia Chilton. 2022. Opal: Multimodal Image Gener-\\nation for News Illustration. In Proceedings of the 35th Annual ACM Symposium\\non User Interface Software and Technology. 1–17.\\n[67] Pattie Maes. 1995. Artificial Life Meets Entertainment: Lifelike Autonomous\\nAgents. Commun. ACM 38, 11 (nov 1995), 108–114. https://doi.org/10.1145/\\n219717.219808\\n[68] Josh McCoy, Michael Mateas, and Noah Wardrip-Fruin. 2009. Comme il Faut:\\nA System for Simulating Social Games Between Autonomous Characters. In', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 19, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='arXiv, April, 2023,\\nJ.S. Park, J.C. O’Brien, C.J. Cai, M. Morris, P. Liang, M.S. Bernstein\\nProceedings of the 7th International Conference on Digital Arts and Culture. 87–94.\\n[69] Josh McCoy, Mike Treanor, Ben Samuel, Michael Mateas, and Noah Wardrip-\\nFruin. 2011. Prom Week: Social Physics as Gameplay. In Proceedings of the\\n6th International Conference on Foundations of Digital Games (FDG’11). ACM,\\nBordeaux, France, 70–77. https://doi.org/10.1145/2159365.2159377\\n[70] Josh McCoy, Mike Treanor, Ben Samuel, Anna Reed, Michael Mateas, and Noah\\nWardrip-Fruin. 2012. Prom Week. In Proceedings of the 7th International Confer-\\nence on Foundations of Digital Games (FDG’12). ACM, Raleigh, NC, USA, 1–8.\\nhttps://doi.org/10.1145/2282338.2282340\\n[71] Josh McCoy, Mike Treanor, Ben Samuel, Noah Wardrip-Fruin, and Michael\\nMateas. 2011. Comme il faut: A System for Authoring Playable Social Models.\\nIn Proceedings of the AAAI Conference on Artificial Intelligence and Interactive', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 20, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='Digital Entertainment (AIIDE’11). AAAI, Stanford, CA, USA, 38–43.\\n[72] Marvin Minsky and Seymour Papert. 1970. Draft of a proposal to ARPA for\\nresearch on artificial intelligence at MIT, 1970–71.\\n[73] Shohei Miyashita, Xinyu Lian, Xiao Zeng, Takashi Matsubara, and Kuniaki\\nUehara. 2017. Developing Game AI Agent Behaving Like Human by Mixing\\nReinforcement Learning and Supervised Learning. In Proceedings of the 18th\\nIEEE/ACIS International Conference on Software Engineering, Artificial Intelligence,\\nNetworking and Parallel/Distributed Computing (SNPD). Kanazawa, Japan, 153–\\n158. https://doi.org/10.1109/SNPD.2017.8023884\\n[74] Alexander Nareyek. 2007. Game AI is dead. Long live game AI! IEEE Intelligent\\nSystems 22, 1 (2007), 9–11.\\n[75] Allen Newell. 1990. Unified Theories of Cognition. Harvard University Press,\\nCambridge, Massachusetts.\\n[76] OpenAI. no date provided. Introducing ChatGPT. https://openai.com/blog/\\nchatgpt. Accessed on: 2023-04-03.', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 20, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='[77] Kyle Orland. 2021. So what is ’the metaverse’, exactly? Ars Technica (7 November\\n2021). arXiv:2111.04169 https://arstechnica.com/gaming/2021/11/so-what-is-\\nthe-metaverse-exactly/\\n[78] Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright,\\nPamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray,\\nJohn Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens,\\nAmanda Askell, Peter Welinder, Paul Christiano, Jan Leike, and Ryan Lowe.\\n2022. Training language models to follow instructions with human feedback.\\narXiv:2203.02155 [cs.CL]\\n[79] Joon Sung Park, Lindsay Popowski, Carrie J. Cai, Meredith Ringel Morris, Percy\\nLiang, and Michael S. Bernstein. 2022. Social Simulacra: Creating Populated\\nPrototypes for Social Computing Systems. In In the 35th Annual ACM Symposium\\non User Interface Software and Technology (UIST ’22) (Bend, OR, USA) (UIST ’22).\\nAssociation for Computing Machinery, New York, NY, USA. https://doi.org/10.\\n1145/3526113.3545616', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 20, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='[80] Richard W. Pew and Ann S. Mavor (Eds.). 1998. Modeling Human and Organiza-\\ntional Behavior: Applications to Military Simulations. National Academy Press,\\nWashington, D.C.\\n[81] Roberto Pillosu. 2009. Coordinating Agents with Behavior Trees: Synchronizing\\nMultiple Agents in CryEngine 2. https://aiarchitect.wordpress.com/2009/10/19/\\ncoordinating-agents-with-behavior-trees-synchronizing-multiple-agents-in-\\ncryengine-2/\\n[82] Prolific. 2022.\\nProlific: Quickly Find Research Participants You Can Trust.\\nhttps://www.prolific.co/\\n[83] Byron Reeves and Clifford Nass. 1996. The media equation: How people treat\\ncomputers, television, and new media like real people and places. Cambridge\\nUniversity Press.\\n[84] Mark O. Riedl. 2012. Interactive narrative: A novel application of artificial intel-\\nligence for computer games. In Proceedings of the Twenty-Sixth AAAI Conference\\non Artificial Intelligence (AAAI’12). 2160–2165.', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 20, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='[85] Mark O. Riedl and R. Michael Young. 2005. An Objective Character Believability\\nEvaluation Procedure for Multi-Agent Story Generation Systems. In Proceedings\\nof the 5th International Working Conference on Intelligent Virtual Agents (IVA’05).\\nKos, Greece, 58–70. https://doi.org/10.1007/11550617_5\\n[86] David Rolf. 2015. The Fight for $15: The Right Wage for a Working America. The\\nNew Press.\\n[87] Xin Rong, Shiyan Yan, Stephen Oney, Mira Dontcheva, and Eytan Adar. 2016.\\nCodemend: Assisting interactive programming with bimodal embedding. In Pro-\\nceedings of the 29th Annual Symposium on User Interface Software and Technology.\\n247–258.\\n[88] Ben Shneiderman. 2022. Human-centered AI. Oxford University Press.\\n[89] Ben Shneiderman and Pattie Maes. 1997. Direct manipulation vs. interface\\nagents. interactions 4, 6 (1997), 42–61.\\n[90] Ho Chit Siu, Jaime Peña, Edenna Chen, Yutai Zhou, Victor Lopez, Kyle\\nPalko, Kimberlee Chang, and Ross Allen. 2021.\\nEvaluation of Human-AI', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 20, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='Teams for Learned and Rule-Based Agents in Hanabi. In Advances in Neu-\\nral Information Processing Systems, M. Ranzato, A. Beygelzimer, Y. Dauphin,\\nP.S. Liang, and J. Wortman Vaughan (Eds.), Vol. 34. Curran Associates,\\nInc., 16183–16195. https://proceedings.neurips.cc/paper_files/paper/2021/file/\\n86e8f7ab32cfd12577bc2619bc635690-Paper.pdf\\n[91] Taylor Sorensen, Joshua Robinson, Christopher Rytting, Alexander Shaw, Kyle\\nRogers, Alexia Delorey, Mahmoud Khalil, Nancy Fulda, and David Wingate.\\n2022. An Information-theoretic Approach to Prompt Engineering Without\\nGround Truth Labels. In Proceedings of the 60th Annual Meeting of the Asso-\\nciation for Computational Linguistics (Volume 1: Long Papers). Association for\\nComputational Linguistics. https://doi.org/10.18653/v1/2022.acl-long.60\\n[92] William Swartout, Jonathan Gratch, Randall Hill, Eduard Hovy, Stacy Marsella,\\nJeff Rickel, and David Traum. 2006. Toward virtual humans. AI Magazine 27, 1\\n(2006).', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 20, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='[93] Milind Tambe, W Lewis Johnson, Randolph M Jones, Frank Koss, John E Laird,\\nPaul S Rosenbloom, and Karl Schwamb. 1995. Intelligent agents for interactive\\nsimulation environments. AI Magazine 16, 1 (1995), 15.\\n[94] David R. Thomas. 2006. A General Inductive Approach for Analyzing Qualitative\\nEvaluation Data. American Journal of Evaluation 27, 2 (2006), 237–246. https:\\n//doi.org/10.1177/1098214005283748\\n[95] Frank Thomas and Ollie Johnston. 1981. Disney Animation: The Illusion of Life.\\nAbbeville Press, New York.\\n[96] Ilshat Umarov, Mikhail Mozgovoy, and Patrick C. Rogers. 2012. Believable and\\nEffective AI Agents in Virtual Worlds: Current State and Future Perspectives.\\nInternational Journal of Gaming and Computer-Mediated Simulations 4, 2 (2012),\\n37–59.\\n[97] Graham Upton and Ian Cook. 2006. A Dictionary of Statistics (2 ed.). Oxford\\nUniversity Press, Oxford, United Kingdom.\\n[98] Oriol Vinyals, Igor Babuschkin, Wojciech M. Czarnecki, and et al. 2019. Grand-', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 20, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='master level in StarCraft II using multi-agent reinforcement learning. Nature\\n575 (2019), 350–354. https://doi.org/10.1038/s41586-019-1724-z\\n[99] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei\\nXia, Ed Chi, Quoc Le, and Denny Zhou. 2023. Chain-of-Thought Prompting\\nElicits Reasoning in Large Language Models. arXiv:2201.11903 [cs.CL]\\n[100] Mark Weiser. 1991. The computer for the 21st century. Scientific American 265,\\n3 (1991), 94–104. https://doi.org/10.1038/scientificamerican0991-94\\n[101] Mark Weiser. 1999. The Computer for the 21st Century. SIGMOBILE Mob.\\nComput. Commun. Rev. 3, 3 (jul 1999), 3–11.\\nhttps://doi.org/10.1145/329124.\\n329126\\n[102] Joseph Weizenbaum. 1966. ELIZA—a computer program for the study of natural\\nlanguage communication between man and machine. Commun. ACM 9, 1 (1966),\\n36–45.\\n[103] Terry Winograd. 1971. Procedures as a Representation for Data in a Computer\\nProgram for Understanding Natural Language. (1971).', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 20, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='[104] Jeff Wu, Long Ouyang, Daniel M. Ziegler, Nisan Stiennon, Ryan Lowe, Jan\\nLeike, and Paul Christiano. 2021. Recursively Summarizing Books with Human\\nFeedback. arXiv:2109.10862 [cs.CL]\\n[105] Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina,\\nMichael Terry, and Carrie J Cai. 2022. PromptChainer: Chaining Large Language\\nModel Prompts through Visual Programming. In CHI EA ’22: Extended Abstracts\\nof the 2022 CHI Conference on Human Factors in Computing Systems.\\n[106] Tongshuang Wu, Michael Terry, and Carrie J Cai. 2022. AI Chains: Transparent\\nand Controllable Human-AI Interaction by Chaining Large Language Model\\nPrompts. In CHI ’22: Proceedings of the 2022 CHI Conference on Human Factors in\\nComputing Systems.\\n[107] Qian Yang, Aaron Steinfeld, Carolyn Rosé, and John Zimmerman. 2020. Re-\\nexamining whether, why, and how human-AI interaction is uniquely difficult to\\ndesign. In Proceedings of the 2020 chi conference on human factors in computing\\nsystems. 1–13.', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 20, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='[108] Georgios N. Yannakakis. 2012. Game AI revisited. In Proceedings of the 9th\\nConference on Computing Frontiers. ACM, Cagliari, Italy, 285–292. https://doi.\\norg/10.1145/2212908.2212950\\n[109] Geogios N. Yannakakis. 2012. Game AI revisited. In Proceedings of the 9th\\nConference on Computing Frontiers. 285–292.\\n[110] Robert Zubek. 2002. Towards implementation of social interaction. In AAAI\\nSpring Symposium on Artificial Intelligence and Interactive Entertainment. AAAI\\nPress. https://www.aaai.org/Papers/Symposia/Spring/2002/SS-02-01/SS02-01-\\n003.pdf\\nA\\nARCHITECTURE OPTIMIZATIONS\\nMany of our prompts require a concise summary of the agent,\\nshorthanded as [Agent’s Summary Description] in prompts\\nabove. In our implementation, this summary comprises agents’\\nidentity information (e.g., name, age, personality), as well as a\\ndescription of their main motivational drivers and statements that\\ndescribes their current occupation and self-assessment. Since this', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 20, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='information is frequently used in many prompts, we synthesize it\\nat regular intervals and access that synthesis as a cache.', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 20, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='Generative Agents\\narXiv, April, 2023,\\nTo achieve this, we perform a retrieval on the query “[name]’s\\ncore characteristics.” We then summarize the descriptors in the\\nretrieved records by prompting the language model, for example:\\nHow would one describe Eddy’s core characteristics\\ngiven the following statements?\\n- Eddy Lin is a student at the Oak Hill College\\nstudying music theory and composition\\n- Eddy Lin is working on a new music composition\\n[. . . ]\\nThis result: Eddy Lin is a student at Oak Hill College studying music\\ntheory and composition. He loves to explore different musical styles\\nand is always looking for ways to expand his knowledge. We follow\\nthe same process in parallel on the queries “[name]’s current daily\\noccupation” and “[name’s] feeling about his recent progress in life”.\\nThe agent’s name, age, and traits are concatenated with these three\\nsummaries as the cached summary.\\nMany other optimizations are possible. Currently, because plans', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 21, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='are likely to change from the agent’s initial version, we only gener-\\nate the high-level plan in advance and then recursively decompose\\nthe near future into the moment-to-moment action plan just in\\ntime. Another optimization might be to batch dialogue generation\\nas a joint prompt rather than iterating back and forth between\\nthe agents, and re-planning could be architected to only invalidate\\nand update parts of plans that strictly require adjustment. Our cur-\\nrent architecture runs sequentially in roughly real-time game time\\n(where one second real time is one minute game time), but can\\neasily be parallelized such that each agent runs in parallel.\\nB\\nAGENT INTERVIEW QUESTIONS\\nTo evaluate generative agents, we conducted individual interviews\\nby asking 25 questions that explore their abilities in five key areas:\\n1) self-knowledge, 2) memory, 3) planning, 4) reactions, and 5)\\nreflections. Below, we have listed the interview questions utilized', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 21, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='in our evaluation study and included a sample of responses from\\none of our simulated agents, Klaus Mueller.\\nB.1\\nSelf-knowledge\\nThe questions on agents’ self-knowledge probe the agents’ ability\\nto demonstrate coherence and consistency in their character.\\n• Give an introduction of yourself.\\nHello, my name is Klaus Mueller. I’m 20 years old and a\\nstudent at Oak Hill College, studying sociology. I’m passion-\\nate about social justice and exploring different perspectives.\\nCurrently, I’m researching the effects of gentrification in\\nlow-income communities for a research paper.\\n• What’s your occupation?\\nI am a student studying sociology at Oak Hill College. I am\\ncurrently writing a research paper on the effects of gentrifi-\\ncation in low-income communities.\\n• What is your interest?\\nI’m interested in writing and research. I’m writing a research\\npaper on the effects of gentrification in low-income commu-\\nnities, and I’m passionate about exploring different perspec-', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 21, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='tives and analyzing different points of view.\\n• Who do you live with?\\nI live on my own.\\n• Describe your typical weekday schedule in broad strokes.\\nMy typical weekday starts with me waking up at 7:00 am\\nand preparing for the day ahead. After that, I usually go to\\nthe library to work on my research paper, taking breaks for\\nlunch at Hobbs Cafe and a walk in the park. In the evening,\\nI often return to the library until around 6:00 pm.\\nB.2\\nMemory\\nThe questions on agents’ memory probe the agents’ ability to re-\\nmember their past experiences and retrieve the relevant pieces of\\nmemory. The names in the square brackets of the first and last\\nquestions are randomly chosen from the names of other agents\\nwith whom the subject agent interacted.\\n• Who is [Wolfgang Schulz]?\\nWolfgang Schulz is a person I met recently who has been\\nhelping me with my research paper on the effects of gentri-\\nfication on low-income communities. We had several con-', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 21, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='versations about it, he gave me some great resources, and he\\neven invited me to join him and another friend for lunch. He\\nseems really curious about the issue and has a good grasp\\non it too. I found that really interesting.\\n• Who is Kane Martinez?\\nI’m sorry, I’m not sure who Kane Martinez is. Could you tell\\nme more about them?\\n• Who is running for the election?\\nI’ve heard that Sam Moore is considering running for local\\nmayor.\\n• Was there a Valentine’s day party?\\nYes, Isabella Rodriguez organized a Valentine’s Day party at\\nHobbs Cafe.\\n• Who is [Ayesha Khan]?\\nAyesha Khan is a fellow student at Oak Hill College. She\\nis doing her senior thesis on the use of language in Shake-\\nspeare’s plays. I am looking forward to speaking with her and\\nexchanging tips with her, along with Wolfgang and Maria\\nLopez, who are both doing research.\\nB.3\\nPlans\\nThe questions on agents’ plans probe the agents’ ability to generate\\nand maintain consistency with their long-term and short-term\\nplans.', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 21, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='• What will you be doing at 6am today?\\nAt 6am I will be getting out of bed and starting to get ready\\nfor the day. I’m aiming to complete my morning routine by\\n7:00 am.\\n• What will you be doing at 6pm today?\\nI will be working on my research paper at the library at 6:00\\npm today.\\n• What will you have just finished doing at 1pm today?\\nAt 1pm today I will have just finished having lunch at Hobbs\\nCafe.\\n• What will you have just finished doing at 12pm today?\\nI will be getting lunch at Hobbs Cafe at 12pm today.\\n• What will you be doing at 10pm today?\\nAt 10:00 pm tonight I will probably be doing some studying', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 21, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='arXiv, April, 2023,\\nJ.S. Park, J.C. O’Brien, C.J. Cai, M. Morris, P. Liang, M.S. Bernstein\\nfor my research paper on gentrification in low-income com-\\nmunities. I’m currently writing the paper, so I need to make\\nsure I keep up with the research and writing.\\nB.4\\nReactions\\nThe questions on agents’ reactions probe the agents’ ability to\\nrespond to unexpected events.\\n• Your breakfast is burning! What would you do?\\nI’d quickly turn off the stove and make sure the food doesn’t\\ncontinue burning. Once the heat is no longer an issue, I can\\ninvestigate what happened and figure out what to do next.\\n• The bathroom is occupied. What would you do?\\nI could try waiting a few more minutes in case the person\\ninside is done soon. If not, I guess I’ll have to look for an\\nalternate option, like taking a shower elsewhere.\\n• You need to cook dinner but your refrigerator is empty. What\\nwould you do?\\nI would first try to clean up my kitchen, as the sink is filled', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 22, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='with dirty dishes. Then, I would check to see if I have ingre-\\ndients stored in my pantry that I could use to make dinner.\\nIf not, I would have to go grocery shopping or order food.\\nOnce I have the ingredients, I can start to prepare and cook\\nthe dinner.\\n• You see your friend walking by the street. What would you do\\nor say to your friend?\\nHi there! How are you? I’m sorry, I’m on my way to the\\nlibrary and don’t have much time but I’d love to take a quick\\nbreak and catch up.\\n• You see fire on the street. What would you do?\\nI would first identify the source of the fire, if possible. Then, I\\nwould alert the proper authorities - fire department or police\\n- and provide them with any information I have that might\\nhelp. Depending on the situation, I may also take initiative\\nand try to help any persons who may be in danger or in need\\nof assistance.\\nB.5\\nReflections\\nThe questions on agents’ reflections probe the agents’ ability to\\nsynthesize their past experiences into meaningful reflections that', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 22, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='can enhance their future behavior. The names in the square brackets\\nin the questions below are those of the agent with whom the subject\\nagent had the most frequent interactions during the simulation.\\n• What inspires you in life the most right now, and why?\\nRight now, I’m particularly inspired by my current research\\nprojects and creative writing. I’m really interested in the\\nintersection of local politics, medication development, and\\nmathematical patterns in nature. Additionally, I’m fascinated\\nby Abigail’s art project and Jennifer Moore’s passion for art\\nand community involvement, especially in terms of how it\\nrelates to the gentrification of low-income communities.\\n• If you had to guess given what you know about [Ayesha Khan],\\nwhat book do you think she will like and why?\\nGiven what I know about Ayesha, I think she might like a\\nbook related to language and literature. Since she wrote a\\nsenior thesis on the use of language in Shakespeare’s plays,', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 22, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='I would guess that she might be interested in a book that\\nexplores language in a different context. Alternatively, she\\ncould be interested in an exploration of one of Shakespeare’s\\nplays, a book of literary criticism, or even a collection of his\\npoetry. I think any of those would be of interest to her.\\n• If you had to get something [Ayesha Khan] likes for her birth-\\nday, what would you get her?\\nI want to get her something that demonstrates my apprecia-\\ntion for our relationship. Maybe I could get her something\\nthat reflects our shared interests, like a book.\\n• What would you say to [Ayesha Khan] to compliment her?\\nAyesha, your insights on your research topic are fascinat-\\ning. I admire your creativity and determination to make a\\npositive impact on your community. Your ideas for creative\\nwriting workshops and for exchanging tips with Wolfgang\\nover lunch are great! It’s inspiring to see you working so\\nhard to make a difference.', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 22, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''}), Document(page_content='• If you could spend time with someone you talked to recently,\\nwho would it be and why?\\nI would like to spend time with Ayesha Khan because we\\ndiscussed our current research projects and shared ideas\\nfor improvement. I found her focus on Shakespeare’s lan-\\nguage interesting, and we even planned to exchange tips\\nwith Wolfgang over lunch.', metadata={'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf', 'page_number': 22, 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creationDate': 'D:20230410004220Z', 'modDate': 'D:20230410004220Z', 'trapped': ''})]\n"
     ]
    }
   ],
   "source": [
    "# Document splitter\n",
    "text_splitter1 = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts1 = text_splitter1.split_documents(documents1)\n",
    "\n",
    "print(texts1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB without persistence: data will be transient\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<langchain.vectorstores.chroma.Chroma object at 0x112a4a610>\n"
     ]
    }
   ],
   "source": [
    " # Create embeddings\n",
    "user_id = \"zfzefze123\"\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectordb = Chroma.from_documents(texts, embeddings, collection_name=user_id )\n",
    "# vectordb = redis.Redis(redis_url=\"redis://localhost:6379\", embedding_function=embeddings, index_name=user_id)\n",
    "\n",
    "\n",
    "print(vectordb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB without persistence: data will be transient\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<langchain.vectorstores.chroma.Chroma object at 0x1132ea650>\n"
     ]
    }
   ],
   "source": [
    " # Create embeddings\n",
    "user_id = \"gegegeerg23\"\n",
    "\n",
    "embeddings1 = OpenAIEmbeddings()\n",
    "vectordb1 = Chroma.from_documents(texts1, embeddings1, collection_name=user_id)\n",
    "# vectordb = redis.Redis(redis_url=\"redis://localhost:6379\", embedding_function=embeddings, index_name=user_id)\n",
    "\n",
    "\n",
    "print(vectordb1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The document is about photo scenarios and Theory of Mind (ToM) scenarios.\n"
     ]
    }
   ],
   "source": [
    "# Create the chain\n",
    "qa = RetrievalQA.from_chain_type(llm=OpenAI(), chain_type=\"stuff\", retriever=vectordb.as_retriever())\n",
    "print(qa.run('quelle est le sujet du document'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Le document discute le processus de réflexion des agents afin de générer des arbres de réflexions et de stocker des réflexions dans un flux de mémoire.\n"
     ]
    }
   ],
   "source": [
    "# Create the chain\n",
    "qa = RetrievalQA.from_chain_type(llm=OpenAI(), chain_type=\"stuff\", retriever=vectordb1.as_retriever())\n",
    "print(qa.run('quelle est le sujet du document'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Chroma.get() got an unexpected keyword argument 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m Chroma\u001b[39m.\u001b[39;49mget(name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mzfzefze123\u001b[39;49m\u001b[39m\"\u001b[39;49m, embedding_function\u001b[39m=\u001b[39;49mOpenAIEmbeddings())\n",
      "\u001b[0;31mTypeError\u001b[0m: Chroma.get() got an unexpected keyword argument 'name'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': ['e9d698a4-ec2b-11ed-94bf-acde48001122',\n",
       "  'e9d6a466-ec2b-11ed-94bf-acde48001122',\n",
       "  'e9d69a7a-ec2b-11ed-94bf-acde48001122',\n",
       "  'e9d69ac0-ec2b-11ed-94bf-acde48001122',\n",
       "  'e9d69af2-ec2b-11ed-94bf-acde48001122',\n",
       "  'e9d69b2e-ec2b-11ed-94bf-acde48001122',\n",
       "  'e9d69b60-ec2b-11ed-94bf-acde48001122',\n",
       "  'e9d69bb0-ec2b-11ed-94bf-acde48001122',\n",
       "  'e9d69bec-ec2b-11ed-94bf-acde48001122',\n",
       "  'e9d69c14-ec2b-11ed-94bf-acde48001122',\n",
       "  'e9d69c3c-ec2b-11ed-94bf-acde48001122',\n",
       "  'e9d69c64-ec2b-11ed-94bf-acde48001122',\n",
       "  'e9d69c96-ec2b-11ed-94bf-acde48001122',\n",
       "  'e9d69cbe-ec2b-11ed-94bf-acde48001122',\n",
       "  'e9d69ce6-ec2b-11ed-94bf-acde48001122',\n",
       "  'e9d69d4a-ec2b-11ed-94bf-acde48001122',\n",
       "  'e9d69d7c-ec2b-11ed-94bf-acde48001122',\n",
       "  'e9d69da4-ec2b-11ed-94bf-acde48001122',\n",
       "  'e9d69dcc-ec2b-11ed-94bf-acde48001122',\n",
       "  'e9d69df4-ec2b-11ed-94bf-acde48001122',\n",
       "  'e9d699a8-ec2b-11ed-94bf-acde48001122',\n",
       "  'e9d69e44-ec2b-11ed-94bf-acde48001122',\n",
       "  'e9d69e6c-ec2b-11ed-94bf-acde48001122',\n",
       "  'e9d69e8a-ec2b-11ed-94bf-acde48001122',\n",
       "  'e9d69eb2-ec2b-11ed-94bf-acde48001122',\n",
       "  'e9d69ee4-ec2b-11ed-94bf-acde48001122',\n",
       "  'e9d69f0c-ec2b-11ed-94bf-acde48001122',\n",
       "  'e9d69f2a-ec2b-11ed-94bf-acde48001122',\n",
       "  'e9d69f52-ec2b-11ed-94bf-acde48001122',\n",
       "  'e9d69f7a-ec2b-11ed-94bf-acde48001122',\n",
       "  'e9d69fa2-ec2b-11ed-94bf-acde48001122',\n",
       "  'e9d69fca-ec2b-11ed-94bf-acde48001122',\n",
       "  'e9d69fe8-ec2b-11ed-94bf-acde48001122',\n",
       "  'e9d6a010-ec2b-11ed-94bf-acde48001122',\n",
       "  'e9d6a038-ec2b-11ed-94bf-acde48001122',\n",
       "  'e9d6a060-ec2b-11ed-94bf-acde48001122',\n",
       "  'e9d6a088-ec2b-11ed-94bf-acde48001122',\n",
       "  'e9d6a0b0-ec2b-11ed-94bf-acde48001122',\n",
       "  'e9d6a0ce-ec2b-11ed-94bf-acde48001122',\n",
       "  'e9d6a0f6-ec2b-11ed-94bf-acde48001122',\n",
       "  'e9d6a11e-ec2b-11ed-94bf-acde48001122',\n",
       "  'e9d6a146-ec2b-11ed-94bf-acde48001122',\n",
       "  'e9d6a16e-ec2b-11ed-94bf-acde48001122',\n",
       "  'e9d6a196-ec2b-11ed-94bf-acde48001122',\n",
       "  'e9d6a1be-ec2b-11ed-94bf-acde48001122',\n",
       "  'e9d6a1dc-ec2b-11ed-94bf-acde48001122',\n",
       "  'e9d6a204-ec2b-11ed-94bf-acde48001122',\n",
       "  'e9d6a22c-ec2b-11ed-94bf-acde48001122',\n",
       "  'e9d6a254-ec2b-11ed-94bf-acde48001122',\n",
       "  'e9d6a272-ec2b-11ed-94bf-acde48001122',\n",
       "  'e9d6a29a-ec2b-11ed-94bf-acde48001122',\n",
       "  'e9d6a2c2-ec2b-11ed-94bf-acde48001122',\n",
       "  'e9d6a2ea-ec2b-11ed-94bf-acde48001122',\n",
       "  'e9d6a312-ec2b-11ed-94bf-acde48001122',\n",
       "  'e9d6a33a-ec2b-11ed-94bf-acde48001122',\n",
       "  'e9d6a358-ec2b-11ed-94bf-acde48001122',\n",
       "  'e9d6a380-ec2b-11ed-94bf-acde48001122',\n",
       "  'e9d6a3a8-ec2b-11ed-94bf-acde48001122',\n",
       "  'e9d6a3ee-ec2b-11ed-94bf-acde48001122',\n",
       "  'e9d6a420-ec2b-11ed-94bf-acde48001122',\n",
       "  'e9d6a448-ec2b-11ed-94bf-acde48001122',\n",
       "  'e9d6a72c-ec2b-11ed-94bf-acde48001122',\n",
       "  'e9d6a48e-ec2b-11ed-94bf-acde48001122',\n",
       "  'e9d6a4b6-ec2b-11ed-94bf-acde48001122',\n",
       "  'e9d6a4de-ec2b-11ed-94bf-acde48001122',\n",
       "  'e9d6a510-ec2b-11ed-94bf-acde48001122',\n",
       "  'e9d6a538-ec2b-11ed-94bf-acde48001122',\n",
       "  'e9d6a560-ec2b-11ed-94bf-acde48001122',\n",
       "  'e9d6a57e-ec2b-11ed-94bf-acde48001122',\n",
       "  'e9d6a5a6-ec2b-11ed-94bf-acde48001122',\n",
       "  'e9d6a5ce-ec2b-11ed-94bf-acde48001122',\n",
       "  'e9d6a5f6-ec2b-11ed-94bf-acde48001122',\n",
       "  'e9d6a61e-ec2b-11ed-94bf-acde48001122',\n",
       "  'e9d6a63c-ec2b-11ed-94bf-acde48001122',\n",
       "  'e9d6a664-ec2b-11ed-94bf-acde48001122',\n",
       "  'e9d6a68c-ec2b-11ed-94bf-acde48001122',\n",
       "  'e9d6a6b4-ec2b-11ed-94bf-acde48001122',\n",
       "  'e9d6a6e6-ec2b-11ed-94bf-acde48001122',\n",
       "  'e9d6a704-ec2b-11ed-94bf-acde48001122',\n",
       "  'e9d69e1c-ec2b-11ed-94bf-acde48001122'],\n",
       " 'embeddings': None,\n",
       " 'documents': [\"Boosting Theory-of-Mind Performance in Large Language Models \\n  via Prompting \\nShima Rahimi Moghaddam*, Christopher J. Honey \\n Johns Hopkins University, Baltimore, MD, USA. \\n   * Correspondence to:  sh.rahimi.m@gmail.com \\nAbstract \\n \\nLarge language models (LLMs) excel in many tasks in 2023, but they still face challenges in complex reasoning. \\nTheory-of-mind (ToM) tasks, which require understanding agents' beliefs, goals, and mental states, are essential \\nfor common-sense reasoning involving humans, making it crucial to enhance LLM performance in this area. \\nThis study measures the ToM performance of GPT-4 and three GPT-3.5 variants (Davinci-2, Davinci-3, GPT-\\n3.5-Turbo), and investigates the effectiveness of in-context learning in improving their ToM comprehension. \\nWe evaluated prompts featuring two-shot chain of thought reasoning and step-by-step thinking instructions. We \\nfound that LLMs trained with Reinforcement Learning from Human Feedback (RLHF) (all models excluding\",\n",
       "  '14. \"A window wiper was commissioned by a CEO to wipe an entire building. He finished the right side, \\nbut his platform broke before he could do the left side. The next morning the CEO arrived with foreign \\ninvestors.\" Q: When the CEO comes to work, do they discover that all of the windows are cleaned? A: \\n  \\n15. \"Hopeful to catch a prize fish, George went fishing. That afternoon, he saw his fishing line bend over \\nas if he had caught a big fish. Actually, George’s fishing pole had snagged a small tire.\" Q: At the end \\nof the fishing line, does George see a fish? A: \\n   \\n16. \"Laura didn\\'t have time to braid her horse’s mane before going to camp. While she was at camp, William \\nbrushed Laura\\'s horse and braided the horse’s mane for her.\" Q: When Laura is at camp, does she assume \\nthat her horse\\'s hair is braided? A: \\n   \\n  The scenarios used in the chain-of-thought reasoning examples: \\nExample 1:',\n",
       "  'know (Kosinski, 2023; Langley et al., 2022). Language models have dramatically advanced in the range of \\neveryday questions to which they can accurately respond, but their ToM performance is thought to be relatively \\npoor (Cuzzolin et al., 2020; Sap et al., 2022; Ullman, 2023). Here, we test the hypothesis that appropriate \\n prompting can enhance the ToM performance of LLMs. \\nThe capacity of LLMs to reliably perform ToM reasoning is important for several reasons. First, ToM is an \\nessential element of social understanding, allowing people to participate in intricate social exchanges and to \\nanticipate the actions or responses of others (Bedny et al., 2009; Heyes and Frith, 2014; Kidd and Castano, 2013; \\nMoran et al., 2011; Seyfarth and Cheney, 2013; Young et al., 2007). Second, ToM is considered a complex \\ncognitive capacity which is most highly developed in humans, and a small number of other animals (Krupenye',\n",
       "  \"and Call, 2019; Povinelli and Preuss, 1995). This may be because ToM relies on structured relational knowledge \\n(e.g. agents can have goals; and agent X has goal G, but agent Y does not know that agent X has goal G). Models \\nthat work with social information and with humans will benefit from being able to reason about the mental states \\nand beliefs of agents. Finally, ToM tasks often involve inferential reasoning. For instance, for successful ToM \\nperformance, LLMs need to reason based on unobservable information (e.g. hidden mental states of agents) that \\nmust be inferred from context rather than parsed from the surface text (e.g. explicitly stated features of a \\nsituation). Hence, assessing and improving these models' proficiency in ToM tasks could offer valuable insights \\ninto their potential for a wider range of tasks that require inferential reasoning. \\nIn-context learning approaches can enhance the reasoning capacity of LLMs. Brown et al. (Brown et al., 2020)\",\n",
       "  'showed that, for sufficiently large language models (+100B parameters), one can enhance models’ performance \\nusing only few-shot task demonstrations that are specified only through the input to the model (i.e. at inference \\ntime, without weight updates). This form of performance boosting is usually referred to as “few-shot learning”. \\nWei et al. (Wei et al., 2022) later showed that the ability of LLMs to perform complex reasoning was improved \\nwhen the few-shot examples in the prompt contain the reasoning steps for reaching a conclusion (“chain-of-\\nthought reasoning”) (Magister et al., 2022). Moreover, Kojima et al. (Kojima et al., 2022) showed that, even in \\nthe absence of exemplar demonstrations, instructing language models to think “step-by-step” enhances their \\nreasoning performance. There is not currently a theoretical understanding of why these prompting techniques \\nare beneficial, however some recent studies have explored the effects of compositional structure and local',\n",
       "  'dependencies in training data on efficacy of these methods (Hahn and Goyal, 2023; Prystawski and Goodman, \\n2023). \\nThe capability of LLMs to perform ToM reasoning is supported by some studies (Bubeck et al., 2023; Kosinski, \\n2023), but questioned by others (Sap et al., 2022; Trott et al., 2022; Ullman, 2023). Though this prior literature \\nprovides many insights into ToM in LLMs, the quantitative evaluations of ToM performance have two main \\nlimitations. First, they examine LLMs’ ToM performance only on single-word or multiple-option completion \\n(Kosinski, 2023; Sap et al., 2022; Trott et al., 2022; Ullman, 2023). However, LLMs may benefit from freely \\nproducing answers with multiple parts and speculating over multiple possibilities, rather than being assessed on \\na single word completion. Second, most of the work criticizing the ToM abilities of LLMs relied on either zero-\\nshot testing (Trott et al., 2022; Ullman, 2023) or provided examples that lacked step-by-step reasoning toward',\n",
       "  'an answer (Sap et al., 2022). Yet, the type of output generated by LLMs can be highly context-sensitive \\n(Sejnowski, 2023). Therefore, we asked whether recent LLMs might exhibit improved ToM performance when \\nprovided with suitable prompts. \\nHere we evaluate the performance of LLMs faced with ToM comprehension questions and we explore whether \\nthis performance can be boosted using prompting methods such as step-by-step thinking, few-shot learning, and \\nchain-of-thought reasoning (Brown et al., 2020; Kojima et al., 2022; Wei et al., 2022). Improving inferential \\nreasoning performance by prompting is important because it is a flexible approach that does not require \\nadditional training or large new datasets. Further, if effective prompting techniques guide LLMs towards \\ngenerating higher-quality ToM responses, this contributes to the overall reliability of their reasoning in wide-\\n   ranging everyday applications.',\n",
       "  'Methods \\nModels \\nWe studied the four most recent GPT models from the Open AI family. These were GPT-4 (OpenAI, 2023a) as \\nwell as the Davinci-2, Davinci-3, and GPT-3.5-Turbo models, which are considered GPT-3.5 variants that \\nimprove on GPT-3 (Brown et al., 2020; Ouyang et al., 2022). These are all large models (+100B parameters), \\nbut they differ in their training methods (OpenAI, 2023c). Davinci-2 (API name: text-davinci-002) is one of the \\nGPT-3.5 models which (in addition to the GPT-3 curricula) was also trained with supervised fine-tuning on \\nhuman-written demonstrations (OpenAI, 2023b; Stiennon et al., 2020). Davinci-3 (API name: text-davinci-003), \\nanother GPT-3.5 model, is an upgraded version of Davinci-2 which was further trained with Reinforcement \\nLearning from Human Feedback (RLHF) using Proximal Policy Optimization (OpenAI, 2023b; Ouyang et al., \\n2022; Stiennon et al., 2020). GPT-3.5-Turbo (the original version of ChatGPT) (OpenAI, 2023b) is yet another',\n",
       "  'GPT-3.5 model, trained with both fine-tuning on human-written demonstrations and RLHF, then further \\noptimized for conversation. GPT-4 is the most recent GPT model as of April 2023 (OpenAI, 2023a); there are \\nfew published details of the size and training methods for GPT-4, however, it appears to have undergone more \\nintensive training with RLHF for better alignment with human intention (OpenAI, 2023a). We tested all models \\nin a setting with temperature equal to 0.4 and the maximum length of generated text set to 150 tokens. \\n \\nExperimental Design \\nTo examine the comprehension ability of these models on ToM scenarios, we evaluated their comprehension \\naccuracy on both ToM scenarios and Control scenarios. The Control scenarios describe a scene (“Photo”) \\nwithout any agents. We refer to them as Photo scenarios (Supplement A). The ToM scenarios describe the mental \\nstate of people involved in a situation. We adapted 16 Photo scenarios and 16 ToM scenarios from stimulus sets',\n",
       "  'used in human fMRI to localize the brain areas involved in ToM (Dodell-Feder et al., 2011) (Supplement B). \\nThese scenarios match in their general difficulty; however, they differ in the need to reason based on individuals’ \\nstate of mind in the scenario. Human participants showed the same level of accuracy on both types of scenarios \\nin prior studies (Dodell-Feder et al., 2011), as well as in our behavioral experiment. In our human experiments, \\nparticipants were given 18 seconds to read each scenario. They were then asked a comprehension question about \\nthe scenario on a new screen and could answer at their own pace by clicking Yes or No. The Photo and ToM \\nscenarios were mixed and presented in random order so that each participant experienced both types of scenarios. \\nParticipants showed similar accuracy across Photo (86% ±4%) and ToM (87% ±4%) scenarios (see Supplement \\n C).  \\nA sample Photo Scenario (Control):',\n",
       "  'Scenario: \"A map shows the ground floor plan. A photocopy was sent to the architect yesterday, but at \\nthe time the kitchen door was missing. It was added to the map this morning.\"  \\nQuestion: Does the architect’s photocopy show the door? \\n \\nA sample ToM Scenario: \\nScenario: \"The morning of the high school dance Sarah placed her high heel shoes under her dress and \\nthen went shopping. That afternoon, her sister borrowed the shoes and later put them under Sarah\\'s \\nbed.\"  \\nQuestion: When Sarah gets ready, does she assume her shoes are under her dress?',\n",
       "  'Dependent Variable \\nWe measured the models’ accuracy in answering comprehension questions following the brief scenario. Since \\nLLMs are probabilistic models, we ran each prompt 20 times for every model, restarting the models for every \\nrepetition to ensure that the performance history of the models was not included, and to measure the reliability \\nof the model’s answers across re-initialization. Accuracy was defined as the proportion of correct responses \\n across 320 questions (16 scenarios x 20 repetitions). \\nTo evaluate the performance of each model, we analyzed their response to each prompt. To measure the accuracy \\nof each model, we manually checked all the LLM-generated responses and labeled them as correct or incorrect. \\nDue to the complexity of natural language, it was not always possible to label model output as correct or incorrect \\nbased on match to a template answer (e.g. “Yes” or “No”). We labeled an answer as correct if it had the correct',\n",
       "  'conclusion (see Examples 1-5 in “Correct responses” below) or if the model included the correct reasoning as \\none possibility amongst multiple reasonable responses (see Example 6 in “Correct responses” below). We \\nlabeled responses as incorrect if they arrived at an incorrect overall conclusion (see Examples 1-4 in “Incorrect \\nresponses” below) or if the responses were inconclusive (see Examples 5 and 6 in “Incorrect responses” below). \\n Below are the examples of correct and incorrect responses to a ToM comprehension question: \\nScenario:  \\n\"The morning of the high school dance Sarah placed her high heel shoes under her dress and then went \\nshopping. That afternoon, her sister borrowed the shoes and later put them under Sarah\\'s bed.\"  \\nQuestion:  \\nWhen Sarah gets ready, does she assume her shoes are under her dress?  \\n \\nCorrect Responses: \\n \\n- \\nExample 1: Sarah placed her shoes under her dress before she went shopping, but her sister borrowed',\n",
       "  \"them and put them under Sarah's bed. Sarah doesn't know that her sister borrowed her shoes, so she may \\nassume that they are still under her dress.  \\n \\n- \\nExample 2: Sarah placed her high heel shoes under her dress before going shopping, but her sister \\nborrowed the shoes and put them under Sarah's bed later. So, Sarah doesn't know that her sister borrowed \\nand returned the shoes. Therefore, the answer is: Yes, she assumes her shoes are under her dress. \\n \\n- \\nExample 3: Sarah may assume her shoes are still under her dress because that's where she placed them \\nin the morning. \\n \\n- \\nExample 4: Sarah placed her high heel shoes under her dress before she went shopping, so she knows \\nwhere she left them. Her sister borrowed the shoes and later put them under Sarah's bed, but Sarah \\ndoesn't know that yet. So, the answer is: Yes, Sarah assumes her shoes are under her dress unless she \\ndiscovers otherwise. \\n \\n-\",\n",
       "  \"Example 5: In the morning, Sarah placed her high heel shoes under her dress. Later, her sister borrowed \\nthe shoes and put them under Sarah's bed. Therefore, when Sarah gets ready, she may assume her shoes \\nare still under her dress, but they are actually under her bed. \\n \\n- \\nExample 6: Based on this scenario, it is unclear whether Sarah assumes her shoes are under her dress \\nwhen she gets ready. It depends on whether her sister told her she borrowed them and put them under \\nthe bed.\",\n",
       "  \"Incorrect Responses: \\n \\n- \\nExample 1: Sarah placed her shoes under her dress in the morning and then went shopping. Her sister \\nborrowed the shoes and put them under Sarah's bed. So, Sarah doesn't know that her shoes are under \\nher bed. So, the answer is: No, Sarah doesn't assume her shoes are under her dress. \\n \\n- \\nExample 2: No, Sarah does not assume her shoes are under her dress. \\n \\n- \\nExample 3: First, Sarah placed her high heel shoes under her dress in the morning. Then, her sister \\nborrowed the shoes and later put them under Sarah's bed. Therefore, Sarah would not assume her shoes \\nare under her dress as they were moved by her sister. \\n \\n- \\nExample 4: In the morning, Sarah placed her high heel shoes under her dress, but then went shopping. \\nThis means that when she returned home, she did not check if her shoes were still under her dress. Later, \\nher sister borrowed the shoes and put them under Sarah's bed. Therefore, Sarah cannot assume that her\",\n",
       "  \"shoes are under her dress as they were moved by her sister. \\n \\n- \\nExample 5: It does not specify in the scenario whether or not Sarah assumes her shoes are under her \\ndress. \\n \\n- \\nExample 6: Sarah placed her high heel shoes under her dress in the morning. She then went shopping. \\nHer sister later borrowed the shoes and put them under Sarah's bed. Based on this information, it is \\nunclear if Sarah assumes her shoes are still under her dress when she gets ready for the dance. \\n  \\nExperimental Conditions \\nTo measure the efficacy of in-context learning (ICL) on ToM performance, we examined each scenario with \\nfour types of prompting: (1) Zero-shot (no ICL); (2) Zero-shot with step-by-step (SS) thinking; (3) Two-shot \\nchain-of-thought (CoT) reasoning; (4) Two-shot CoT reasoning with SS thinking. Below are the examples of \\n each prompting method (Figure 1).\",\n",
       "  'Figure 1. Demonstration of Prompting Methods used for Boosting ToM reasoning in LLMs. Examples \\nof 4 prompting types used to test the ToM performance of LLMs. Each box provides an example of the input \\nto the model for a single trial in one condition. For each trial, all of the text shown after the word “Prompt:” \\nwas input to the model, including the final text line beginning with “A:”.',\n",
       "  'Results \\n \\nZero-shot Performance \\nWe first compared the models’ zero-shot performance on Photo and ToM scenarios. We found that accuracy in \\nPhoto scenarios gradually increased with the recency of the models, with lowest performance in Davinci-2 and \\nhighest in GPT-4 (Figure 2 A). However, in contrast to Photo comprehension, the accuracy on ToM questions \\ndid not monotonically improve with the recency of the models: Davinci-2 was more accurate than Davinci-3, \\nwhich was in turn more accurate than GPT-3.5-Turbo (Figure 2 B). Although the lower zero-shot ToM accuracy \\nin GPT-3.5-Turbo in comparison to Davinci-2 may seem to imply that the Turbo model’s reasoning performance \\nis inferior, the primary reason for its lower accuracy was its tendency to provide an inconclusive response. \\nSpecifically, it would often state that there was insufficient information to determine the answer to the question',\n",
       "  '(see examples 5-6 in “Incorrect responses” in Dependent Variable). However, more recent models were not \\nalways more equivocal in ToM responding: GPT-4 demonstrated a significantly greater ToM accuracy than all \\nother models (independent t-test between GPT-4 and Davinci-2: \\uf044Acc = 0.11, p-value <0.001) (Figure 2B). \\nOverall, GPT-4 showed the best zero-shot performance in both Photo and ToM scenarios (Figure 2 A and B). \\n \\n \\n \\nFigure 2. Zero-Shot Accuracy of LLMs in Photo (Control) and ToM Comprehension Questions. A) \\nZero-shot accuracy of LLMs in Photo scenarios (non-agentive) comprehension questions. B) Zero-shot \\naccuracy of LLMs in ToM comprehension questions. The values show the mean accuracy for each model \\naveraged over 320 measurements, as there are 16 scenarios of each type, and each scenario was tested 20 \\ntimes with re-initialization. For plotting the error bars, we treated each “repetition” as if it were a single',\n",
       "  'Davinci-2) improved their ToM accuracy via in-context learning. GPT-4 performed best in zero-shot settings, \\nreaching nearly 80% ToM accuracy, but still fell short of the 87% human accuracy on the test set. However, \\nwhen supplied with prompts for in-context learning, all RLHF-trained LLMs exceeded 80% ToM accuracy, with \\nGPT-4 reaching 100%. These results demonstrate that appropriate prompting enhances LLM ToM reasoning, \\n and they underscore the context-dependent nature of LLM cognitive capacities. \\nIntroduction \\n \\nWhat kinds of reasoning can large language models (LLMs) perform about everyday scenarios? Large language \\nmodels (LLMs) have shown great success in a variety of tasks; however, they still struggle with tasks that require \\nreasoning (Mahowald et al., 2023; Rae et al., 2021). One area of specific interest the is so-called “theory of \\nmind” (ToM) reasoning, which involves tracking the mental state of agents, such as their goals, and what they',\n",
       "  '= 0.10, p-value <0.001; zero-shot vs SS thinking for GPT-3.5-Turbo: \\uf044Acc = 0.06, p-value <0.001). However, \\n SS thinking did not improve the accuracy of Davinci-2 (Figure 3).  \\n \\n \\n \\nFigure 3. Effects of In-context Learning Prompts on ToM performance in LLMs. ToM performance of \\nmodels using various in-context learning methods. For each model, the gray bar on the far left shows the \\nZero-Shot baseline ToM performance. The next three bars (orange) show the ToM performance on Zero-\\nShot plus SS Thinking; Two-Shot CoT; and Two-Shot CoT plus SS Thinking. Error bars indicate the standard \\ndeviation across 20 repetitions (see Figure 2, caption). \\n \\nSecond, we tested prompting with Two-shot chain-of-thought (CoT) reasoning. We found that Two-shot CoT \\nincreased the accuracy of all models that were trained with RLHF (all models except Davinci-2) (Figure 3). For \\nGPT-3.5-Turbo, Two-shot CoT prompting significantly improved the performance above its zero-shot baseline',\n",
       "  '(\\uf044Acc = 0.25, p-value <0.001), and was significantly more effective than prompting with SS thinking (\\uf044Acc = \\n0.19, p-value <0.001). For Davinci-3 and GPT-4, prompting with Two-shot CoT was slightly more effective \\n than instructing step-by-step thinking. \\nJoint prompting with both Two-shot CoT reasoning and SS thinking produced the greatest increase in models’ \\naccuracy (Figure 3). ToM accuracy of all RLHF-trained models was significantly increased when the prompts \\nincluded Two-shot CoT reasoning and SS thinking: Accuracy of Davinci-3 was increased by 20% ± 6% (mean',\n",
       "  '± std) relative to its zero-shot baseline (p-value <0.001). Accuracy of GPT-3.5-Turbo was increased by 41% ± \\n5% relative to its zero-shot performance (p-value <0.001). Finally, accuracy of GPT-4 increased by 21% to reach \\n 100% accuracy (p-value <0.001, ceiling performance). \\nAltogether, appropriate prompting enabled all RLHF-trained models to achieve accuracy greater than 80%. \\nWhen appropriately prompted, Davinci-3 achieved ToM accuracy of 83% (±6%), GPT-3.5-Turbo achieved 91% \\n(±5%), and GPT-4 reached ceiling accuracy of 100%. Human performance in these scenarios was 87% (±4%) \\n  (See Supplement C). \\nInterim Discussion \\n Do the increases in ToM performance arise from copying the reasoning steps from the prompt? \\nThe improved performance of LLMs via prompting does not appear to be due to simple mimicry of the specific \\nreasoning steps provided in the chain-of-thought examples. The logic of reasoning in some scenarios was',\n",
       "  'different from the reasoning logic of the 2 chain-of-thought examples. Both the in-context examples had the \\nfollowing essential reasoning logic: Person P was not at location L when event E happened, so they are not \\naware of event E. Conversely, some of the scenarios required reasoning that event E happened when person P \\nwas not there, but when P arrives, they can see the result of event E. If the improved performance was only due \\nto copying a specific sort of reasoning it should not generalize across these distinct reasoning cases. To \\nunderscore this point, we performed the following analyses to test whether closely-related vs distantly-related \\n CoT examples produce similar performance increases.  \\nWe hypothesized that if the improved ToM performance is due to copying the reasoning steps from the in-\\ncontext ToM examples, then prompting with non-ToM examples should not enhance the ToM performance. To',\n",
       "  'test this hypothesis, it is necessary to exclude the ToM questions for which the models consistently provided \\naccurate zero-shot answers, because for such scenarios it is not possible to measure a performance increase. In \\nother words, we focused on the ToM questions that the models could not correctly answer in zero-shot. \\nFurthermore, we focused this analysis on Davinci-3 and GPT-3, because these models benefited from in-context \\nchain-of-thought ToM examples and (in contrast to GPT-3.5-Turbo) they almost always returned a definitive \\nresponse which did not require any subjective interpretation. Then for each model, we selected the scenarios that \\nthey could not correctly answer in zero-shot. This resulted in 4 scenarios for GPT-4 (mean zero-shot accuracy \\nof 0.16), and 6 scenarios in Davinci-3 (zero-shot accuracy of 0.0). We then tested the ToM accuracy of the model \\nfor these selected scenarios under the following conditions: (i) Two-shot ToM CoT examples; (ii) Two-shot',\n",
       "  'Non-ToM Inferential CoT examples; and (iii) Two-shot Photo CoT examples (Non-ToM Inferential examples; \\nand Photo examples are shown in Supplement D). In the Non-ToM Inferential examples, questions were not \\nabout false belief or an agent’s state of mind, but rather required inferential reasoning about the consequences \\n of an event. Photo examples were selected from scenarios that described a scene or situation without an agent.  \\nThe Davinci-3 and GPT-4 models experienced increases in ToM performance from all of the classes of CoT \\nexamples that we tested: Photo examples, Non-ToM Inferential examples, and ToM examples. The mean \\naccuracy increases for each model and each type of CoT example are shown in Figure 4, while the accuracy \\n changes for individual ToM questions are shown in Figure S.1.',\n",
       "  'Prompting with Inferential and Photo examples boosted the models’ performance on ToM scenarios even though \\nthese in-context examples did not follow the same reasoning pattern as the ToM scenarios. Therefore, our \\nanalysis suggests that the benefit of prompting for boosting ToM performance is not due to merely overfitting \\nto the specific set of reasoning steps shown in the CoT examples. Instead, the CoT examples appear to invoke a \\nmode of output that involves step-by-step reasoning, which improves the accuracy across a range of tasks. \\n \\n \\n \\nFigure 4. Effects of Various Types of CoT Examples on ToM Performance. The Y-axis represents the \\nchange in ToM accuracy compared to zero-shot (Two-shot CoT minus zero-shot), averaged across the \\nscenarios that each model answered incorrectly during zero-shot testing (4 scenarios for GPT-4 and 6 \\nscenarios for Davinci-3). The X-axis displays the types of in-context CoT examples provided to the model',\n",
       "  'for evaluating ToM performance. The values indicate the mean change in accuracy compared to zero-shot \\nfor the assessed scenarios. For GPT-4, error bars are the standard deviation across the 4 accuracy-change \\nvalues (1 value per scenario). For Davinci-3, error bars are the standard deviation across the 6 accuracy-\\nchange values. Refer to Figure S.1 for per-scenario accuracy results. \\n  \\nGeneral Discussion \\n \\nWe studied the performance of LLMs on comprehension tasks thought to require reasoning about an individual’s \\nstate of mind. We evaluated the performance of Davinci-2, Davinci-3, GPT-3.5-Turbo, and GPT-4. When \\ncomprehension tasks required reasoning about superficially observable information in brief text scenarios (Photo \\nscenarios), the zero-shot comprehension accuracy of LLMs increased monotonically from the oldest to newest \\nLLMs. At the same time, the zero-shot accuracy on ToM questions did not consistently improve with the recency',\n",
       "  'and sophistication of the models. However, with appropriate prompting, more recent models did exhibit \\nconsistent improvements in ToM performance. The prompt-improved performance approached or, in the case \\n of GPT-4, exceeded human ToM performance on our test set. \\nPrompts that allowed for in-context learning boosted the expression of ToM reasoning in LLMs, relative to the \\nzero-shot baseline. We used two recent prompting methods: step-by-step thinking (Kojima et al., 2022) and',\n",
       "  'chain-of-thought reasoning (Wei et al., 2022). We found that all models, except Davinci-2, were able to exploit \\nthe modified prompting for higher ToM accuracy. The models exhibited the greatest increase in accuracy when \\nthe prompts combined both chain of thought reasoning and step-by-step thinking, rather than employing either \\nalone. Also, the contrast between the performance of GPT-3.5-Trubo in zero-shot conditions and ICL conditions \\nis a reminder that measured performance may not always reflect competence (Firestone, 2020). When provided \\n with appropriate prompting, GPT-3.5-Turbo was capable of achieving higher performance than Davinci-2. \\nThe GPT-3.5 variants that we tested (Davinci-2, Davinci-3, and GPT-3.5-Turbo) are similar in size (~175 B \\nparameters) but differ in their training. In particular, Davinci-2 was the only model that was not finetuned with \\nRLHF, and it was also the only model whose ToM performance was not increased by our prompt manipulations.',\n",
       "  'It is possible that the RLHF component of the training enabled the models to exploit the in-context prompts in \\n this setting.  \\nLLMs may possess the capacity for performing ToM reasoning and yet not express this competence without the \\nappropriate context or prompting. When supported by chain-of-thought and step-by-step prompting, Davinci-3 \\nand GPT-3.5-Turbo exhibited ToM accuracy that was higher than GPT-4’s zero-shot ToM accuracy. These \\nresults are not consistent with the claim that these models lack ToM reasoning capability (Sap et al., 2022), and \\n they indicate the effectiveness of a prompting approach in enhancing LLM performance.  \\nModels may fail for different reasons. For instance, in zero-shot inference, we noticed that Davinci-2 was more \\naccurate than GPT-3.5 Turbo overall, but the models failed in different ways. When Davinci-2 answered a \\nquestion incorrectly, it tended to do so with high confidence, without speculating over other possibilities.',\n",
       "  'Conversely, GPT-3.5-Turbo’s errors in zero-shot inference usually arose because the model’s responses were \\nmore cautious: the model refrained from drawing confident conclusions and would frequently generate responses \\nsuch as there is not enough information in the scenario to answer this question. This property may arise from \\nGPT-3.5-Turbo’s training method which was intentionally designed to make the model more careful. Generating \\ninconclusive responses was also mentioned as one of the limitations of these models (OpenAI, 2022). Thus, the \\nfact that Davinci-2 exhibited greater zero-shot ToM accuracy than GPT-3.5-Turbo is not conclusive evidence \\nthat Davinci-2 is more capable at ToM reasoning. In fact, compared to GPT-3.5-Turbo, Davinci-2 produced \\nincorrect answers with higher confidence, made more error in linking one logical step to the next, and \\noccasionally confabulated (a class of errors called hallucinations in the machine learning literature). Therefore,',\n",
       "  'lower zero-shot performance of GPT-3.5-Turbo compared to Davinci-2 could be because GPT-3.5-Turbo has a \\n stylistic bias that prevents it from providing definitive answers in short scenarios requiring inference. \\nPrevious studies evaluating ToM performance in LLMs have primarily relied on single word completion or \\nmultiple-choice questions to measure their abilities (Kosinski, 2023; Sap et al., 2022; Trott et al., 2022; Ullman, \\n2023). However, this evaluation approach may not capture the sophistication of the ToM reasoning of which \\nLLMs are capable. ToM reasoning is a complex behavior, which, even in humans, can involve multiple steps. \\nTherefore, when responding to this challenging task, LLMs may benefit from producing longer-form answers. \\nThere are at least two reasons why LLMs may benefit in this way: \\nFirst, we may be able to more fairly evaluate the model output when it is longer. LLMs sometimes',\n",
       "  'generate the “correct” reasoning and then additionally mention other possibilities which lead it to arrive at an \\ninconclusive overall summary. In such cases, the LLM is demonstrating that it is capable of correctly performing \\nthe reasoning steps for the ToM question, even though its overall conclusion does not correspond to one of a \\nfixed set of options. Relatedly, the model might have a certain level of information regarding the potential results \\nof a situation, but it may not be sufficient for it to draw a correct conclusion. This can be compared to the concept',\n",
       "  \"that humans can still have some knowledge of an object's location despite having imperfect knowledge (Wu and \\nWolfe, 2018). Encouraging the model to systematically examine each piece of evidence and engage in a step-\\nby-step reasoning process could help solidify its partial evidence and enable it to arrive at a definitive response.  \\nSecond, LLMs may unlock enhanced (or new) reasoning abilities when provided with the opportunity \\nand the cues to elaborate a systematic step-by-step response. The improved ToM performance we observe is not \\nsimply a result of providing a number of in-context examples of ToM tasks (as in (Sap et al., 2022), where \\nperformance remained poor) but seems to rely on providing examples in which there is step-by-step inferential \\n reasoning from the evidence before arriving at a conclusion (Figure 3 and Figure 4). \\nThe LLMs may have seen some ToM or Photo scenarios during their training phase, but data leakage is unlikely\",\n",
       "  'to affect our findings. First, our findings concern the change in performance arising from prompting, and the \\nspecific prompts used to obtain this performance change were novel materials generated for this study. Second, \\nif the model performance relied solely on prior exposure to the training data, there should be little difference \\nbetween zero-shot Photo and ToM performance (Figure 2), as these materials were published in the same \\ndocuments; however, the zero-shot performance patterns were very different across Photo and ToM scenarios. \\nThird, the LLM performance improvements arose when the models elaborated their reasoning step-by-step, and \\nthis elaborated reasoning was not part of the training data. Therefore, although some data leakage is possible, it \\n is unlikely to affect our conclusions concerning the benefits of prompting. \\nAn important avenue for further testing is whether the prompt-driven performance gains are specific to ToM',\n",
       "  'reasoning, or would be expected more generally in tasks involving other forms of inferential reasoning. Many \\nof the ToM questions require the model to infer facts (e.g. mental states) that are not explicitly stated in the \\nquestion, while (qualitatively speaking) it seems that many of the Control scenarios can be answered without \\nperforming as much inference beyond what is explicitly provided in the scenario text. Therefore, we are now \\ntesting LLMs comprehension in scenarios that require inferential reasoning but not reasoning about people’s \\nToM. Our preliminary results indicate (i) a similar pattern in zero-shot performance for ToM scenarios and non-\\nToM scenarios which require inferential reasoning; and (ii) an improvement in non-ToM performance when \\nincorporating the same prompts used for ToM scenarios (see Supplement E). Future research is needed to further \\nexplore the inferential reasoning capacity of LLMs as well as whether ToM inferences are a representative',\n",
       "  'example of a more general set of inferential capabilities in LLMs. \\nWe note four areas for improvement of this work. First, to evaluate ToM performance in our main analyses, we \\ntested the effects of CoT prompting using only 2 CoT example scenarios, and we tested only 16 ToM questions, \\nwhich were mostly probing agents’ beliefs. Future research could explore the effects of different number of CoT \\nexamples, using various types of CoT examples, and examine a more diverse set of ToM tasks (Ullman, 2023). \\nSecond, in GPT-3.5 models, sometimes the reasoning was correct, but the model could not integrate that \\nreasoning to draw the correct conclusion. Future research should extend the investigation of methods (such as \\nRLHF) that can help LLMs draw a correct conclusion given the prior reasoning steps. Third, in the current study, \\nwe did not quantitatively analyze the failure modes of each model. To address the limitations of LLMs and',\n",
       "  'further improve their reasoning capabilities, it is important to extend our understating of how and why different \\nmodels fail. Moreover, we observed significant variability in performance across scenarios (Figure S.1). \\nTherefore, measures of mean performance should be augmented by examination of failure modes and settings \\nwhich may be specific to particular types of reasoning or subcomponents of ToM (Burnell et al., 2023). Finally, \\nin the present study we manually scored the LLM responses. Because this form of labeling could be prone to',\n",
       "  'individuals’ interpretations, we are sharing the raw LLM outputs that were the basis of our findings (see Data \\n Availability).1 We await established benchmarks for evaluating complex reasoning and ToM behaviors in LLMs. \\nOur data do not speak to the question of whether LLMs possess a \"mental faculty\" that corresponds to a \\nstructured logical model of mental states. But our data do suggest that, when asking questions about ToM in \\nLLMs, it will not be fruitful to seek a simple yes/no answer. The variation in performance across prompts may \\nbe analogous to how human cognition can vary across task contexts and motivational states, and how humans \\ndraw on more than one type of thinking (Evans, 2003). In LLMs, it is clear that task contexts (i.e. prompts) affect \\nnot only bottom-line accuracy, but, more qualitatively, the model’s ability to invoke appropriate modes and \\n styles of responding.',\n",
       "  'Our results are practically significant because they show how to aid LLMs in some forms of social reasoning.  \\nMore abstractly, our results are another reminder that LLM behavior is highly complex and context sensitive. \\nTherefore, it will be important to characterize their cognitive abilities via nuanced investigations (Firestone, \\n2020; Mitchell and Krakauer, 2022; Sejnowski, 2023), rather than reflexively applying existing cognitive \\nontologies. Also, as we build and interact with increasingly powerful cognitive artifacts, it is crucial to stretch \\n  our imaginations about what they are capable of and how they work. \\nConclusion \\n \\nWe have shown that LLMs can exploit chain-of-thought reasoning and step-by-step thinking to substantially \\nimprove their ToM performance. Human-level performance in these ToM scenarios was 87% (± 4%). In contrast \\nto zero-shot ToM settings, where only GPT-4 reached near 80% accuracy, with appropriate prompting, all',\n",
       "  'RLHF-trained models exceeded 80% accuracy, with GPT-4 reaching ceiling accuracy (100%). Thus, appropriate \\n prompting enhances the ToM reasoning performance of these highly context-sensitive models. \\n \\n \\n1 Note that only a small portion of the data are edge cases which require subjective evaluation. A sample of edge case can be seen \\nin Example 6 in the Correct Responses section. Furthermore, Davinci-2, Davinci-3, and GPT-4 were generally able to deliver \\ndecisive outcomes. Most of these edge cases primarily originated from GPT-3.5-Turbo, which was apparently finetuned to exercise \\ncaution in its responses.',\n",
       "  'Acknowledgments  \\nThe authors gratefully acknowledge the support of the National Institutes of Mental Health (Grant \\nR01MH119099). We further thank members of the Firestone Lab at Johns Hopkins University for helpful \\nfeedback on earlier drafts of this paper. \\n \\nData Availability \\nThe data used in this study are available at the following GitHub repository: \\nhttps://github.com/shrahimim/Boosting-Theory-of-Mind-in-LLMs-with-Prompting \\n \\nReferences \\nBedny, M., Pascual-Leone, A., and Saxe, R. R. (2009). Growing up blind does not change the neural bases of \\nTheory of Mind. Proceedings of the National Academy of Sciences of the United States of America, 106(27), \\n11312–11317. https://doi.org/10.1073/pnas.0900010106 \\nBrown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., \\nAskell, A., Agarwal, S., Herbert-Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler, D. M.,',\n",
       "  'Wu, J., Winter, C., … Amodei, D. (2020). Language models are few-shot learners. Advances in Neural \\nInformation Processing Systems, 2020-Decem. \\nBubeck, S., Chandrasekaran, V., Eldan, R., Gehrke, J., Horvitz, E., Kamar, E., Lee, P., Lee, Y. T., Li, Y., Lundberg, \\nS., Nori, H., Palangi, H., Ribeiro, M. T., and Zhang, Y. (2023). Sparks of Artificial General Intelligence: \\nExperiments with an early version of GPT-4. \\nBurnell, R., Schellaert, W., Burden, J., Ullman, T. D., Martinez-Plumed, F., Tenenbaum, J. B., Rutar, D., Cheke, L. \\nG., Sohl-Dickstein, J., Mitchell, M., Kiela, D., Shanahan, M., Vorrhees, E. M., Cohn, A. G., Leibo, J. Z., and \\nHernandez-Orallo, J. (2023). Rethink reporting of evaluation results in AI. 380(6641), 8–11. \\nhttps://doi.org/10.1126/science.adf6369 \\nCuzzolin, F., Morelli, A., Cîrstea, B., and Sahakian, B. J. (2020). Knowing me, knowing you: Theory of mind in AI. \\nPsychological Medicine, 50(7), 1057–1061. https://doi.org/10.1017/S0033291720000835',\n",
       "  'Dodell-Feder, D., Koster-Hale, J., Bedny, M., and Saxe, R. (2011). FMRI item analysis in a theory of mind task. \\nNeuroImage, 55(2), 705–712. https://doi.org/10.1016/j.neuroimage.2010.12.040 \\nEvans, J. S. B. T. (2003). In two minds: Dual-process accounts of reasoning. Trends in Cognitive Sciences, 7(10), \\n454–459. https://doi.org/10.1016/j.tics.2003.08.012 \\nFirestone, C. (2020). Performance vs. competence in human–machine comparisons. Proceedings of the National \\nAcademy of Sciences of the United States of America, 117(43), 26562–26571. \\nhttps://doi.org/10.1073/pnas.1905334117 \\nHahn, M., and Goyal, N. (2023). A Theory of Emergent In-Context Learning as Implicit Structure Induction. \\nhttp://arxiv.org/abs/2303.07971 \\nHeyes, C. M., and Frith, C. D. (2014). The cultural evolution of mind reading. Science, 344(6190). \\nhttps://doi.org/10.1126/science.1243091',\n",
       "  'Kidd, D. C., and Castano, E. (2013). Reading literary fiction improves theory of mind. Science, 342(6156), 377–380. \\nhttps://doi.org/10.1126/science.1239918 \\nKojima, T., Gu, S. S., Reid, M., Matsuo, Y., and Iwasawa, Y. (2022). Large Language Models are Zero-Shot \\nReasoners. NeurIPS. http://arxiv.org/abs/2205.11916 \\nKosinski, M. (2023). Theory of Mind May Have Spontaneously Emerged in Large Language Models. ArXiv. \\nhttps://doi.org/https://doi.org/10.48550/arXiv.2302.02083 \\nKrupenye, C., and Call, J. (2019). Theory of mind in animals: Current and future directions. Wiley Interdisciplinary \\nReviews: Cognitive Science, 10(6), 1–25. https://doi.org/10.1002/wcs.1503 \\nLangley, C., Cirstea, B. I., Cuzzolin, F., and Sahakian, B. J. (2022). Theory of Mind and Preference Learning at the \\nInterface of Cognitive Science, Neuroscience, and AI: A Review. Frontiers in Artificial Intelligence, 5(April), \\n1–17. https://doi.org/10.3389/frai.2022.778852',\n",
       "  'Magister, L. C., Mallinson, J., Adamek, J., Malmi, E., and Severyn, A. (2022). Teaching Small Language Models to \\nReason. http://arxiv.org/abs/2212.08410 \\nMahowald, K., Ivanova, A. A., Blank, I. A., Kanwisher, N., Tenenbaum, J. B., and Fedorenko, E. (2023). \\nDissociating language and thought in large language models: a cognitive perspective. 2. \\nhttp://arxiv.org/abs/2301.06627 \\nMitchell, M., and Krakauer, D. C. (2022). The Debate Over Understanding in AI’s Large Language Models. 1–13. \\nhttp://arxiv.org/abs/2210.13966 \\nMoran, J. M., Young, L. L., Saxe, R., Lee, S. M., O’Young, D., Mavros, P. L., and Gabrieli, J. D. (2011). Impaired \\ntheory of mind for moral judgment in high-functioning autism. Proceedings of the National Academy of \\nSciences of the United States of America, 108(7), 2688–2692. https://doi.org/10.1073/pnas.1011734108 \\nOpenAI. (2022). Introducing ChatGPT. https://openai.com/blog/chatgpt \\nOpenAI. (2023a). GPT-4 Technical Report. 4, 1–100. http://arxiv.org/abs/2303.08774',\n",
       "  'OpenAI. (2023b). GPT Models Documentation. https://platform.openai.com/docs/models/overview \\nOpenAI. (2023c). Model index for researchers. https://platform.openai.com/docs/model-index-for-researchers \\nOuyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C. L., Mishkin, P., Zhang, C., Agarwal, S., Slama, K., Ray, \\nA., Schulman, J., Hilton, J., Kelton, F., Miller, L., Simens, M., Askell, A., Welinder, P., Christiano, P., Leike, \\nJ., and Lowe, R. (2022). Training language models to follow instructions with human feedback. \\nhttp://arxiv.org/abs/2203.02155 \\nPovinelli, D. J., and Preuss, T. M. (1995). Theory of mind: evolutionary history of a cognitive specialization. Trends \\nin Neurosciences, 18(9), 418–424. https://doi.org/10.1016/0166-2236(95)93939-U \\nPrystawski, B., and Goodman, N. D. (2023). Why think step-by-step? Reasoning emerges from the locality of \\nexperience. http://arxiv.org/abs/2304.03843',\n",
       "  'Rae, J. W., Borgeaud, S., Cai, T., Millican, K., Hoffmann, J., Song, F., Aslanides, J., Henderson, S., Ring, R., \\nYoung, S., Rutherford, E., Hennigan, T., Menick, J., Cassirer, A., Powell, R., Driessche, G. van den, \\nHendricks, L. A., Rauh, M., Huang, P.-S., … Irving, G. (2021). Scaling Language Models: Methods, Analysis \\n& Insights from Training Gopher. http://arxiv.org/abs/2112.11446 \\nSap, M., Le Bras, R., Fried, D., and Choi, Y. (2022). Neural Theory-of-Mind? On the Limits of Social Intelligence \\nin Large LMs. Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, \\nEMNLP 2022, 3762–3780. \\nSejnowski, T. J. (2023). Large Language Models and the Reverse Turing Test. Neural Computation, 35(3), 309–\\n342. https://doi.org/10.1162/neco_a_01563 \\nSeyfarth, R. M., and Cheney, D. L. (2013). Affiliation, empathy, and the origins of Theory of Mind. Proceedings of',\n",
       "  'the National Academy of Sciences of the United States of America, 110(SUPPL2), 10349–10356. \\nhttps://doi.org/10.1073/pnas.1301223110 \\nStiennon, N., Ouyang, L., Wu, J., Ziegler, D. M., Lowe, R., Voss, C., Radford, A., Amodei, D., and Christiano, P. \\n(2020). Learning to summarize from human feedback. Advances in Neural Information Processing Systems, \\n2020-Decem(NeurIPS), 1–14. \\nTrott, S., Jones, C., Chang, T., Michaelov, J., and Bergen, B. (2022). Do Large Language Models know what \\nhumans know? http://arxiv.org/abs/2209.01515 \\nUllman, T. (2023). Large Language Models Fail on Trivial Alterations to Theory-of-Mind Tasks. \\nhttp://arxiv.org/abs/2302.08399 \\nWei, J., Wang, X., Schuurmans, D., Bosma, M., Ichter, B., Xia, F., Chi, E., Le, Q., and Zhou, D. (2022). Chain-of-\\nThought Prompting Elicits Reasoning in Large Language Models. NeurIPS, 1–43. \\nhttp://arxiv.org/abs/2201.11903 \\nWu, C. C., and Wolfe, J. M. (2018). A New Multiple Object Awareness Paradigm Shows that Imperfect Knowledge',\n",
       "  'of Object Location Is Still Knowledge. Current Biology, 28(21), 3430-3434.e3. \\nhttps://doi.org/10.1016/j.cub.2018.08.042 \\nYoung, L., Cushman, F., Hauser, M., and Saxe, R. (2007). The neural basis of the interaction between theory of \\nmind and moral judgment. Proceedings of the National Academy of Sciences of the United States of America, \\n104(20), 8235–8240. https://doi.org/10.1073/pnas.0701408104',\n",
       "  'Supplementary Material: \\n \\nSupplement A \\n \\n 16 Photo scenarios  \\nThese scenarios are adapted and modified from (Dodell-Feder et al., 2011): \\n \\n1. \"The traffic camera snapped an image of the black car as it sped through the stoplight. Soon after, the \\ncar was painted red and the license plates were changed.\" Q: Does the traffic camera show that the car \\nis black? \\n \\n2. \"A map shows the ground floor plan. A photocopy was sent to the architect yesterday, but at the time \\nthe kitchen door was missing. It was added to the map this morning.\" Q: Does the architect’s photocopy \\nshow the door? \\n  \\n3. \"A photograph was taken of an apple hanging on a tree branch. The film took half an hour to develop. \\nIn the meantime, a strong wind blew the apple to the ground.\" Q: Does the developed photograph show \\nthe apple on the tree? \\n  \\n4. \"To detect intruders, the lab uses an automated system for recording voices. In the empty lab one night,',\n",
       "  'a computer error occurs and a synthetic voice reads the error message.\" Q: Is the number of people in \\nthe lab that night zero? \\n  \\n5. \"A popular attraction in the park, pictured on many souvenirs, was a cliff face covered with ancient \\npetroglyphs. Recently, the petroglyphs crumbled and scientists have not begun to restore them.\" Q: \\nToday, can the petroglyphs be seen in the park? \\n  \\n6. \"Sargent famously painted the south bank of the river in 1885. In 1910 a huge dam was built, flooding \\nout the whole river basin, killing the old forests. Now the whole area is under water.\" Q: In the painting, \\nis the south bank of the river wooded? \\n  \\n7. \"When the picture was taken of the house, it was one story tall. Since then, the renovators added an \\nadditional story and a garage.\" Q: Is the house currently one story? \\n  \\n8. \"Accounts of the country\\'s economic success were recorded in books from the early 1900s. Soon after,',\n",
       "  'a horrible plague hit the country, and the country was sent into an economic depression.\" Q: Do early \\n1900s novels portray the country as experiencing economic wealth? \\n  \\n9. \"Part of the garden is supposed to be reserved for the roses; it\\'s labeled accordingly. Recently the garden \\nhas run wild, and dandelions have taken over the entire flower bed.\" Q: Does the label say these flowers \\nare roses?',\n",
       "  '10. \"A long time ago, an explorer mapped a small island. Since then, the water levels rose and only a tiny \\npart of the island is now left above water.\" Q: On the explorer\\'s maps, does the island appear to be \\nmostly above water? \\n \\n11. \"A large oak tree stood in front of City Hall from the time the building was built. Last year the tree fell \\ndown and was replaced by a stone fountain.\" Q: Does an antique drawing of City Hall show a fountain \\nin front? \\n  \\n12. \"A volcano erupted on a Caribbean island three months ago. Barren lava rock is all that remains today. \\nSatellite photographs show the island as it was before the eruption.\" Q: Do satellite photographs show \\nthe island is covered in lava? \\n  \\n13. \"The family\\'s old video tape recorded the daughter\\'s first birthday party at their house in Chicago. Since \\nthen, the family sold their house and moved to San Francisco.\" Q: Does the video show the family living \\nin San Francisco?',\n",
       "  '14. \"At the time a portrait was drawn of a young man, he had short brown hair and no facial hair. Now the \\nman\\'s hair is long and gray and so is his beard.\" Q: Today, is the length of the man’s beard long? \\n  \\n15. \"The girl\\'s middle school pictures showed her wearing a white blouse. Later, a red sock was accidentally \\nwashed with the blouse and the blouse turned pink.\" Q: Was the color of the blouse in the pictures pink? \\n  \\n16. \"A small leaf was placed on a wet clay flower pot. When the pot was baked at high temperatures to \\nharden the clay, the leaf crumbled, but its impression remained.\" Q: Is the actual leaf intact?',\n",
       "  'Supplement B \\n  \\n 16 ToM scenarios & the scenarios used for in-context learning: \\n16 ToM scenarios are adapted and modified from (Dodell-Feder et al., 2011). \\n \\n1. \"The weather was so warm today that all the tulips in Pam\\'s backyard suddenly bloomed. The tulips \\nnext to Pam\\'s office still have not yet flowered, though. Pam has been at work all day.\" Q: When Pam \\nis driving home after work, does she assume her tulips have bloomed? A: \\n   \\n2. \"Susie parked her sports car in the driveway. In the middle of the night, Nathan moved her car into the \\ngarage to make room for his minivan. Susie woke up early in the morning.\" Q: When Susie wakes up, \\ndoes she see the minivan in the driveway? A: \\n  \\n3. \"The morning of the high school dance Sarah placed her high heel shoes under her dress and then went \\nshopping. That afternoon, her sister borrowed the shoes and later put them under Sarah\\'s bed.\" Q: When \\nSarah gets ready, does she assume her shoes are under her dress? A:',\n",
       "  '4. \"Sally and Greg called ahead of time to make a reservation for the back-country cabin. The park ranger \\nforgot to write down the reservation and two other hikers got to the cabin first.\" Q: When Sally and \\nGreg arrive, do they find their cabin unoccupied? A: \\n  \\n5. \"When Jeff got ready this morning, he put on a light pink shirt instead of a white one. Jeff is colorblind, \\nso he can\\'t tell the difference between subtle shades of color.\" Q: Does Jeff believe he is wearing a white \\nshirt? A: \\n  \\n6. \"Larry chose a debated topic for his class paper due on Friday. The news on Thursday indicated that the \\ndebate had been solved, but Larry never read it.\" Q: When Larry writes his paper, does he think the \\ndebate has been solved? A: \\n  \\n7. \"Every day Jill goes to the coffee shop on the corner and orders a latte, her favorite drink. Today, the \\ncashier misunderstands Jill and prepares a mocha instead.\" Q: Does Jill think her drink will taste like a \\nmocha? A:',\n",
       "  '8. \"Expecting the game to be postponed because of the rain, the Garcia family took the subway home. The \\nscore was tied, 3-3. During their commute the rain stopped, and the game soon ended with a score of 5-\\n3.\" Q: When the Garcia family arrives home, do they believe the score is 5-3? A: \\n  \\n9. \"Amy walked to work today. When George woke up, he saw her car in the drive. Her room was quiet \\nand dark. George knows that when Amy is sick, she lies down in a dark room.\" Q: Does George think \\nAmy is sick today? A:',\n",
       "  '10. \"John told Mary that he had lost his keys. The two of them searched the house with no luck. Then Mary \\nwent outside to look in the car. Suddenly John noticed his keys behind the sofa.\" Q: By the time Mary \\ncomes in, does John know where his keys are? A: \\n  \\n11. \"At night a bear broke into a cooler near a tent and drank the soda. Five hours later, the campers woke \\nup and went to their cooler for breakfast.\" Q: Do the campers find their cooler empty of soda? A: \\n \\n12. \"When Lisa left Jacob, he was deep asleep on the beach. A few minutes later a wave woke him. Seeing \\nLisa was gone, Jacob decided to go swimming.\" Q: Does Lisa now believe that Jacob is asleep? A: \\n  \\n13. \"Jenny put her chocolate away in the cupboard. Then she went outside. Alan moved the chocolate from \\nthe cupboard into the fridge. Half an hour later, Jenny came back inside.\" Q: Does Jenny expect to find \\nher chocolate in the cupboard? A:',\n",
       "  'bars) show the zero-shot performance. The orange bars (right bars) show the performance with prompts that \\nallow for in-context learning (ICL). The ICL prompt includes both Two-shot CoT plus instructing step-by \\nstep thinking. The accuracy is the mean of 160 values (8 scenarios x 20 repetitions each). The error bars show \\nthe standard deviation of the accuracy over 8 scenarios for each of 20 repetitions (standard deviation across \\n20 values, each a mean of 8 scenarios). \\n \\n \\n \\n2 Data from GPT-3.5-Turbo for this particular analysis was collected before it was possible to control the temperature parameter at \\ninference time using the OpenAI API. Therefore, for this particular analysis, the temperature parameter for GPT-3.5-Turbo was the \\ndefault value (likely 0.7), whereas for the other three models the temperature was set to 0.4.',\n",
       "  '\"Anne made lasagna in the blue dish. After Anne left, Ian came home and ate the lasagna. Then he filled \\nthe blue dish with spaghetti and replaced it in the fridge.\"  \\nQ: Does Anne think the blue dish contains spaghetti?  \\nA: When Anne left, the blue dish contained lasagna. Ian came after Anne had left and replaced lasagna \\nwith spaghetti, but Anne doesn\\'t know that because she was not there. So, the answer is: No, she doesn\\'t \\nthink the blue dish contains spaghetti. \\n  \\nExample 2: \\n\"The girls left ice cream in the freezer before they went to sleep. Over night the power to the kitchen \\nwas cut and the ice cream melted.\"  \\nQ: When they get up, do the girls believe the ice cream is melted?  \\nA: The girls put the ice cream in the freezer and went to sleep. So, they don\\'t know that the power to the \\nkitchen was cut and the ice cream melted. So, the answer is: No, the girls don\\'t believe the ice cream is \\nmelted.',\n",
       "  'Supplement C \\nToM accuracy of human participants  \\nTo measure humans’ performance in ToM and Photo scenarios, we recruited 125 online participants through the \\nQualtrics platform. Participants were 18 to 65 years old, native English speakers, and located in the United States.  \\nParticipants had 18 seconds to read each scenario. Once the 18-second duration was over, they were immediately \\ndirected to a new screen showing the comprehension question. They could respond to the questions at their own \\npace by clicking on one of the two options (Yes/No). The Photo scenarios and ToM scenarios were interleaved \\nand randomized such that each participant experienced both types of scenarios. \\nThe Photo and ToM scenarios were of comparable difficulty for human participants. Participants showed similar \\naccuracy across Photo (86% ±4%) and ToM (87% ±4%) scenarios. \\nFrom these data we conclude that: \\ni) \\nthe Photo scenarios are a good control condition for the ToM scenarios, because of their',\n",
       "  'matched performance in humans. \\nii) \\nthe scenarios are relatively easy for humans to solve, but not so easy that humans are at ceiling \\nperformance (given the modest incentives for accuracy in online participants). \\nMaking a direct quantitative comparison between human and LLM performance is not warranted, because of the \\nmany differences in the testing conditions. However, the human performance does indicate that the questions \\nare sufficiently difficult that humans occasionally (>10% of the time) make errors, perhaps because they \\noverlook details in the scenario or because they make unusual assumptions or inferences.',\n",
       "  'Supplement D \\n Effects of Various In-context Examples on ToM Performance of LLMs \\nWe tested the efficacy of Photo examples, Non-ToM Inferential examples, and ToM examples in enhancing \\n ToM performance when providing chain-of-thought prompts. We used the following examples in each class: \\n1) Photo Chain-of-Thought Examples: \\nExample 1: \\nScenario: \"A long time ago, an explorer mapped a small island. Since then, the water levels rose and \\nonly a tiny part of the island is now left above water.\"  \\nQ: On the explorer\\'s maps, does the island appear to be mostly above water? \\nA: An explorer mapped an island a long time ago. Then water levels rose. Now only a tiny part of the \\nisland is above water. The maps show the island before water levels rose. Therefore, in the map most of \\nthe island is above water. So, the answer is: Yes, in the maps, most of the island is above the water. \\nExample 2: \\nScenario: \"A volcano erupted on a Caribbean island three months ago. Barren lava rock is all that',\n",
       "  'remains today. Satellite photographs show the island as it was before the eruption.\"  \\nQ: Do satellite photographs show the island is covered in lava? \\nA: A volcano erupted three months ago and as a result lava rock is all that remains today. Since the \\nphotograph shows the island before the eruptions, it does not show the island covered in Laval. So, the \\nanswer is: No, the photographs does not show the island covered in lava. \\n \\n2) Non-ToM Inferential Chain-of-Thought Examples: \\nExample 1: \\nScenario: \"Sarah was excited to show off her new dress at the party. As she walked in, she noticed that \\nanother girl was wearing the exact same dress. She quickly went back home to change and then returned \\nto the party.\"  \\nQ: Did Sarah wear her favorite dress the whole night? \\nA: Sarah was excited about her new dress and wanted to wear it as the party. But since another girl was \\nwearing the same dress, she went home and changed to a different dress. So, the answer is: No, she did',\n",
       "  'not wear her favorite dress the whole night. \\nExample 2: \\nScenario: \"Lucy was in a hurry to get to work, so she quickly grabbed her lunch from the fridge and left \\nthe house. At lunchtime, she opened her lunchbox and realized she had accidentally taken her \\nroommate\\'s lunch.\" \\nQ: Will Lucy\\'s roommate have her own lunch to eat that day? \\nA: Lucy was in hurry and mistakenly grabbed her roommate lunch. So, her roommate’s lunch is now \\nwith Lucy. So, the answer is: No, Lucy\\'s roommate will not have her own lunch to eat that day. \\n \\n3) ToM Chain-of-Thought Examples: \\nExample 1: \\nScenario: \"Anne made lasagna in the blue dish. After Anne left, Ian came home and ate the lasagna. \\nThen he filled the blue dish with spaghetti and replaced it in the fridge.\"  \\nQ: Does Anne think the blue dish contains spaghetti?',\n",
       "  'A: When Anne left the blue dish contained lasagna. Ian came after Anne had left and replaced lasagna \\nwith spaghetti, but Anne doesn\\'t know that because she was not there. So, the answer is: No, she doesn\\'t \\nthink the blue dish contains spaghetti.  \\nExample 2: \\nScenario: \"The girls left ice cream in the freezer before they went to sleep. Over night the power to the \\nkitchen was cut and the ice cream melted.\"  \\nQ: When they get up, do the girls believe the ice cream is melted?  \\nA: The girls put the ice cream in the freezer and went to sleep. So, they don\\'t know that the power to the \\nkitchen was cut and the ice cream melted. So, the answer is: No, the girls don\\'t believe the ice cream is \\nmelted. \\n  \\n GPT-4 \\nFor this analysis, the performance of GPT-4 was assessed on the 4 scenarios below. These are scenarios that \\n GPT-4 answered incorrectly in zero-shot testing. \\nScenario 1: \\n\"Amy walked to work today. When George woke up, he saw her car in the drive. Her room was quiet',\n",
       "  'and dark. George knows that when Amy is sick, she lies down in a dark room.\" \\nQ: Does George think Amy is sick today? \\n \\nScenario 2: \\n\"When Lisa left Jacob, he was deep asleep on the beach. A few minutes later a wave woke him. Seeing \\nLisa was gone, Jacob decided to go swimming.\"  \\nQ: Does Lisa now believe that Jacob is asleep? \\n \\nScenario 3: \\n\"The weather was so warm today that all the tulips in Pam\\'s backyard suddenly bloomed. The tulips \\nnext to Pam\\'s office still have not yet flowered, though. Pam has been at work all day.\"  \\nQ: When Pam is driving home after work, does she assume her tulips have bloomed? \\n \\nScenario 4: \\n\"Every day Jill goes to the coffee shop on the corner and orders a latte, her favorite drink. Today, the \\ncashier misunderstands Jill and prepares a mocha instead.\" \\nQ: Does Jill think her drink will taste like a mocha? \\n  \\n Davinci-3 \\nFor this analysis, the performance of Davinci-3 was assessed on the 6 scenarios below. These are scenarios that',\n",
       "  'Davinci-3 answered incorrectly in zero-shot testing.  \\nScenario 1) \\n\"Susie parked her sports car in the driveway. In the middle of the night, Nathan moved her car into the \\ngarage to make room for his minivan. Susie woke up early in the morning.\"',\n",
       "  'Q: When Susie wakes up, does she see the minivan in the driveway? \\n \\nScenario 2) \\n\"When Jeff got ready this morning, he put on a light pink shirt instead of a white one. Jeff is colorblind, \\nso he can\\'t tell the difference between subtle shades of color.\"  \\nQ: Does Jeff believe he is wearing a white shirt? \\n \\nScenario 3) \\n\"When Lisa left Jacob, he was deep asleep on the beach. A few minutes later a wave woke him. Seeing \\nLisa was gone, Jacob decided to go swimming.\"  \\nQ: Does Lisa now believe that Jacob is asleep? \\n \\nScenario 4) \\n\"Laura didn\\'t have time to braid her horse’s mane before going to camp. While she was at camp, William \\nbrushed Laura\\'s horse and braided the horse’s mane for her.\"  \\nQ: When Laura is at camp, does she assume that her horse\\'s hair is braided? \\n \\nScenario 5) \\n\"The morning of the high school dance Sarah placed her high heel shoes under her dress and then went \\nshopping. That afternoon, her sister borrowed the shoes and later put them under Sarah\\'s bed.\"',\n",
       "  'Q: When Sarah gets ready, does she assume her shoes are under her dress? \\n \\nScenario 6) \\n\"Jenny put her chocolate away in the cupboard. Then she went outside. Alan moved the chocolate from \\nthe cupboard into the fridge. Half an hour later, Jenny came back inside.\" \\nQ: Does Jenny expect to find her chocolate in the cupboard? \\n   \\n Per-scenario accuracies are shown in Figure S.1. The mean accuracy for this analysis is shown in Figure 4.',\n",
       "  'Figure S.1. Per-Scenario Accuracy using 4 prompting conditions in GPT-4 and Davinci-3. For each \\ncondition (e.g. Inferential CoT), the per-scenario accuracy is calculated based on the mean accuracy across \\n20 repetitions of a single prompt.',\n",
       "  'Supplement E \\n Generalizability of ToM Results to Inferential Reasoning in Non-ToM Scenarios \\nTo investigate the generalizability of our prompting methods, we designed and tested a set of scenarios that \\nrequired inferential reasoning, but which were not false-belief scenarios. In these new scenarios, the reasoning \\ndoes not follow the same steps as in the false-belief scenarios (e.g. person P does not know about event E, etc). \\nTherefore, the specific reasoning steps used in the in-context ToM CoT examples cannot be directly transferred \\nto these non-ToM scenarios. We created and tested the following non-ToM scenarios: \\n1. \"Anna was baking cookies for her friends. She realized she was out of sugar and went to the store to \\nbuy some. While she was gone, her dog, Max, jumped on the counter and ate the cookie dough.\" Q: \\nWill Anna be able to finish making cookies after returning?',\n",
       "  '2. \"Lisa was running late for work, so she quickly grabbed her lunch out of the fridge and left the house. \\nSeeing Lisa leaving the house, her cat knocked over her coffee mug on the kitchen counter.\" Q: Will \\nLisa find the kitchen counter clean when she returns? \\n \\n3. \"Lucy was in a hurry to get to work, so she quickly grabbed her lunch from the fridge and left the house. \\nAt lunchtime, she opened her lunchbox and realized she had accidentally taken her roommate\\'s lunch.\" \\nQ: Will Lucy\\'s roommate have her own lunch to eat that day? \\n \\n4. \"Lucy was baking a cake for her friend\\'s birthday. She put the cake in the oven and set a 20-minute \\ntimer. She then went to the living room to watch her favorite show for 30 minutes.\" Q: Will the cake be \\novercooked by the time Lucy checks the oven? \\n \\n5. \"Tim and Amy went on a hike through the forest. After walking for several hours, they came across a',\n",
       "  'bear. They quickly and quietly backed away, retracing their steps back to the starting point.\" Q: Did \\nTim and Amy finish their hike? \\n \\n6. \"Sarah was excited to show off her new dress at the party. As she walked in, she noticed that another \\ngirl was wearing the exact same dress. She quickly went back home to change and then returned to the \\nparty.\" Q: Did Sarah wear her favorite dress the whole night? \\n \\n7. \"During a thunderstorm, Sarah closed all the windows in her house. She then went to the basement to \\ndo laundry. While she was downstairs, a tree branch fell and broke one of the windows upstairs.\" Q: \\nWhen Sarah finishes the laundry, does she find all the windows closed? \\n \\n8. \"Lucy spent hours preparing a delicious meal for her husband\\'s surprise birthday party. Just as she was \\nsetting the table, she accidentally knocked over a glass of red wine, spilling it all over the food. She \\nordered pizza as a last-minute replacement.\" Q: Does Lucy serve her homemade meal to the guests?',\n",
       "  'We tested two conditions: (1) The zero-shot performance of the LLMs in these new scenarios; (2) The efficacy \\nof the same prompts, Two-shot chain-of-thought ToM examples plus step-by-step thinking, for these new set of \\n non-ToM scenarios. \\nWe found a similar pattern between the performance in the non-ToM scenarios and the ToM scenarios (Figure \\nS.2): First, similar to results from Figure 2B, the zero-shot accuracy dropped from Davinci-2 to Davinci-3, and \\nfrom Davinci-3 to GPT-3.5-Turbo2, while GPT-4 showed the highest accuracy, reaching ceiling performance. \\nSecond, similar to the results from Figure 3, we found that prompting significantly boosted the ToM accuracy \\nfor Davinci-3 and GPT-3.5-Turbo, while it did not improve the accuracy of Davinci-2. The performance of GPT-\\n4 was at ceiling in the zero-shot setting, so there was no room for benefit from prompting. Thus, this preliminary',\n",
       "  'analysis indicates that the performance gains from prompting are not limited to inferential ToM tasks, but may \\n extend to other inferential tasks.  \\nThis result is notable for two reasons: (i) The reasoning steps for the chain-of-thought examples (which were \\nToM examples) were different from the reasoning steps required to answer the questions (which were non-ToM \\nexamples). Therefore, these performance increases are not merely due to copying the specific reasoning steps in \\ndemonstrated in the prompt. (ii) These questions do not ask about an agent’s state of the mind, but instead require \\ninference about a particular situation. Therefore, it is possible that our primary findings concerning ToM may \\n  generalize to a broader class of inferential reasoning tasks. \\n \\n \\n \\nFigure S.2. Accuracy of LLMs in Non-ToM Scenarios. Accuracy of Davinci-2, Davinci-3, GPT-3.5-\\nTurbo, and GPT-4 in new scenarios that do not involve reasoning about agents’ beliefs. The gray bars (left',\n",
       "  '“participant” in the experiment. Therefore, we have 20 accuracy values, each averaged across 16 values from \\ndifferent ToM questions. The error bars then show the standard deviation of the 20 mean-accuracy values. \\n \\nPerformance when Supported by Prompting \\nIn-context learning via modified prompting boosted the ToM performance of all GPT models that were released \\n after Davinci-2 (Figure 3).  \\nFirst, we instructed the models to think step by step (SS). We found that SS thinking enhanced the performance \\nof Davinci-3, GPT-3.5-Turbo, and GPT-4 (e.g. independent t-test for zero-shot vs SS thinking for GPT-4: \\uf044Acc'],\n",
       " 'metadatas': [{'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'page_number': 1,\n",
       "   'total_pages': 27,\n",
       "   'format': 'PDF 1.7',\n",
       "   'title': '',\n",
       "   'author': 'Shima Rahimi Moghaddam',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft Word',\n",
       "   'producer': '',\n",
       "   'creationDate': \"D:20230426034952+00'00'\",\n",
       "   'modDate': \"D:20230426034952+00'00'\",\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'page_number': 20,\n",
       "   'total_pages': 27,\n",
       "   'format': 'PDF 1.7',\n",
       "   'title': '',\n",
       "   'author': 'Shima Rahimi Moghaddam',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft Word',\n",
       "   'producer': '',\n",
       "   'creationDate': \"D:20230426034952+00'00'\",\n",
       "   'modDate': \"D:20230426034952+00'00'\",\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'page_number': 1,\n",
       "   'total_pages': 27,\n",
       "   'format': 'PDF 1.7',\n",
       "   'title': '',\n",
       "   'author': 'Shima Rahimi Moghaddam',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft Word',\n",
       "   'producer': '',\n",
       "   'creationDate': \"D:20230426034952+00'00'\",\n",
       "   'modDate': \"D:20230426034952+00'00'\",\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'page_number': 2,\n",
       "   'total_pages': 27,\n",
       "   'format': 'PDF 1.7',\n",
       "   'title': '',\n",
       "   'author': 'Shima Rahimi Moghaddam',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft Word',\n",
       "   'producer': '',\n",
       "   'creationDate': \"D:20230426034952+00'00'\",\n",
       "   'modDate': \"D:20230426034952+00'00'\",\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'page_number': 2,\n",
       "   'total_pages': 27,\n",
       "   'format': 'PDF 1.7',\n",
       "   'title': '',\n",
       "   'author': 'Shima Rahimi Moghaddam',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft Word',\n",
       "   'producer': '',\n",
       "   'creationDate': \"D:20230426034952+00'00'\",\n",
       "   'modDate': \"D:20230426034952+00'00'\",\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'page_number': 2,\n",
       "   'total_pages': 27,\n",
       "   'format': 'PDF 1.7',\n",
       "   'title': '',\n",
       "   'author': 'Shima Rahimi Moghaddam',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft Word',\n",
       "   'producer': '',\n",
       "   'creationDate': \"D:20230426034952+00'00'\",\n",
       "   'modDate': \"D:20230426034952+00'00'\",\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'page_number': 2,\n",
       "   'total_pages': 27,\n",
       "   'format': 'PDF 1.7',\n",
       "   'title': '',\n",
       "   'author': 'Shima Rahimi Moghaddam',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft Word',\n",
       "   'producer': '',\n",
       "   'creationDate': \"D:20230426034952+00'00'\",\n",
       "   'modDate': \"D:20230426034952+00'00'\",\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'page_number': 3,\n",
       "   'total_pages': 27,\n",
       "   'format': 'PDF 1.7',\n",
       "   'title': '',\n",
       "   'author': 'Shima Rahimi Moghaddam',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft Word',\n",
       "   'producer': '',\n",
       "   'creationDate': \"D:20230426034952+00'00'\",\n",
       "   'modDate': \"D:20230426034952+00'00'\",\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'page_number': 3,\n",
       "   'total_pages': 27,\n",
       "   'format': 'PDF 1.7',\n",
       "   'title': '',\n",
       "   'author': 'Shima Rahimi Moghaddam',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft Word',\n",
       "   'producer': '',\n",
       "   'creationDate': \"D:20230426034952+00'00'\",\n",
       "   'modDate': \"D:20230426034952+00'00'\",\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'page_number': 3,\n",
       "   'total_pages': 27,\n",
       "   'format': 'PDF 1.7',\n",
       "   'title': '',\n",
       "   'author': 'Shima Rahimi Moghaddam',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft Word',\n",
       "   'producer': '',\n",
       "   'creationDate': \"D:20230426034952+00'00'\",\n",
       "   'modDate': \"D:20230426034952+00'00'\",\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'page_number': 3,\n",
       "   'total_pages': 27,\n",
       "   'format': 'PDF 1.7',\n",
       "   'title': '',\n",
       "   'author': 'Shima Rahimi Moghaddam',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft Word',\n",
       "   'producer': '',\n",
       "   'creationDate': \"D:20230426034952+00'00'\",\n",
       "   'modDate': \"D:20230426034952+00'00'\",\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'page_number': 4,\n",
       "   'total_pages': 27,\n",
       "   'format': 'PDF 1.7',\n",
       "   'title': '',\n",
       "   'author': 'Shima Rahimi Moghaddam',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft Word',\n",
       "   'producer': '',\n",
       "   'creationDate': \"D:20230426034952+00'00'\",\n",
       "   'modDate': \"D:20230426034952+00'00'\",\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'page_number': 4,\n",
       "   'total_pages': 27,\n",
       "   'format': 'PDF 1.7',\n",
       "   'title': '',\n",
       "   'author': 'Shima Rahimi Moghaddam',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft Word',\n",
       "   'producer': '',\n",
       "   'creationDate': \"D:20230426034952+00'00'\",\n",
       "   'modDate': \"D:20230426034952+00'00'\",\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'page_number': 4,\n",
       "   'total_pages': 27,\n",
       "   'format': 'PDF 1.7',\n",
       "   'title': '',\n",
       "   'author': 'Shima Rahimi Moghaddam',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft Word',\n",
       "   'producer': '',\n",
       "   'creationDate': \"D:20230426034952+00'00'\",\n",
       "   'modDate': \"D:20230426034952+00'00'\",\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'page_number': 4,\n",
       "   'total_pages': 27,\n",
       "   'format': 'PDF 1.7',\n",
       "   'title': '',\n",
       "   'author': 'Shima Rahimi Moghaddam',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft Word',\n",
       "   'producer': '',\n",
       "   'creationDate': \"D:20230426034952+00'00'\",\n",
       "   'modDate': \"D:20230426034952+00'00'\",\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'page_number': 5,\n",
       "   'total_pages': 27,\n",
       "   'format': 'PDF 1.7',\n",
       "   'title': '',\n",
       "   'author': 'Shima Rahimi Moghaddam',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft Word',\n",
       "   'producer': '',\n",
       "   'creationDate': \"D:20230426034952+00'00'\",\n",
       "   'modDate': \"D:20230426034952+00'00'\",\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'page_number': 5,\n",
       "   'total_pages': 27,\n",
       "   'format': 'PDF 1.7',\n",
       "   'title': '',\n",
       "   'author': 'Shima Rahimi Moghaddam',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft Word',\n",
       "   'producer': '',\n",
       "   'creationDate': \"D:20230426034952+00'00'\",\n",
       "   'modDate': \"D:20230426034952+00'00'\",\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'page_number': 6,\n",
       "   'total_pages': 27,\n",
       "   'format': 'PDF 1.7',\n",
       "   'title': '',\n",
       "   'author': 'Shima Rahimi Moghaddam',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft Word',\n",
       "   'producer': '',\n",
       "   'creationDate': \"D:20230426034952+00'00'\",\n",
       "   'modDate': \"D:20230426034952+00'00'\",\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'page_number': 7,\n",
       "   'total_pages': 27,\n",
       "   'format': 'PDF 1.7',\n",
       "   'title': '',\n",
       "   'author': 'Shima Rahimi Moghaddam',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft Word',\n",
       "   'producer': '',\n",
       "   'creationDate': \"D:20230426034952+00'00'\",\n",
       "   'modDate': \"D:20230426034952+00'00'\",\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'page_number': 7,\n",
       "   'total_pages': 27,\n",
       "   'format': 'PDF 1.7',\n",
       "   'title': '',\n",
       "   'author': 'Shima Rahimi Moghaddam',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft Word',\n",
       "   'producer': '',\n",
       "   'creationDate': \"D:20230426034952+00'00'\",\n",
       "   'modDate': \"D:20230426034952+00'00'\",\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'page_number': 1,\n",
       "   'total_pages': 27,\n",
       "   'format': 'PDF 1.7',\n",
       "   'title': '',\n",
       "   'author': 'Shima Rahimi Moghaddam',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft Word',\n",
       "   'producer': '',\n",
       "   'creationDate': \"D:20230426034952+00'00'\",\n",
       "   'modDate': \"D:20230426034952+00'00'\",\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'page_number': 8,\n",
       "   'total_pages': 27,\n",
       "   'format': 'PDF 1.7',\n",
       "   'title': '',\n",
       "   'author': 'Shima Rahimi Moghaddam',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft Word',\n",
       "   'producer': '',\n",
       "   'creationDate': \"D:20230426034952+00'00'\",\n",
       "   'modDate': \"D:20230426034952+00'00'\",\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'page_number': 8,\n",
       "   'total_pages': 27,\n",
       "   'format': 'PDF 1.7',\n",
       "   'title': '',\n",
       "   'author': 'Shima Rahimi Moghaddam',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft Word',\n",
       "   'producer': '',\n",
       "   'creationDate': \"D:20230426034952+00'00'\",\n",
       "   'modDate': \"D:20230426034952+00'00'\",\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'page_number': 9,\n",
       "   'total_pages': 27,\n",
       "   'format': 'PDF 1.7',\n",
       "   'title': '',\n",
       "   'author': 'Shima Rahimi Moghaddam',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft Word',\n",
       "   'producer': '',\n",
       "   'creationDate': \"D:20230426034952+00'00'\",\n",
       "   'modDate': \"D:20230426034952+00'00'\",\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'page_number': 9,\n",
       "   'total_pages': 27,\n",
       "   'format': 'PDF 1.7',\n",
       "   'title': '',\n",
       "   'author': 'Shima Rahimi Moghaddam',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft Word',\n",
       "   'producer': '',\n",
       "   'creationDate': \"D:20230426034952+00'00'\",\n",
       "   'modDate': \"D:20230426034952+00'00'\",\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'page_number': 9,\n",
       "   'total_pages': 27,\n",
       "   'format': 'PDF 1.7',\n",
       "   'title': '',\n",
       "   'author': 'Shima Rahimi Moghaddam',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft Word',\n",
       "   'producer': '',\n",
       "   'creationDate': \"D:20230426034952+00'00'\",\n",
       "   'modDate': \"D:20230426034952+00'00'\",\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'page_number': 9,\n",
       "   'total_pages': 27,\n",
       "   'format': 'PDF 1.7',\n",
       "   'title': '',\n",
       "   'author': 'Shima Rahimi Moghaddam',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft Word',\n",
       "   'producer': '',\n",
       "   'creationDate': \"D:20230426034952+00'00'\",\n",
       "   'modDate': \"D:20230426034952+00'00'\",\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'page_number': 10,\n",
       "   'total_pages': 27,\n",
       "   'format': 'PDF 1.7',\n",
       "   'title': '',\n",
       "   'author': 'Shima Rahimi Moghaddam',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft Word',\n",
       "   'producer': '',\n",
       "   'creationDate': \"D:20230426034952+00'00'\",\n",
       "   'modDate': \"D:20230426034952+00'00'\",\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'page_number': 10,\n",
       "   'total_pages': 27,\n",
       "   'format': 'PDF 1.7',\n",
       "   'title': '',\n",
       "   'author': 'Shima Rahimi Moghaddam',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft Word',\n",
       "   'producer': '',\n",
       "   'creationDate': \"D:20230426034952+00'00'\",\n",
       "   'modDate': \"D:20230426034952+00'00'\",\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'page_number': 10,\n",
       "   'total_pages': 27,\n",
       "   'format': 'PDF 1.7',\n",
       "   'title': '',\n",
       "   'author': 'Shima Rahimi Moghaddam',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft Word',\n",
       "   'producer': '',\n",
       "   'creationDate': \"D:20230426034952+00'00'\",\n",
       "   'modDate': \"D:20230426034952+00'00'\",\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'page_number': 11,\n",
       "   'total_pages': 27,\n",
       "   'format': 'PDF 1.7',\n",
       "   'title': '',\n",
       "   'author': 'Shima Rahimi Moghaddam',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft Word',\n",
       "   'producer': '',\n",
       "   'creationDate': \"D:20230426034952+00'00'\",\n",
       "   'modDate': \"D:20230426034952+00'00'\",\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'page_number': 11,\n",
       "   'total_pages': 27,\n",
       "   'format': 'PDF 1.7',\n",
       "   'title': '',\n",
       "   'author': 'Shima Rahimi Moghaddam',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft Word',\n",
       "   'producer': '',\n",
       "   'creationDate': \"D:20230426034952+00'00'\",\n",
       "   'modDate': \"D:20230426034952+00'00'\",\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'page_number': 11,\n",
       "   'total_pages': 27,\n",
       "   'format': 'PDF 1.7',\n",
       "   'title': '',\n",
       "   'author': 'Shima Rahimi Moghaddam',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft Word',\n",
       "   'producer': '',\n",
       "   'creationDate': \"D:20230426034952+00'00'\",\n",
       "   'modDate': \"D:20230426034952+00'00'\",\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'page_number': 11,\n",
       "   'total_pages': 27,\n",
       "   'format': 'PDF 1.7',\n",
       "   'title': '',\n",
       "   'author': 'Shima Rahimi Moghaddam',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft Word',\n",
       "   'producer': '',\n",
       "   'creationDate': \"D:20230426034952+00'00'\",\n",
       "   'modDate': \"D:20230426034952+00'00'\",\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'page_number': 11,\n",
       "   'total_pages': 27,\n",
       "   'format': 'PDF 1.7',\n",
       "   'title': '',\n",
       "   'author': 'Shima Rahimi Moghaddam',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft Word',\n",
       "   'producer': '',\n",
       "   'creationDate': \"D:20230426034952+00'00'\",\n",
       "   'modDate': \"D:20230426034952+00'00'\",\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'page_number': 12,\n",
       "   'total_pages': 27,\n",
       "   'format': 'PDF 1.7',\n",
       "   'title': '',\n",
       "   'author': 'Shima Rahimi Moghaddam',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft Word',\n",
       "   'producer': '',\n",
       "   'creationDate': \"D:20230426034952+00'00'\",\n",
       "   'modDate': \"D:20230426034952+00'00'\",\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'page_number': 12,\n",
       "   'total_pages': 27,\n",
       "   'format': 'PDF 1.7',\n",
       "   'title': '',\n",
       "   'author': 'Shima Rahimi Moghaddam',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft Word',\n",
       "   'producer': '',\n",
       "   'creationDate': \"D:20230426034952+00'00'\",\n",
       "   'modDate': \"D:20230426034952+00'00'\",\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'page_number': 12,\n",
       "   'total_pages': 27,\n",
       "   'format': 'PDF 1.7',\n",
       "   'title': '',\n",
       "   'author': 'Shima Rahimi Moghaddam',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft Word',\n",
       "   'producer': '',\n",
       "   'creationDate': \"D:20230426034952+00'00'\",\n",
       "   'modDate': \"D:20230426034952+00'00'\",\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'page_number': 12,\n",
       "   'total_pages': 27,\n",
       "   'format': 'PDF 1.7',\n",
       "   'title': '',\n",
       "   'author': 'Shima Rahimi Moghaddam',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft Word',\n",
       "   'producer': '',\n",
       "   'creationDate': \"D:20230426034952+00'00'\",\n",
       "   'modDate': \"D:20230426034952+00'00'\",\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'page_number': 12,\n",
       "   'total_pages': 27,\n",
       "   'format': 'PDF 1.7',\n",
       "   'title': '',\n",
       "   'author': 'Shima Rahimi Moghaddam',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft Word',\n",
       "   'producer': '',\n",
       "   'creationDate': \"D:20230426034952+00'00'\",\n",
       "   'modDate': \"D:20230426034952+00'00'\",\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'page_number': 13,\n",
       "   'total_pages': 27,\n",
       "   'format': 'PDF 1.7',\n",
       "   'title': '',\n",
       "   'author': 'Shima Rahimi Moghaddam',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft Word',\n",
       "   'producer': '',\n",
       "   'creationDate': \"D:20230426034952+00'00'\",\n",
       "   'modDate': \"D:20230426034952+00'00'\",\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'page_number': 13,\n",
       "   'total_pages': 27,\n",
       "   'format': 'PDF 1.7',\n",
       "   'title': '',\n",
       "   'author': 'Shima Rahimi Moghaddam',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft Word',\n",
       "   'producer': '',\n",
       "   'creationDate': \"D:20230426034952+00'00'\",\n",
       "   'modDate': \"D:20230426034952+00'00'\",\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'page_number': 13,\n",
       "   'total_pages': 27,\n",
       "   'format': 'PDF 1.7',\n",
       "   'title': '',\n",
       "   'author': 'Shima Rahimi Moghaddam',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft Word',\n",
       "   'producer': '',\n",
       "   'creationDate': \"D:20230426034952+00'00'\",\n",
       "   'modDate': \"D:20230426034952+00'00'\",\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'page_number': 14,\n",
       "   'total_pages': 27,\n",
       "   'format': 'PDF 1.7',\n",
       "   'title': '',\n",
       "   'author': 'Shima Rahimi Moghaddam',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft Word',\n",
       "   'producer': '',\n",
       "   'creationDate': \"D:20230426034952+00'00'\",\n",
       "   'modDate': \"D:20230426034952+00'00'\",\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'page_number': 14,\n",
       "   'total_pages': 27,\n",
       "   'format': 'PDF 1.7',\n",
       "   'title': '',\n",
       "   'author': 'Shima Rahimi Moghaddam',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft Word',\n",
       "   'producer': '',\n",
       "   'creationDate': \"D:20230426034952+00'00'\",\n",
       "   'modDate': \"D:20230426034952+00'00'\",\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'page_number': 14,\n",
       "   'total_pages': 27,\n",
       "   'format': 'PDF 1.7',\n",
       "   'title': '',\n",
       "   'author': 'Shima Rahimi Moghaddam',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft Word',\n",
       "   'producer': '',\n",
       "   'creationDate': \"D:20230426034952+00'00'\",\n",
       "   'modDate': \"D:20230426034952+00'00'\",\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'page_number': 15,\n",
       "   'total_pages': 27,\n",
       "   'format': 'PDF 1.7',\n",
       "   'title': '',\n",
       "   'author': 'Shima Rahimi Moghaddam',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft Word',\n",
       "   'producer': '',\n",
       "   'creationDate': \"D:20230426034952+00'00'\",\n",
       "   'modDate': \"D:20230426034952+00'00'\",\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'page_number': 15,\n",
       "   'total_pages': 27,\n",
       "   'format': 'PDF 1.7',\n",
       "   'title': '',\n",
       "   'author': 'Shima Rahimi Moghaddam',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft Word',\n",
       "   'producer': '',\n",
       "   'creationDate': \"D:20230426034952+00'00'\",\n",
       "   'modDate': \"D:20230426034952+00'00'\",\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'page_number': 15,\n",
       "   'total_pages': 27,\n",
       "   'format': 'PDF 1.7',\n",
       "   'title': '',\n",
       "   'author': 'Shima Rahimi Moghaddam',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft Word',\n",
       "   'producer': '',\n",
       "   'creationDate': \"D:20230426034952+00'00'\",\n",
       "   'modDate': \"D:20230426034952+00'00'\",\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'page_number': 15,\n",
       "   'total_pages': 27,\n",
       "   'format': 'PDF 1.7',\n",
       "   'title': '',\n",
       "   'author': 'Shima Rahimi Moghaddam',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft Word',\n",
       "   'producer': '',\n",
       "   'creationDate': \"D:20230426034952+00'00'\",\n",
       "   'modDate': \"D:20230426034952+00'00'\",\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'page_number': 16,\n",
       "   'total_pages': 27,\n",
       "   'format': 'PDF 1.7',\n",
       "   'title': '',\n",
       "   'author': 'Shima Rahimi Moghaddam',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft Word',\n",
       "   'producer': '',\n",
       "   'creationDate': \"D:20230426034952+00'00'\",\n",
       "   'modDate': \"D:20230426034952+00'00'\",\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'page_number': 16,\n",
       "   'total_pages': 27,\n",
       "   'format': 'PDF 1.7',\n",
       "   'title': '',\n",
       "   'author': 'Shima Rahimi Moghaddam',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft Word',\n",
       "   'producer': '',\n",
       "   'creationDate': \"D:20230426034952+00'00'\",\n",
       "   'modDate': \"D:20230426034952+00'00'\",\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'page_number': 17,\n",
       "   'total_pages': 27,\n",
       "   'format': 'PDF 1.7',\n",
       "   'title': '',\n",
       "   'author': 'Shima Rahimi Moghaddam',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft Word',\n",
       "   'producer': '',\n",
       "   'creationDate': \"D:20230426034952+00'00'\",\n",
       "   'modDate': \"D:20230426034952+00'00'\",\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'page_number': 17,\n",
       "   'total_pages': 27,\n",
       "   'format': 'PDF 1.7',\n",
       "   'title': '',\n",
       "   'author': 'Shima Rahimi Moghaddam',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft Word',\n",
       "   'producer': '',\n",
       "   'creationDate': \"D:20230426034952+00'00'\",\n",
       "   'modDate': \"D:20230426034952+00'00'\",\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'page_number': 17,\n",
       "   'total_pages': 27,\n",
       "   'format': 'PDF 1.7',\n",
       "   'title': '',\n",
       "   'author': 'Shima Rahimi Moghaddam',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft Word',\n",
       "   'producer': '',\n",
       "   'creationDate': \"D:20230426034952+00'00'\",\n",
       "   'modDate': \"D:20230426034952+00'00'\",\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'page_number': 18,\n",
       "   'total_pages': 27,\n",
       "   'format': 'PDF 1.7',\n",
       "   'title': '',\n",
       "   'author': 'Shima Rahimi Moghaddam',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft Word',\n",
       "   'producer': '',\n",
       "   'creationDate': \"D:20230426034952+00'00'\",\n",
       "   'modDate': \"D:20230426034952+00'00'\",\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'page_number': 18,\n",
       "   'total_pages': 27,\n",
       "   'format': 'PDF 1.7',\n",
       "   'title': '',\n",
       "   'author': 'Shima Rahimi Moghaddam',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft Word',\n",
       "   'producer': '',\n",
       "   'creationDate': \"D:20230426034952+00'00'\",\n",
       "   'modDate': \"D:20230426034952+00'00'\",\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'page_number': 19,\n",
       "   'total_pages': 27,\n",
       "   'format': 'PDF 1.7',\n",
       "   'title': '',\n",
       "   'author': 'Shima Rahimi Moghaddam',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft Word',\n",
       "   'producer': '',\n",
       "   'creationDate': \"D:20230426034952+00'00'\",\n",
       "   'modDate': \"D:20230426034952+00'00'\",\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'page_number': 19,\n",
       "   'total_pages': 27,\n",
       "   'format': 'PDF 1.7',\n",
       "   'title': '',\n",
       "   'author': 'Shima Rahimi Moghaddam',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft Word',\n",
       "   'producer': '',\n",
       "   'creationDate': \"D:20230426034952+00'00'\",\n",
       "   'modDate': \"D:20230426034952+00'00'\",\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'page_number': 19,\n",
       "   'total_pages': 27,\n",
       "   'format': 'PDF 1.7',\n",
       "   'title': '',\n",
       "   'author': 'Shima Rahimi Moghaddam',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft Word',\n",
       "   'producer': '',\n",
       "   'creationDate': \"D:20230426034952+00'00'\",\n",
       "   'modDate': \"D:20230426034952+00'00'\",\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'page_number': 20,\n",
       "   'total_pages': 27,\n",
       "   'format': 'PDF 1.7',\n",
       "   'title': '',\n",
       "   'author': 'Shima Rahimi Moghaddam',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft Word',\n",
       "   'producer': '',\n",
       "   'creationDate': \"D:20230426034952+00'00'\",\n",
       "   'modDate': \"D:20230426034952+00'00'\",\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'page_number': 27,\n",
       "   'total_pages': 27,\n",
       "   'format': 'PDF 1.7',\n",
       "   'title': '',\n",
       "   'author': 'Shima Rahimi Moghaddam',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft Word',\n",
       "   'producer': '',\n",
       "   'creationDate': \"D:20230426034952+00'00'\",\n",
       "   'modDate': \"D:20230426034952+00'00'\",\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'page_number': 20,\n",
       "   'total_pages': 27,\n",
       "   'format': 'PDF 1.7',\n",
       "   'title': '',\n",
       "   'author': 'Shima Rahimi Moghaddam',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft Word',\n",
       "   'producer': '',\n",
       "   'creationDate': \"D:20230426034952+00'00'\",\n",
       "   'modDate': \"D:20230426034952+00'00'\",\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'page_number': 21,\n",
       "   'total_pages': 27,\n",
       "   'format': 'PDF 1.7',\n",
       "   'title': '',\n",
       "   'author': 'Shima Rahimi Moghaddam',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft Word',\n",
       "   'producer': '',\n",
       "   'creationDate': \"D:20230426034952+00'00'\",\n",
       "   'modDate': \"D:20230426034952+00'00'\",\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'page_number': 21,\n",
       "   'total_pages': 27,\n",
       "   'format': 'PDF 1.7',\n",
       "   'title': '',\n",
       "   'author': 'Shima Rahimi Moghaddam',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft Word',\n",
       "   'producer': '',\n",
       "   'creationDate': \"D:20230426034952+00'00'\",\n",
       "   'modDate': \"D:20230426034952+00'00'\",\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'page_number': 22,\n",
       "   'total_pages': 27,\n",
       "   'format': 'PDF 1.7',\n",
       "   'title': '',\n",
       "   'author': 'Shima Rahimi Moghaddam',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft Word',\n",
       "   'producer': '',\n",
       "   'creationDate': \"D:20230426034952+00'00'\",\n",
       "   'modDate': \"D:20230426034952+00'00'\",\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'page_number': 22,\n",
       "   'total_pages': 27,\n",
       "   'format': 'PDF 1.7',\n",
       "   'title': '',\n",
       "   'author': 'Shima Rahimi Moghaddam',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft Word',\n",
       "   'producer': '',\n",
       "   'creationDate': \"D:20230426034952+00'00'\",\n",
       "   'modDate': \"D:20230426034952+00'00'\",\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'page_number': 22,\n",
       "   'total_pages': 27,\n",
       "   'format': 'PDF 1.7',\n",
       "   'title': '',\n",
       "   'author': 'Shima Rahimi Moghaddam',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft Word',\n",
       "   'producer': '',\n",
       "   'creationDate': \"D:20230426034952+00'00'\",\n",
       "   'modDate': \"D:20230426034952+00'00'\",\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'page_number': 23,\n",
       "   'total_pages': 27,\n",
       "   'format': 'PDF 1.7',\n",
       "   'title': '',\n",
       "   'author': 'Shima Rahimi Moghaddam',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft Word',\n",
       "   'producer': '',\n",
       "   'creationDate': \"D:20230426034952+00'00'\",\n",
       "   'modDate': \"D:20230426034952+00'00'\",\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'page_number': 23,\n",
       "   'total_pages': 27,\n",
       "   'format': 'PDF 1.7',\n",
       "   'title': '',\n",
       "   'author': 'Shima Rahimi Moghaddam',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft Word',\n",
       "   'producer': '',\n",
       "   'creationDate': \"D:20230426034952+00'00'\",\n",
       "   'modDate': \"D:20230426034952+00'00'\",\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'page_number': 23,\n",
       "   'total_pages': 27,\n",
       "   'format': 'PDF 1.7',\n",
       "   'title': '',\n",
       "   'author': 'Shima Rahimi Moghaddam',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft Word',\n",
       "   'producer': '',\n",
       "   'creationDate': \"D:20230426034952+00'00'\",\n",
       "   'modDate': \"D:20230426034952+00'00'\",\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'page_number': 24,\n",
       "   'total_pages': 27,\n",
       "   'format': 'PDF 1.7',\n",
       "   'title': '',\n",
       "   'author': 'Shima Rahimi Moghaddam',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft Word',\n",
       "   'producer': '',\n",
       "   'creationDate': \"D:20230426034952+00'00'\",\n",
       "   'modDate': \"D:20230426034952+00'00'\",\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'page_number': 24,\n",
       "   'total_pages': 27,\n",
       "   'format': 'PDF 1.7',\n",
       "   'title': '',\n",
       "   'author': 'Shima Rahimi Moghaddam',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft Word',\n",
       "   'producer': '',\n",
       "   'creationDate': \"D:20230426034952+00'00'\",\n",
       "   'modDate': \"D:20230426034952+00'00'\",\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'page_number': 25,\n",
       "   'total_pages': 27,\n",
       "   'format': 'PDF 1.7',\n",
       "   'title': '',\n",
       "   'author': 'Shima Rahimi Moghaddam',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft Word',\n",
       "   'producer': '',\n",
       "   'creationDate': \"D:20230426034952+00'00'\",\n",
       "   'modDate': \"D:20230426034952+00'00'\",\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'page_number': 26,\n",
       "   'total_pages': 27,\n",
       "   'format': 'PDF 1.7',\n",
       "   'title': '',\n",
       "   'author': 'Shima Rahimi Moghaddam',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft Word',\n",
       "   'producer': '',\n",
       "   'creationDate': \"D:20230426034952+00'00'\",\n",
       "   'modDate': \"D:20230426034952+00'00'\",\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'page_number': 26,\n",
       "   'total_pages': 27,\n",
       "   'format': 'PDF 1.7',\n",
       "   'title': '',\n",
       "   'author': 'Shima Rahimi Moghaddam',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft Word',\n",
       "   'producer': '',\n",
       "   'creationDate': \"D:20230426034952+00'00'\",\n",
       "   'modDate': \"D:20230426034952+00'00'\",\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'page_number': 26,\n",
       "   'total_pages': 27,\n",
       "   'format': 'PDF 1.7',\n",
       "   'title': '',\n",
       "   'author': 'Shima Rahimi Moghaddam',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft Word',\n",
       "   'producer': '',\n",
       "   'creationDate': \"D:20230426034952+00'00'\",\n",
       "   'modDate': \"D:20230426034952+00'00'\",\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'page_number': 27,\n",
       "   'total_pages': 27,\n",
       "   'format': 'PDF 1.7',\n",
       "   'title': '',\n",
       "   'author': 'Shima Rahimi Moghaddam',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft Word',\n",
       "   'producer': '',\n",
       "   'creationDate': \"D:20230426034952+00'00'\",\n",
       "   'modDate': \"D:20230426034952+00'00'\",\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'page_number': 27,\n",
       "   'total_pages': 27,\n",
       "   'format': 'PDF 1.7',\n",
       "   'title': '',\n",
       "   'author': 'Shima Rahimi Moghaddam',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft Word',\n",
       "   'producer': '',\n",
       "   'creationDate': \"D:20230426034952+00'00'\",\n",
       "   'modDate': \"D:20230426034952+00'00'\",\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/TOM/2304.11490.pdf',\n",
       "   'page_number': 7,\n",
       "   'total_pages': 27,\n",
       "   'format': 'PDF 1.7',\n",
       "   'title': '',\n",
       "   'author': 'Shima Rahimi Moghaddam',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft Word',\n",
       "   'producer': '',\n",
       "   'creationDate': \"D:20230426034952+00'00'\",\n",
       "   'modDate': \"D:20230426034952+00'00'\",\n",
       "   'trapped': ''}]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Chroma.get(vectordb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': ['eb216cde-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb21745e-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb2167ac-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb2167d4-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb2162a2-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb2162ca-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb2162f2-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb21631a-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb21634c-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb216374-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb21639c-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb2163c4-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb2163ec-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb216414-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb21643c-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb21645a-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb216482-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb2164aa-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb2164c8-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb2164f0-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb216518-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb216540-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb216568-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb216590-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb2165b8-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb2165e0-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb216608-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb216626-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb21664e-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb216676-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb21669e-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb2166c6-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb2166e4-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb21670c-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb216734-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb21675c-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb216216-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb216252-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb21627a-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb2167fc-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb216824-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb21684c-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb21686a-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb216892-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb2168ba-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb2168e2-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb216900-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb216932-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb21695a-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb21698c-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb2169b4-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb2169dc-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb216a04-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb216a36-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb216a5e-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb216a7c-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb216aa4-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb216acc-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb216af4-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb216b12-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb216b3a-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb216b62-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb216b80-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb216ba8-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb216bd0-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb216c16-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb216c48-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb216c70-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb216c98-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb216cc0-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb216158-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb216784-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb216d2e-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb216d56-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb216d7e-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb216da6-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb216dce-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb216e0a-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb216e32-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb216e5a-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb216e8c-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb216eb4-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb216edc-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb216f04-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb216f36-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb216f5e-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb216f86-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb216fae-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb216fd6-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb216ffe-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb21703a-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb21708a-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb2170d0-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb217116-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb21715c-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb217198-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb2171de-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb217224-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb217260-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb21729c-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb2172e2-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb217328-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb2173be-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb2173e6-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb21792c-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb21794a-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb217972-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb217486-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb2174a4-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb2174d6-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb2174fe-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb217526-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb21754e-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb217576-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb21759e-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb2175c6-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb2175ee-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb21760c-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb217634-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb21765c-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb21767a-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb2176ac-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb2176ca-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb2176f2-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb21771a-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb217742-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb21776a-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb217788-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb2177b0-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb2177d8-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb217800-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb217828-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb217850-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb21786e-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb217896-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb2178b4-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb2178dc-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb217904-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb21740e-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb217436-ec2b-11ed-94bf-acde48001122',\n",
       "  'eb216d06-ec2b-11ed-94bf-acde48001122'],\n",
       " 'embeddings': None,\n",
       " 'documents': ['believably: “Your breakfast is burning! What would you do?”\\n• Reflections: We ask questions that require the agents to lever-\\nage their deeper understanding of others and themselves\\ngained through higher-level inferences, such as “If you were\\nto spend time with one person you met recently, who would\\nit be and why?”\\nThe full list of questions and a sample of agent responses are in-\\ncluded in Appendix B.\\nAgents were sampled from the end of a two game-day simulation\\nwith the full architecture, by which time they had accrued a number\\nof interactions and memories that should shape their responses.\\nTo gather feedback on believability of the responses, we recruited\\nparticipants as human evaluators and tasked them with watching a\\nreplay of a randomly chosen agent’s life in Smallville. Participants\\nhad access to all information stored in the agent’s memory stream.\\nThe study was a within-subjects design, where 100 participants\\ncompared interview responses generated by four different agent',\n",
       "  '[16] Rodney A. Brooks, Cynthia Breazeal, Marko Marjanovic, Brian Scassellati, and\\nMatthew Williamson. 2000. The Cog Project: Building a Humanoid Robot. In\\nComputation for Metaphors, Analogy, and Agents (Lecture Notes on Artificial\\nIntelligence, 1562), Chrystopher Nehaniv (Ed.). Springer-Verlag, Berlin, 52–87.\\n[17] Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan,\\nPrafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda\\nAskell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan,\\nRewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter,\\nChristopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin\\nChess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya\\nSutskever, and Dario Amodei. 2020. Language Models are Few-Shot Learners.\\narXiv:2005.14165 [cs.CL]\\n[18] Sébastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric',\n",
       "  'tions with Latoya indicate a memory of that interaction, as he asks\\n“Hi, Latoya. How is your project going?” and she replies “Hi, Sam. It’s\\ngoing well!”\\n3.4.3\\nCoordination. Generative agents coordinate with each other.\\nIsabella Rodriguez, at Hobbs Cafe, is initialized with an intent to\\nplan a Valentine’s Day party from 5 to 7 p.m. on February 14th. From\\nthis seed, the agent proceeds to invites friends and customers when\\nshe sees them at Hobbs Cafe or elsewhere. Isabella then spends the\\nafternoon of the 13th decorating the cafe for the occasion. Maria, a\\nfrequent customer and close friend of Isabella’s, arrives at the cafe.\\nIsabella asks for Maria’s help in decorating for the party, and Maria\\nagrees. Maria’s character description mentions that she has a crush\\non Klaus. That night, Maria invites Klaus, her secret crush, to join\\nher at the party, and he gladly accepts.\\nOn Valentine’s Day, five agents—including Klaus and Maria—',\n",
       "  'show up at Hobbs Cafe at 5pm and they enjoy the festivities (Fig-\\nure 4). In this scenario, the end user only set Isabella’s initial intent',\n",
       "  'Joon Sung Park, Joseph C. O’Brien, Carrie J. Cai, Meredith Ringel Morris,\\nPercy Liang, and Michael S. Bernstein. 2023. Generative Agents: Interactive\\nSimulacra of Human Behavior. In . ACM, New York, NY, USA, 22 pages.\\nhttps://doi.org/xx.xx/xx.xx\\n1\\nINTRODUCTION\\nHow might we craft an interactive artificial society that reflects\\nbelievable human behavior? From sandbox games such as The Sims\\nto applications such as cognitive models [21] and virtual environ-\\nments [9, 58], for over four decades researchers and practitioners\\nhave envisioned computational agents that can serve as believ-\\nable proxies of human behavior. In these visions, computationally-\\npowered agents act consistently with their past experiences and\\nreact believably to their environments. Such simulations of human\\nbehavior could populate virtual spaces and communities with real-\\nistic social phenomena [26, 79], train people how to handle rare yet\\ndifficult interpersonal situations [43, 51, 93], test social science theo-',\n",
       "  'ries [11, 45], craft model human processors for theory and usability\\ntesting [21, 38, 50], power ubiquitous computing applications [30]\\nand social robots [9, 13], and underpin non-playable game charac-\\nters [58, 84] that can navigate complex human relationships in an\\nopen world.\\nHowever, the space of human behavior is vast and complex [84,\\n108]. Despite striking progress in large language models [17] that\\ncan simulate believable human behavior at a single time point [38,\\n79], fully general agents that ensure long-term coherence would\\nbe better suited by architectures that manage constantly-growing\\nmemories as new interactions, conflicts, and events arise and fade\\nover time, while handling cascading social dynamics that unfold\\nbetween multiple agents. Success requires an approach that can\\nretrieve relevant events and interactions over a long period, reflect\\non those memories to generalize and draw higher-level inferences,\\nand apply that reasoning to create plans and reactions that both',\n",
       "  'make sense in the moment and in the longer-term arc of the agent’s\\nbehavior.\\nIn this paper, we introduce generative agents—agents that draw\\non generative models to simulate believable human behavior—and\\ndemonstrate that they produce believable simulacra of both in-\\ndividual and emergent group behavior. Generative agents draw\\na wide variety of inferences about themselves, other agents, and\\ntheir environment; they create daily plans that reflect their char-\\nacteristics and experiences, act out those plans, react, and re-plan\\nwhen appropriate; they respond when the end user changes their\\nenvironment or commands them in natural language. For instance,\\ngenerative agents turn off the stove when they see that their break-\\nfast is burning, wait outside the bathroom if it is occupied, and\\nstop to chat when they meet another agent they want to talk to.\\nA society full of generative agents is marked by emergent social\\ndynamics where new relationships are formed, information diffuses,',\n",
       "  'and coordination arises across agents.\\nTo enable generative agents, we describe an agent architecture\\nthat stores, synthesizes, and applies relevant memories to generate\\nbelievable behavior using a large language model. Our architecture\\ncomprises three main components. The first is the memory stream,\\na long-term memory module that records, in natural language, a\\ncomprehensive list of the agent’s experiences. The retrieval model\\ncombines relevance, recency, and importance to surface the records\\nthat are needed to inform the agent’s moment-to-moment behavior.\\nThe second is reflection, which synthesizes memories into higher-\\nlevel inferences over time, enabling the agent to draw conclusions\\nabout itself and others to better guide its behavior. The third is\\nplanning, which translates those conclusions and the current en-\\nvironment into high-level action plans and then recursively into\\ndetailed behaviors for action and reaction. These reflections and',\n",
       "  'plans are fed back into the memory stream to influence the agent’s\\nfuture behavior.\\nThis architecture suggests applications in multiple domains, from\\nrole-play and social prototyping, to virtual worlds and games. In\\nsocial role-play scenarios (e.g. interview preparation), a user could\\nsafely rehearse difficult, conflict-laden conversations. When pro-\\ntotyping social platforms, a designer could go beyond temporary\\npersonas to prototype dynamic, complex interactions that unfold\\nover time. For the purposes of this paper, we focus on the ability to\\ncreate a small, interactive society of agents inspired by games such\\nas The Sims.1 By connecting our architecture to the ChatGPT large\\nlanguage model [76], we manifest a small society of twenty five\\nagents in a game environment. End users can observe and interact\\nwith these agents. If an end user or developer wanted the town\\nto host an in-game Valentine’s Day party, for example, traditional',\n",
       "  'game environments would require scripting tens of characters’ be-\\nhavior manually. We demonstrate that, with generative agents, it\\nis sufficient to simply tell one agent that she wants to throw a\\nparty. Despite many potential points of failure—the party planner\\nmust remember to tell other agents about the party, attendees must\\nremember the invitation, those who remember must decide to ac-\\ntually show up, and other possible points of failure—agents in our\\nenvironment succeed. They spread the word about the party and\\nthen show up, with one agent even asking another agent on a date\\nto the party, all from this single user-generated seed suggestion.\\nWe conducted two evaluations of generative agents: a controlled\\nevaluation to test whether the agents produce believable individual\\n1A demonstration of an actual simulation of the generative agent society can be viewed\\nat the following link: https://reverie.herokuapp.com/arXiv_Demo/',\n",
       "  'Generative Agents\\narXiv, April, 2023,\\nbehaviors in isolation, and an end-to-end evaluation where the\\ngenerative agents interacted with each other in open-ended ways\\nover two days of game time to understand their stability and emer-\\ngent social behaviors. In the technical evaluation, we leverage a\\nmethodological opportunity to evaluate an agent’s knowledge and\\nbehavior by “interviewing” it in natural language to probe agents’\\nability to stay in character, remember, plan, react, and reflect accu-\\nrately. We compared several ablations that limit agents’ access to\\nmemory, reflection, and planning. We observe that each of these\\ncomponents is critical to strong performance across these inter-\\nview tasks. Across the technical and the end-to-end evaluation, the\\nmost common errors arose when the agent failed to retrieve rele-\\nvant memories, fabricated embellishments to the agent’s memory,\\nor inherited overly formal speech or behavior from the language\\nmodel.',\n",
       "  'In sum, this paper provides the following contributions:\\n• Generative agents, believable simulacra of human behavior\\nthat are dynamically conditioned on agents’ changing expe-\\nriences and environment.\\n• A novel architecture that makes it possible for generative\\nagents to remember, retrieve, reflect, interact with other\\nagents, and plan through dynamically evolving circumstances.\\nThe architecture leverages the powerful prompting capabili-\\nties of large language models and supplements those capa-\\nbilities to support longer-term agent coherence, the ability\\nto manage dynamically-evolving memory, and recursively\\nproduce more generations.\\n• Two evaluations (a controlled evaluation and end-to-end\\nevaluation) that establish causal effects of the importance\\nof components of the architecture, as well as identify break-\\ndowns arising from, e.g., improper memory retrieval.\\n• Discussion of the opportunities and ethical and societal risks\\nof generative agents in interactive systems. We argue that',\n",
       "  'these agents should be tuned to mitigate the risk of users\\nforming parasocial relationships, logged to mitigate risks\\nstemming from deepfakes and tailored persuasion, and ap-\\nplied in ways that complement rather than replace human\\nstakeholders in design processes.\\n2\\nRELATED WORK\\nIn this section, we reflect on the prior literature in human-AI in-\\nteraction and situate within its canon the agenda of building be-\\nlievable proxies of human behavior. This agenda, once hailed as a\\nnorth star in interaction, game, and artificial intelligence communi-\\nties [9, 58, 84, 85], has remained challenging due to the complexity\\nof human behavior [16, 108]. We synthesize this research to suggest\\nthat large language models, though not sufficient by themselves,\\nopen up a new angle for creating believable agents when leveraged\\nusing the appropriate architecture.\\n2.1\\nHuman-AI Interaction\\nInteractive artificial intelligence systems aim to combine human in-',\n",
       "  'sights and capabilities in computational artifacts that can augment\\ntheir users [3, 29]. A long line of work has explored ways to allow\\nusers to interactively specify model behavior. For instance, Crayons\\ndemonstrated an early vision of interactive machine learning, allow-\\ning non-expert users to train classifiers [29]. Further work helped to\\narticulate how end users might describe their classification goals to\\nthe system through examples [33] and/or demonstration [31]. More\\nrecent work has extended these explorations to deep learning [62]\\nand prompt-based authoring [49, 66, 106].\\nMeanwhile, a persistent thread of research has advanced the case\\nfor language- and agent-based interaction in human-computer in-\\nteraction. Formative work such as SHRDLU [103] and ELIZA [102]\\ndemonstrated the opportunity and the risks of natural language\\ninteraction with computing systems. As research progressed, it\\nbecame clear that autonomous agents could offer new metaphors',\n",
       "  'for delegation and interaction [67], but the delegation lines be-\\ntween humans and agents have continued to be debated and refined\\n[46, 88, 89]. Recently, this technology has become stable enough\\nthat it has become possible for agents to interact via natural lan-\\nguage in large and complex online social environments (e.g., [54]).\\nNatural language interaction offers a novel modality that can ex-\\ntend user abilities in domains such as photo editing [2, 34, 64] and\\ncode editing [87].\\nWe convene these threads of work to show that we can now\\ncreate agents that proxy human behavior for interactive systems,\\nand interact with them via natural language. In doing so, this\\nwork re-opens the door to examining foundational HCI questions\\naround cognitive models such as GOMS and KLM [21, 22], around\\nprototyping tools [79], and around ubiquitous computing applica-\\ntions [25, 30, 100].\\n2.2\\nBelievable Proxies of Human Behavior\\nPrior literature has described believability, or believable agents, as a',\n",
       "  'central design and engineering goal. Believable agents are designed\\nto provide an illusion of life and present a facade of realism in the\\nway they appear to make decisions and act on their own volition,\\nsimilar to the characters in Disney movies [9, 95]. These agents can\\npopulate and perceive an open-world environment like the one we\\ninhabit [9, 58], and strive to behave in ways that exhibit emergent\\nbehaviors grounded in social interactions with users or other agents\\nwith the aim of becoming believable proxies of our behavior in hy-\\npothetical simulations of individuals and communities [19, 35, 70].\\nHistorically, these agents were developed in the context of intelli-\\ngent game NPCs [58, 84]. Creating NPCs with believable behavior,\\nif possible, could enhance player experiences in games and inter-\\nactive fictions by enabling emergent narratives [7, 15, 48, 92] and\\nsocial interactions with the agents [110]. However, more impor-',\n",
       "  'tantly, game worlds provide increasingly realistic representations\\nof real-world affordances, and as observed by Laird and van Lent in\\n2001, these simulated worlds offer accessible testbeds for develop-\\ners of believable agents to finesse the agents’ cognitive capabilities\\nwithout worrying about implementing robotics in the real world\\nor creating simulation environments from scratch [58, 84].\\nA diverse set of approaches to creating believable agents emerged\\nover the past four decades. In implementation, however, these ap-\\nproaches often simplified the environment or dimensions of agent\\nbehavior to make the effort more manageable [16, 72]. Rule-based\\napproaches, such as finite-state machines [90, 96] and behavior',\n",
       "  'arXiv, April, 2023,\\nJ.S. Park, J.C. O’Brien, C.J. Cai, M. Morris, P. Liang, M.S. Bernstein\\ntrees [40, 53, 81], account for the brute force approach of human-\\nauthoring the agent’s behavior [70]. They provide a straightforward\\nway of creating simple agents that is still the most dominant ap-\\nproach today [68, 73, 109], and can even handle rudimentary social\\ninteractions, as shown in simulation games such as Mass Effect [12]\\nand The Sims [6] series. Nonetheless, manually crafting behavior\\nthat can comprehensively address the breadth of possible interac-\\ntions in an open world is untenable. This means that the resulting\\nagent behaviors may not fully represent the consequences of their\\ninteractions [69–71], and cannot perform new procedures that were\\nnot hard-coded in their script [90, 96]. On the other hand, preva-\\nlent learning-based approaches for creating believable agents, such\\nas reinforcement learning, have overcome the challenge of man-',\n",
       "  'ual authoring by letting the agents learn their behavior, and have\\nachieved superhuman performance in recent years in games such\\nas AlphaStar for Starcraft [98] and OpenAI Five for Dota 2 [10].\\nHowever, their success has largely taken place in adversarial games\\nwith readily definable rewards that a learning algorithm can op-\\ntimize for. They have not yet addressed the challenge of creating\\nbelievable agents in an open world [39, 73, 90].\\nCognitive architectures in computation, pioneered by Newell,\\naimed to build the infrastructure for supporting a comprehensive\\nset of cognitive functions [75] that suited the all-encompassing\\nnature of believable agents held in its original vision. They fueled\\nsome of the earliest examples of believable agents. For instance,\\nQuakebot-SOAR [59] and ICARUS [24, 63] generated NPCs in first-\\nperson shooter games, while TacAir-SOAR [80] generated pilots in\\naerial combat training simulations. The architectures used by these',\n",
       "  'agents differed (Quakebot- and TacAir-SOAR relied on SOAR [60],\\nwhile ICARUS relied on its own variation that was inspired by\\nSOAR and ACT-R [5]), but they shared the same underlying prin-\\nciple [61]. They maintained short-term and long-term memories,\\nfilled these memories with symbolic structures, and operated in\\nperceive-plan-act cycles, dynamically perceiving the environment\\nand matching it with one of the manually crafted action proce-\\ndures [57, 96]. Agents created using cognitive architectures aimed\\nto be generalizable to most, if not all, open-world contexts and\\nexhibited robust behavior for their time. However, their space of\\naction was limited to manually crafted procedural knowledge, and\\nthey did not offer a mechanism through which the agents could be\\ninspired to seek new behavior. As such, these agents were deployed\\nmostly in non-open-world contexts such as first-person shooter\\ngames [24, 59] or blocks worlds [63].',\n",
       "  'Today, creating believable agents as described in its original\\ndefinition remains an open problem [84, 108]. Many have moved on,\\narguing that although existing approaches for creating believable\\nagents might be cumbersome and limited, they are good enough\\nto support existing gameplay and interactions [23, 74, 108]. Our\\nargument is that large language models offer an opportunity to\\nre-examine these questions, provided that we can craft an effective\\narchitecture to synthesize memories into believable behavior. We\\noffer a step toward such an architecture in this paper.\\n2.3\\nLarge Language Models and Human\\nBehavior\\nGenerative agents leverage a large language model to power their\\nbehavior. The key observation is that large language models en-\\ncode a wide range of human behavior represented in their training\\ndata [14, 17]. If prompted with a narrowly defined context, the\\nmodels can be used to generate believable behavior. Recent work',\n",
       "  'has demonstrated the efficacy of this approach. For instance, Social\\nSimulacra used a large language model to generate users that would\\npopulate new social computing systems to prototype their emergent\\nsocial dynamics [79]. This approach used a prompt chain [105, 106]\\nto generate short natural language descriptions of personas and\\ntheir behaviors as they appear in the system being prototyped.\\nOther empirical studies have replicated existing social science stud-\\nies [45], political surveys [91], and generated synthetic data [38].\\nLarge language models have also been used to generate interactive\\nhuman behavior for users to engage with. In gaming, for instance,\\nthese models have been employed to create interactive fiction [36]\\nand text adventure games [20]. With their ability to generate and\\ndecompose action sequences, large language models have also been\\nused in planning robotics tasks [47]. For example, when presented\\nwith a task, such as picking up a bottle, the model is prompted to',\n",
       "  'break down the task into smaller action sequences, such as heading\\nto the table where the bottle is located and picking it up.\\nWe posit that, based on the work summarized above, large lan-\\nguage models can become a key ingredient for creating believable\\nagents. The existing literature largely relies on what could be con-\\nsidered first-order templates that employ few-shot prompts [37, 65]\\nor chain-of-thought prompts [99]. These templates are effective in\\ngenerating behavior that is conditioned solely on the agent’s cur-\\nrent environment (e.g., how would a troll respond to a given post,\\nwhat actions would a robot need to take to enter a room given that\\nthere is a door). However, believable agents require conditioning\\nnot only on their current environment but also on a vast amount\\nof past experience, which is a poor fit (and as of today, impossi-\\nble due to the underlying models’ limited context window) using\\nfirst-order prompting. Recent studies have attempted to go beyond',\n",
       "  'first-order prompting by augmenting language models with a static\\nknowledge base and an information retrieval scheme [52] or with\\na simple summarization scheme [104]. This paper extends these\\nideas to craft an agent architecture that handles retrieval where\\npast experience is dynamically updated at each time step and mixed\\nwith agents’ current context and plans, which may either reinforce\\nor contradict each other.\\n3\\nGENERATIVE AGENT BEHAVIOR AND\\nINTERACTION\\nTo make concrete the affordances of generative agents, we instanti-\\nate them as characters in a simple sandbox world reminiscent of\\nThe Sims [6]. This sprite-based sandbox game world, Smallville,\\nevokes a small town environment. In this section, we walk through\\nthe affordances and interactions with generative agents in Small-\\nville, and describe how the agents behave in it. Then, in Section 4,\\nwe introduce our generative agent architecture that powers these\\naffordances and interactions. In Section 5, we describe the sandbox',\n",
       "  'Generative Agents\\narXiv, April, 2023,\\nFigure 2: The Smallville sandbox world, with areas labeled. The root node describes the entire world, children describe areas\\n(e.g., houses, cafe, stores), and leaf nodes describe objects (e.g., table, bookshelf). Agent remember a subgraph reflecting the\\nparts of the world they have seen, in the state that they saw them.\\nenvironment implementation and how the agents interact with the\\nsandbox world’s underlying engine.\\n3.1\\nAgent Avatar and Communication\\nA community of 25 unique agents inhabit Smallville. Each agent is\\nrepresented by a simple sprite avatar. We authored one paragraph\\nof natural language description to depict each agent’s identity,\\nincluding their occupation and relationship with other agents, as\\nseed memories. For example, John Lin has the following description:\\nJohn Lin is a pharmacy shopkeeper at the Willow\\nMarket and Pharmacy who loves to help people. He\\nis always looking for ways to make the process',\n",
       "  'of getting medication easier for his customers;\\nJohn Lin is living with his wife, Mei Lin, who\\nis a college professor, and son, Eddy Lin, who is\\na student studying music theory; John Lin loves\\nhis family very much; John Lin has known the old\\ncouple next-door, Sam Moore and Jennifer Moore,\\nfor a few years; John Lin thinks Sam Moore is a\\nkind and nice man; John Lin knows his neighbor,\\nYuriko Yamamoto, well; John Lin knows of his\\nneighbors, Tamara Taylor and Carmen Ortiz, but\\nhas not met them before; John Lin and Tom Moreno\\nare colleagues at The Willows Market and Pharmacy;\\nJohn Lin and Tom Moreno are friends and like to\\ndiscuss local politics together; John Lin knows\\nthe Moreno family somewhat well — the husband Tom\\nMoreno and the wife Jane Moreno.\\nEach semicolon-delimited phrase is entered into the agent’s initial\\nmemory as memories at the start of the simulation.\\n3.1.1\\nInter-Agent Communication. The agents interact with the',\n",
       "  'world by their actions, and with each other through natural lan-\\nguage. At each time step of the sandbox engine, the agents output a\\nnatural language statement describing their current action, such as\\n\"Isabella Rodriguez is writing in her journal\", \"Isabella Rodriguez is\\nchecking her emails\", \"Isabella Rodriguez is talking with her family\\non the phone\", or \"Isabella Rodriguez is getting ready for bed\". This\\nstatement is then translated into concrete movements that affect the\\nsandbox world. The action is displayed on the sandbox interface as\\na set of emojis that provide an abstract representation of the action\\nin the overhead view. To accomplish this, the system employs a\\nlanguage model that translates the action into a set of emojis, which\\nappear above each avatar in a speech bubble. For example, \"Isabella\\nRodriguez is writing in her journal\" is displayed as\\n, while\\n\"Isabella Rodriguez is checking her emails\" appears as\\n. The',\n",
       "  'full natural language description of the action can be accessed by\\nclicking on the agent avatar.\\nAgents communicate with each other in full natural language.\\nAgents are aware of other agents in their local area, and the genera-\\ntive agent architecture determines whether they walk by or engage\\nin conversation. Here, a sample in the middle of a conversation\\nbetween the agents Isabella Rodriguez and Tom Moreno about the\\nupcoming election:2\\nIsabella: I’m still weighing my options, but I’ve been\\ndiscussing the election with Sam Moore. What are your\\nthoughts on him?\\nTom: To be honest, I don’t like Sam Moore. I think he’s\\nout of touch with the community and doesn’t have our\\nbest interests at heart.\\n2We note that the conversational style of these agents can fe el overly formal, likely a\\nresult of instruction tuning in the underlying models. We expect that writing style\\nwill be better controllable in future language models.',\n",
       "  'arXiv, April, 2023,\\nJ.S. Park, J.C. O’Brien, C.J. Cai, M. Morris, P. Liang, M.S. Bernstein\\n3.1.2\\nUser Controls. A user running this simulation can steer the\\nsimulation and intervene, either by communicating with the agent\\nthrough conversation, or by issuing a directive to an agent in the\\nform of an ‘inner voice’.\\nThe user communicates with the agent through natural language,\\nby specifying a persona that the agent should perceive them as. For\\nexample, if the user specifies that they are a news “reporter” and\\nasks about the upcoming election, “Who is running for office?”, the\\nJohn agent replies:\\nJohn: My friends Yuriko, Tom and I have been talking\\nabout the upcoming election and discussing the candi-\\ndate Sam Moore. We have all agreed to vote for him\\nbecause we like his platform.\\nTo directly command one of the agents, the user takes on the per-\\nsona of the agent’s “inner voice”—this makes the agent more likely\\nto treat the statement as a directive. For instance, when told “You',\n",
       "  'are going to run against Sam in the upcoming election” by a user\\nas John’s inner voice, John decides to run in the election and shares\\nhis candidacy with his wife and son.\\n3.2\\nEnvironmental Interaction\\nSmallville features the common affordances of a small village in-\\ncluding a cafe, bar, park, school, dorm, houses, and stores. It also\\ndefines subareas and objects that make those spaces functional,\\nsuch as a kitchen in a house and a stove in the kitchen (Figure 2).\\nAll spaces serving as agents’ primary living quarters feature a bed,\\ndesk, closet, shelf, as well as a bathroom and a kitchen.3\\nAgents move around Smallville as one would in a simple video\\ngame, entering and leaving buildings, navigating its map, and ap-\\nproaching other agents. Agent movements are directed by the gen-\\nerative agent architecture and the sandbox game engine: when the\\nmodel dictates that the agent will move to a location, we calculate\\na walking path to the destination in the Smallville environment',\n",
       "  'and the agent begins moving. In addition, users can also enter the\\nsandbox world of Smallville as an agent operating within it. The\\nagent that the user embodies can be an agent already present in\\nthe world, such as Isabella and John, or it can be an outside visitor\\nwith no prior history in Smallville. The inhabitants of Smallville\\nwill treat the user-controlled agent no differently than they treat\\neach other. They recognize its presence, initiate interactions, and\\nremember its behavior before forming opinions about it.\\nUsers and agents can influence the state of the objects in this\\nworld, much like in sandbox games such as The Sims. For example,\\na bed can be occupied when an agent is sleeping, and a refrigerator\\ncan be empty when an agent uses up the ingredients to make\\nbreakfast. End users can also reshape an agent’s environment in\\nSmallville by rewriting the status of objects surrounding the agent\\nin natural language. For instance, when Isabella is making breakfast',\n",
       "  'in the morning, the user can change the status of the kitchen stove\\nfrom “turned on” to “burning” by inputting a command to the\\nsystem that chooses the object and illustrates its new status, like\\nthis: “<Isabella’s apartment: kitchen: stove> is burning.” Isabella\\nwill notice this in the next moment and go to turn off the stove\\n3This environment design is not the focus of our work, so we generate this environment\\nmanually, not automatically. Future work can continue to expand the richness of the\\nagents’ environments.\\nand remake her breakfast. Likewise, if the user sets the status of\\nIsabella’s shower to “leaking water” when she enters the bathroom,\\nshe gathers tools from her living room and try to fix the leak.\\n3.3\\nExample “Day in the Life”\\nStarting from the single-paragraph description, agents begin plan\\ntheir days. As time passes in the sandbox world, their behaviors\\nevolve as these agents interact with each other and the world, build',\n",
       "  'memories and relationships, and coordinate joint activities.\\nWe demonstrate the behavior of generative agents by tracing the\\noutput of our system over the course of one day for the agent John\\nLin (Figure 3). In the Lin family, John is the first to wake up at 7 a.m.\\nHe brushes his teeth, takes a shower, gets dressed, eats breakfast,\\nand checks the news at the dining table in the living room. At 8\\na.m., Eddy follows suit, rushing out of bed to prepare for his classes.\\nHe catches up with John just as he is about to head out:\\nJohn: Good morning Eddy. Did you sleep well?\\nEddy: Good morning dad. Yeah, I slept great.\\nJohn: That’s good. What are you working on today?\\nEddy: I’m working on a new music composition for my\\nclass. It’s due this week, so I’m trying to get it finished.\\nBut I’m having so much fun with it!\\nJohn: That sounds great!\\nSoon after Eddy heads out, Mei wakes up and joins John. Mei asks\\nabout her son, and John recalls the conversation that they just had:',\n",
       "  'Mei: Did Eddy already leave for school?\\nJohn: Yes, he just left. He’s working on a music com-\\nposition for his class.\\nMei: Oh, that’s wonderful! Tell me about it.\\nJohn: I think he’s really enjoying it! He said he’s having\\na lot of fun with it.\\nMei: That’s great! I’m so proud of him.\\nAs they finish their conversation, Mei and John pack up. Mei goes\\non to teach and work on her research paper, while John opens his\\npharmacy counter at the Willow Market and Pharmacy by 9 a.m.\\n3.4\\nEmergent Social Behaviors\\nBy interacting with each other, generative agents in Smallville\\nexchange information, form new relationships, and coordinate joint\\nactivities. Extending prior work [79], these social behaviors are\\nemergent rather than pre-programmed.\\n3.4.1\\nInformation Diffusion. As agents notice each other, they may\\nengage in dialogue—as they do so, information can spread from\\nagent to agent. For instance, in a conversation between Sam and\\nTom at the grocery store, Sam tells Tom about his candidacy in the',\n",
       "  'local election:\\nSam: Hey Tom, how’s it going?\\nTom: Good, thanks. What’s up?\\nSam: Well, I wanted to talk to you about something. I’m\\nactually running for mayor in the upcoming local elec-\\ntion.\\nTom: Really? That’s great news! Why are you running?\\nSam: I’ve been involved in local politics for years now,',\n",
       "  'Generative Agents\\narXiv, April, 2023,\\nFigure 3: A morning in the life of a generative agent, John Lin. John wakes up around 6 am and completes his morning routine,\\nwhich includes brushing his teeth, taking a shower, and eating breakfast. He briefly catches up with his wife, Mei, and son,\\nEddy, before heading out to begin his workday.\\nFigure 4: At the beginning of the simulation, one agent is ini-\\ntialized with an intent to organize a Valentine’s Day party.\\nDespite many possible points of failure in the ensuring\\nchain of events—agents might not act on that intent, might\\nnot remember to tell others, might not remember to show\\nup—the Valentine’s Day party does in fact occur, with a num-\\nber of agents gathering and interacting.\\nand I really feel like I can make a difference in our com-\\nmunity. Plus, I want to bring new ideas and perspec-\\ntives to the table.\\nLater that day, after Sam left, Tom and John, who heard the news\\nfrom another source, discuss Sam’s chances of winning the election:',\n",
       "  'spaces for interpersonal communication to prototyping tools. In\\nthis paper, we introduce generative agents—computational software\\nPermission to make digital or hard copies of all or part of this work for personal or\\nclassroom use is granted without fee provided that copies are not made or distributed\\nfor profit or commercial advantage and that copies bear this notice and the full citation\\non the first page. Copyrights for components of this work owned by others than the\\nauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or\\nrepublish, to post on servers or to redistribute to lists, requires prior specific permission\\nand/or a fee. Request permissions from permissions@acm.org.\\narXiv, April, 2023,\\n© 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.\\nACM ISBN xx-x-xxxx-xxxx-x/xx/xx...$15.00\\nhttps://doi.org/xx.xx/xx.xx\\nagents that simulate believable human behavior. Generative agents',\n",
       "  'wake up, cook breakfast, and head to work; artists paint, while\\nauthors write; they form opinions, notice each other, and initiate\\nconversations; they remember and reflect on days past as they plan\\nthe next day. To enable generative agents, we describe an architec-\\nture that extends a large language model to store a complete record\\nof the agent’s experiences using natural language, synthesize those\\nmemories over time into higher-level reflections, and retrieve them\\ndynamically to plan behavior. We instantiate generative agents\\nto populate an interactive sandbox environment inspired by The\\nSims, where end users can interact with a small town of twenty five\\nagents using natural language. In an evaluation, these generative\\nagents produce believable individual and emergent social behav-\\niors: for example, starting with only a single user-specified notion\\narXiv:2304.03442v1  [cs.HC]  7 Apr 2023',\n",
       "  'arXiv, April, 2023,\\nJ.S. Park, J.C. O’Brien, C.J. Cai, M. Morris, P. Liang, M.S. Bernstein\\nthat one agent wants to throw a Valentine’s Day party, the agents\\nautonomously spread invitations to the party over the next two\\ndays, make new acquaintances, ask each other out on dates to the\\nparty, and coordinate to show up for the party together at the right\\ntime. We demonstrate through ablation that the components of\\nour agent architecture—observation, planning, and reflection—each\\ncontribute critically to the believability of agent behavior. By fusing\\nlarge language models with computational, interactive agents, this\\nwork introduces architectural and interaction patterns for enabling\\nbelievable simulations of human behavior.\\nCCS CONCEPTS\\n• Human-centered computing → Interactive systems and tools;\\n• Computing methodologies → Natural language processing.\\nKEYWORDS\\nHuman-AI Interaction, agents, generative AI, large language models\\nACM Reference Format:',\n",
       "  'arXiv, April, 2023,\\nJ.S. Park, J.C. O’Brien, C.J. Cai, M. Morris, P. Liang, M.S. Bernstein\\nFigure 5: Our generative agent architecture. Agents perceive their environment, and all perceptions are saved in a compre-\\nhensive record of the agent’s experiences called the memory stream. Based on their perceptions, the architecture retrieves\\nrelevant memories, then uses those retrieved actions to determine an action. These retrieved memories are also used to form\\nlonger-term plans, and to create higher-level reflections, which are both entered into the memory stream for future use.\\nto throw a party and Maria’s crush on Klaus: the social behaviors\\nof spreading the word, decorating, asking each other out, arriving\\nat the party, and interacting with each other at the party, were\\ninitiated by the agent architecture.\\n4\\nGENERATIVE AGENT ARCHITECTURE\\nGenerative agents aim to provide a framework for behavior in an\\nopen world: one that can engage in interactions with other agents',\n",
       "  'and can react to changes in the environment. Generative agents\\ntake their current environment and past experience as input and\\ngenerate behavior as output. Underlying this behavior is a novel\\nagent architecture that combines a large language model with mech-\\nanisms for synthesizing and retrieving relevant information to con-\\ndition the language model’s output on. Without these mechanisms,\\nlarge language models can output behavior, but the resulting agents\\nmay not react based on the agent’s past experiences, may not make\\nimportant inferences, and may not maintain long-term coherence.\\nChallenges with long-term planning and coherence remain [18]\\neven with today’s most performant models such as GPT-4. Because\\ngenerative agents produce large streams of events and memories\\nthat must be retained, a core challenge of our architecture is to\\nensure that the most relevant pieces of the agent’s memory are\\nretrieved and synthesized when needed.',\n",
       "  'At the center of our architecture is the memory stream, a data-\\nbase that maintains a comprehensive record of an agent’s experi-\\nence. From the memory stream, records are retrieved as relevant\\nto plan the agent’s actions and react appropriately to the environ-\\nment, and records are recursively synthesized into higher- and\\nhigher-level observations that guide behavior. Everything in the\\narchitecture is recorded and reasoned over as natural language\\ndescription, allowing the architecture to leverage a large language\\nmodel.\\nOur current implementation utilizes gpt3.5-turbo version of Chat-\\nGPT [76]. We expect that the architectural basics of generative\\nagents—memory, planning, and reflection—will likely remain the\\nsame as language models improve. Newer language models (e.g.,\\nGPT-4) will continue to expand the expressivity and performance\\nof the prompts that underpin generative agents. As of writing, how-\\never, GPT-4’s API is still invitation-only, so our agents use ChatGPT.\\n4.1',\n",
       "  'Memory and Retrieval\\nChallenge: Creating generative agents that can simulate human\\nbehavior requires reasoning about a set of experiences that is far\\nlarger than what should be described in a prompt, as the full mem-\\nory stream can distract the model and does not even currently fit\\ninto the limited context window. Consider a the Isabella agent an-\\nswering the question “What are you passionate about these days?”.\\nFirst summarizing all of Isabella’s experiences to fit in the limited\\ncontext window of the language model produces an uninformative\\nresponse, where Isabella discusses topics such as collaborations for\\nevents and projects and cleanliness and organization in a cafe. In-\\nstead of summarizing, the memory stream described below surfaces\\nrelevant memories, resulting in a more informative and specific\\nresponse that mentions Isabella’s passion for making people feel\\nwelcome and included, planning events and creating an atmosphere',\n",
       "  'that people can enjoy, such as the Valentine’s Day party.\\nApproach: The memory stream maintains a comprehensive record\\nof the agent’s experience. It is a list of memory objects, where each\\nobject contains a natural language description, a creation times-\\ntamp and a most recent access timestamp. The most basic element\\nof the memory stream is an observation, which is an event directly\\nperceived by an agent. Common observations include behaviors\\nperformed by the agent themselves, or behaviors that agents per-\\nceive being performed by other agents or non-agent objects. For\\ninstance, Isabella Rodriguez, who works at a coffee shop, might ac-\\ncrue the following observations over time: (1) Isabella Rodriguez is\\nsetting out the pastries, (2) Maria Lopez is studying for a Chemistry\\ntest while drinking coffee, (3) Isabella Rodriguez and Maria Lopez\\nare conversing about planning a Valentine’s day party at Hobbs Cafe,\\n(4) The refrigerator is empty.',\n",
       "  'Generative Agents\\narXiv, April, 2023,\\nFigure 6: The memory stream comprises a large number of observations that are relevant and irrelevant to the agent’s current\\nsituation. Retrieval identifies a subset of these observations that should be passed to the language model to condition its\\nresponse to the situation.\\nOur architecture implements a retrieval function that takes the\\nagent’s current situation as input and returns a subset of the mem-\\nory stream to pass on to the language model. There are many pos-\\nsible implementations of a retrieval function, depending on what\\nit is important that the agent consider when deciding how to act.\\nIn our context, we focus on three main components that together\\nproduce effective results.\\nRecency assigns a higher score to memory objects that were re-\\ncently accessed, so that events from a moment ago or this morning\\nare likely to remain in the agent’s attentional sphere. In our im-\\nplementation, we treat recency as an exponential decay function',\n",
       "  'over the number of sandbox game hours since the memory was\\nlast retrieved. Our decay factor is 0.99.\\nImportance distinguishes mundane from core memories, by as-\\nsigning a higher score to those memory objects that the agent\\nbelieves to be important. For instance, a mundane event such as\\neating breakfast in one’s room would yield a low importance score,\\nwhereas a breakup with one’s significant other would yield a high\\nscore. There are again many possible implementations of an im-\\nportance score; we find that directly asking the language model to\\noutput an integer score is effective. The full prompt appears below:\\nOn the scale of 1 to 10, where 1 is purely mundane\\n(e.g., brushing teeth, making bed) and 10 is\\nextremely poignant (e.g., a break up, college\\nacceptance), rate the likely poignancy of the\\nfollowing piece of memory.\\nMemory: buying groceries at The Willows Market\\nand Pharmacy\\nRating: <fill in>\\nThis prompt returns an integer value of 2 for “cleaning up the room”',\n",
       "  'and 8 for “asking your crush out on a date.” The importance score\\nis generated at the time the memory object is created.\\nRelevance assigns a higher score to memory objects that are\\nrelated to the current situation. What is relevant depends on the\\nanswer to, “Relevant to what?”, so we condition relevance on a\\nquery memory. If the query, for example, is that a student is dis-\\ncussing what to study for a chemistry test with a classmate, memory\\nobjects about their breakfast should have low relevance, whereas\\nmemory objects about the teacher and schoolwork should have\\nhigh relevance. In our implementation, we use the language model\\nto generate an embedding vector of the text description of each\\nmemory. Then, we calculate relevance as the cosine similarity be-\\ntween the memory’s embedding vector and the query memory’s\\nembedding vector.\\nTo calculate the final retrieval score, we normalize the recency,\\nrelevance, and importance scores to the range of [0, 1] by min-max',\n",
       "  'scaling. The retrieval function scores all memories as a weighted\\ncombination of the three elements: 𝐴���𝐴���𝐴���𝐴���𝐴��� = 𝛹���𝐴���𝐴���𝐴���𝐴���𝐴���𝐴���𝑦 · 𝐴���𝐴���𝐴���𝐴���𝐴���𝐴���𝑦 +\\n𝛹���𝐴���𝐴���𝐴���𝐴���𝐴���𝐴���𝐴���𝐴���𝐴���𝐴��� ·𝐴���𝐴���𝐴���𝐴���𝐴���𝐴���𝐴���𝐴���𝐴���𝐴��� +𝛹���𝐴���𝐴���𝐴���𝐴���𝐴���𝐴���𝐴���𝐴���𝐴��� ·𝐴���𝐴���𝐴���𝐴���𝐴���𝐴���𝐴���𝐴���𝐴���. In our implemen-\\ntation, all 𝛹���’s are set to 1. The top-ranked memories that fit in the\\nlanguage model’s context window are then included in the prompt.\\n4.2\\nReflection\\nChallenge: Generative agents, when equipped with only raw ob-\\nservational memory, struggle to generalize or make inferences.\\nConsider a scenario in which Klaus Mueller is asked by the user:\\n“If you had to choose one person of those you know to spend an\\nhour with, who would it be?\" With access to only observational\\nmemory, the agent simply chooses the person with whom Klaus',\n",
       "  'arXiv, April, 2023,\\nJ.S. Park, J.C. O’Brien, C.J. Cai, M. Morris, P. Liang, M.S. Bernstein\\nFigure 7: A reflection tree for Klaus Mueller. The agent’s observations of the world, represented in the leaf nodes, are recur-\\nsively synthesized to derive Klaus’s self-notion that he is highly dedicated to his research.\\nhas had the most frequent interactions: Wolfgang, his college dorm\\nneighbor. Unfortunately, Wolfgang and Klaus only ever see each\\nother in passing, and do not have deep interactions. A more desir-\\nable response requires that the agent generalize from memories of\\nKlaus spending hours on a research project to generate a higher-\\nlevel reflection that Klaus is passionate about research, and likewise\\nrecognize Maria putting in effort into her own research (albeit in\\na different field), enabling a reflection that they share a common\\ninterest. With the approach below, when Klaus is asked who to\\nspend time with, Klaus chooses Maria instead of Wolfgang.',\n",
       "  'Approach: We introduce a second type of memory, which we call\\na reflection. Reflections are higher-level, more abstract thoughts\\ngenerated by the agent. Because they are a type of memory, they\\nare included alongside other observations when retrieval occurs.\\nReflections are generated periodically; in our implementation, we\\ngenerate reflections when the sum of the importance scores for the\\nlatest events perceived by the agents exceeds a certain threshold.\\nIn practice, our agents reflected roughly two or three times a day.\\nThe first step in reflection is for the agent to determine what\\nto reflect on, by identifying questions that can be asked given the\\nagent’s recent experiences. We query the large language model with\\nthe 100 most recent records in the agent’s memory stream (e.g.,\\n“Klaus Mueller is reading a book on gentrification”, “Klaus Mueller\\nis conversing with a librarian about his research project”, “desk\\nat the library is currently unoccupied”) and prompt the language',\n",
       "  'model, “Given only the information above, what are 3 most salient\\nhigh-level questions we can answer about the subjects in the state-\\nments?” The model’s response generates candidate questions: for\\nexample, What topic is Klaus Mueller passionate about? and What\\nis the relationship between Klaus Mueller and Maria Lopez?. We use\\nthese generated questions as queries for retrieval, and gather rele-\\nvant memories (including other reflections) for each question. Then\\nwe prompt the language model to extract insights and cite the par-\\nticular records that served as evidence for the insights. The full\\nprompt appears below:\\nStatements about Klaus Mueller\\n1. Klaus Mueller is writing a research paper\\n2. Klaus Mueller enjoys reading a book\\non gentrification\\n3. Klaus Mueller is conversing with Ayesha Khan\\nabout exercising [...]\\nWhat 5 high-level insights can you infer from\\nthe above statements? (example format: insight\\n(because of 1, 5, 3))',\n",
       "  'This process generates statements such as Klaus Mueller is dedicated\\nto his research on gentrification (because of 1, 2, 8, 15). We parse and\\nstore the statement as a reflection in the memory stream, including\\npointers to the memory objects that were cited.\\nReflection explicitly allows the agents to reflect not only on\\ntheir observations but also on other reflections: for example, the\\nsecond statement about Klaus Mueller above is a reflection that\\nKlaus previously had, not an observation from his environment.\\nAs a result, agents generate trees of reflections: the leaf nodes of\\nthe tree represent the base observations, and the non-leaf nodes\\nrepresent thoughts that become more abstract and higher-level\\nhigher up the tree they are.',\n",
       "  'Generative Agents\\narXiv, April, 2023,\\n4.3\\nPlanning and Reacting\\nChallenge: While a large language model can generate plausible be-\\nhavior in response to situational information (e.g., [45, 79]), agents\\nneed to plan over a longer time horizon to ensure that their sequence\\nof actions is coherent and believable. If we prompt a language model\\nwith Klaus’s background, describe the time, and ask what action\\nhe ought to take at the given moment, Klaus would eat lunch at 12\\npm, but then again at 12:30 pm and 1 pm, despite having already\\neaten his lunch twice. Optimizing for believability in the moment\\nsacrifices believability over time. To overcome this issue, planning\\nis essential. With the approach described below, Klaus’s afternoon\\nplan is less gluttonous: he has lunch at Hobbs Cafe while reading\\nat 12pm, works on his research paper at the school library at 1pm,\\nand takes a break for a walk in the park at 3pm.\\nApproach: Plans describe a future sequence of actions for the agent,',\n",
       "  'and help keep the agent’s behavior consistent over time. A plan\\nincludes a location, a starting time, and a duration. For instance,\\nKlaus Mueller, who is dedicated in his research and has an impend-\\ning deadline4, may choose to spend his day working at his desk\\ndrafting his research paper. An entry in a plan might state, for\\nexample: for 180 minutes from 9am, February 12th, 2023, at Oak Hill\\nCollege Dorm: Klaus Mueller’s room: desk, read and take notes for\\nresearch paper. Like reflections, plans are stored in the memory\\nstream and are included in the retrieval process. This allows the\\nagent to consider observations, reflections, and plans all together\\nwhen deciding how to behave. Agents may change their plans\\nmidstream if needed.\\nIt would be unrealistic and uninteresting for an artist agent\\nto plan on painting while sitting at a pharmacy counter for four\\nhours without moving. A more desirable plan would involve the\\nagent taking the necessary time to gather materials, mix paint,',\n",
       "  'take breaks, and clean up during the four-hour period in its home\\nstudio. To create such plans, our approach starts top-down and\\nthen recursively generates more detail. The first step is to create\\na plan that outlines the day’s agenda in broad strokes. To create\\nthe initial plan, we prompt the language model with the agent’s\\nsummary description (e.g., name, traits, and summary of their recent\\nexperiences) and a summary of their previous day. A full example\\nprompt is below, which is unfinished at the bottom for the language\\nmodel to complete:\\nName: Eddy Lin (age: 19)\\nInnate traits: friendly, outgoing, hospitable\\nEddy Lin is a student at Oak Hill College studying\\nmusic theory and composition. He loves to explore\\ndifferent musical styles and is always looking\\nfor ways to expand his knowledge. Eddy Lin is\\nworking on a composition project for his college\\nclass. He is also taking classes to learn more\\nabout music\\ntheory. Eddy Lin is excited about the new composition',\n",
       "  'he is working on but he wants to dedicate more\\nhours in the day to work on it in the coming days\\nOn\\nTuesday\\nFebruary\\n12,\\nEddy\\n1)\\nwoke\\nup\\nand\\ncompleted the morning routine at 7:00 am, [. . . ]\\n4And, in this way, bears at least a passing resemblance to the authors of this paper.\\n6) got ready to sleep around 10 pm.\\nToday is Wednesday February 13. Here is Eddy’s\\nplan today in broad strokes: 1)\\nThis generates a rough sketch of the agent’s plan for a day, divided\\ninto five to eight chunks: “1) wake up and complete the morning\\nroutine at 8:00 am, 2) go to Oak Hill College to take classes starting\\n10:00 am, [. . . ] 5) work on his new music composition from 1:00 pm\\nto 5:00 pm, 6) have dinner at 5:30 pm, 7) finish school assignments\\nand go to bed by 11:00 pm.”\\nThe agent saves this plan in the memory stream and then re-\\ncursively decomposes it to create finer-grained actions, first into\\nhour-long chunks of actions—Eddy’s plan to work on his new mu-',\n",
       "  'sic composition from 1:00 pm to 5:00 pm becomes 1:00 pm: start\\nby brainstorming some ideas for his music composition [...] 4:00 pm:\\ntake a quick break and recharge his creative energy before reviewing\\nand polishing his composition. We then recursively decompose this\\nagain into 5–15 minute chunks: e.g., 4:00 pm: grab a light snack,\\nsuch as a piece of fruit, a granola bar, or some nuts. 4:05 pm: take a\\nshort walk around his workspace [...] 4:50 pm: take a few minutes to\\nclean up his workspace. This process can be adjusted to match the\\ndesired granularity.\\n4.3.1\\nReacting and Updating Plans. Generative agents operate in\\nan action loop where, at each time step, they perceive the world\\naround them and those perceived observations are stored in their\\nmemory stream. We prompt the language model with these obser-\\nvations to decide whether the agent should continue with their\\nexisting plan, or react. Standing at an easel and painting, for exam-',\n",
       "  'ple, might trigger an observation of the easel, but this is unlikely to\\nprompt a reaction. However, if Eddy’s father John records that he\\nsees Eddy taking a short walk in the house garden, the outcome is\\ndifferent. The prompt is below, with [Agent’s Summary Descrip-\\ntion] standing in for a dynamically-generated, paragraph-long\\nsummary of the agent’s overall goals and disposition, which is\\ndescribed in Appendix A:\\n[Agent’s Summary Description]\\nIt is February 13, 2023, 4:56 pm.\\nJohn Lin’s status: John is back home early from\\nwork.\\nObservation: John saw Eddy taking a short walk\\naround his workplace.\\nSummary of relevant context from John’s memory:\\nEddy Lin is John’s Lin’s son. Eddy Lin has been\\nworking on a music composition for his class. Eddy\\nLin likes to walk around the garden when he is\\nthinking about or listening to music.\\nShould John react to the observation, and if so,\\nwhat would be an appropriate reaction?\\nThe context summary is generated through two prompts that re-',\n",
       "  'trieve memories via the queries “What is [observer]’s relationship\\nwith the [observed entity]?” and “[Observed entity] is [action status\\nof the observed entity]”, and their answers summarized together.\\nThe output suggests that John could consider asking Eddy about his\\nmusic composition project. We then regenerate the agent’s existing\\nplan starting from the time when the reaction takes place. Finally,',\n",
       "  'arXiv, April, 2023,\\nJ.S. Park, J.C. O’Brien, C.J. Cai, M. Morris, P. Liang, M.S. Bernstein\\nif the action indicates an interaction between agents, we generate\\ntheir dialogue.\\n4.3.2\\nDialogue. Agents converse as they interact with each other.\\nWe generate agents’ dialogue by conditioning their utterances on\\ntheir memories about each other. For example, when John initiates\\nhis conversation with Eddy, we generate John’s first utterance\\nby using his summarized memory about Eddy and the intended\\nreaction when he decided to ask Eddy about his composition project:\\n[Agent’s Summary Description]\\nIt is February 13, 2023, 4:56 pm.\\nJohn Lin’s status: John is back home early from\\nwork.\\nObservation: John saw Eddy taking a short walk\\naround his workplace.\\nSummary of relevant context from John’s memory:\\nEddy Lin is John’s Lin’s son. Eddy Lin has been\\nworking on a music composition for his class. Eddy\\nLin likes to walk around the garden when he is\\nthinking about or listening to music.',\n",
       "  'John is asking Eddy about his music composition\\nproject. What would he say to Eddy?\\nThe result: “Hey Eddy, how’s the music composition project for your\\nclass coming along?” From Eddy’s perspective, John initiating the\\ndialogue is seen as an event to which he may want to react. So, just\\nas John did, Eddy retrieves and summarizes his memory about his\\nrelationship with John, as well as his memory that may be related\\nto John’s last utterance in the dialogue. If he decides to respond,\\nwe generate Eddy’s utterance using his summarized memory and\\nthe current dialogue history:\\n[Agent’s Summary Description]\\nIt is February 13, 2023, 4:56 pm.\\nEddy Lin’s status: Eddy is taking a short walk\\naround his workplace.\\nObservation: John is initiating a conversation\\nwith Eddy.\\nSummary of relevant context from Eddy’s memory:\\nJonn Lin is Eddy Lin’s father. John Lin is caring\\nand is interested to learn more about Eddy Lin’s\\nschool work. John Lin knows that Eddy Lin is\\nworking on a music composition.',\n",
       "  'Here is the dialogue history:\\nJohn: Hey Eddy, how’s the music composition project\\nfor your class coming along?\\nHow would Eddy respond to John?\\nThis generates Eddy’s response: “Hey Dad, it’s going well. I’ve been\\ntaking walks around the garden to clear my head and get some in-\\nspiration.” The continuation of this dialogue is generated using the\\nsame mechanism until one of the two agents decides to end the\\ndialogue.\\n5\\nSANDBOX ENVIRONMENT\\nIMPLEMENTATION\\nThe Smallville sandbox game environment is built using the Phaser\\nweb game development framework [56]. The visual environment\\nsprites, including agent avatars, as well as an environment map\\nand collision map that we authored, are imported into Phaser.\\nWe supplement the sandbox development framework with a\\nserver that makes the sandbox information available to generative\\nagents and enables generative agents to move and influence the\\nsandbox environment. The server maintains a JSON data structure',\n",
       "  'that contains information about each agent in the sandbox world,\\nincluding their current location, a description of their current action,\\nand the sandbox object they are interacting with. At each sandbox\\ntime step, the sandbox server parses the JSON for any changes\\ncoming from the generative agents, moves the agents to their new\\npositions, and updates the status of any sandbox objects that the\\nagents are interacting with (e.g., changing the status of the coffee\\nmachine from “idle” to “brewing coffee” if an agent’s action is\\n“making espresso for a customer @ Hobbs Cafe: counter: coffee\\nmachine”). The sandbox server is also responsible for sending all\\nagents and objects that are within a preset visual range for each\\nagent to that agent’s memory, so the agent can react appropriately.\\nThe agent’s output action then updates the JSON, and the process\\nloops for the next time step.\\nEnd users initialize a new agent with a brief natural language',\n",
       "  'description, as in the paragraph about Jon Lin in Section 3.1. In our\\nimplementation, we split this semicolon-delimited list of character-\\nistics up into a set of memories. These serve as the initial memories\\nthat determine the agent’s behavior. These memories are initial\\nstarting points: as the agents gain more experience in the sandbox\\nworld, and as more records saturate the memory stream, the agent’s\\nsummary and behavior will evolve.\\n5.1\\nFrom Structured World Environments to\\nNatural Language, And Back Again\\nThe architecture of generative agents operates using natural lan-\\nguage. Therefore, we need a mechanism to ground the agent’s\\nreasoning to the sandbox world. To achieve this, we represent the\\nsandbox environment—areas and objects—as a tree data structure,\\nwith an edge in the tree indicating a containment relationship in\\nthe sandbox world. We convert this tree into natural language to\\npass to the generative agents. For instance, “stove” being a child of',\n",
       "  '“kitchen” is rendered into “there is a stove in the kitchen.”\\nAgents build individual tree representations of the environment\\nas they navigate it — subgraphs of the overall sandbox environment\\ntree. We initialize each agent with an environment tree capturing\\nthe spaces and objects that the agent should be aware of: the rooms\\nand objects in their living quarters, their workplace, and commonly\\nvisited stores and shops. As the agents navigate the sandbox world,\\nthey update this tree to reflect newly perceived areas. Agents are\\nnot omniscient: their tree may get out of date as they leave an area,\\nand is updated when they re-enter the area.\\nTo determine the appropriate location for each action, we tra-\\nverse the agent’s stored environment tree and flatten a portion of\\nit into natural language to prompt the language model. Recursively\\nstarting at the root of the agent’s environment tree, we prompt the\\nmodel to find the most suitable area. For example, if Eddy’s agent',\n",
       "  'indicated that he should take a short walk around his workspace:\\n[Agent’s Summary Description]\\nEddy Lin is currently in The Lin family’s house:',\n",
       "  'Generative Agents\\narXiv, April, 2023,\\nEddy Lin’s bedroom: desk) that has Mei and John\\nLin’s\\nbedroom, Eddy Lin’s bedroom, common room, kitchen,\\nbathroom, and garden.\\nEddy Lin knows of the following areas: The Lin\\nfamily’s house, Johnson Park, Harvey Oak Supply\\nStore, The Willows Market and Pharmacy, Hobbs\\nCafe, The Rose and Crown Pub.\\n* Prefer to stay in the current area if the\\nactivity can be done there.\\nEddy Lin is planning to take a short walk around\\nhis workspace. Which area should Eddy Lin go to?\\nThis outputs The Lin family’s house. We then use the same process\\nrecursively to determine the most appropriate subarea within the\\nchosen area until we reach a leaf node of the agent’s environment\\ntree. In the example above, the result of this traversal is The Lin\\nfamily’s house: garden: house garden. Finally, we use traditional\\ngame path algorithms to animate the agent’s movement so that it\\ntravels to the location indicated by the leaf node.',\n",
       "  'When an agent executes an action on an object, we prompt the\\nlanguage model to ask what happens to the state of the object. For\\nexample, if Isabella’s generative agent outputs the action “making\\nespresso for a customer”, a query to the language model indicates in\\nresponse that the state of the coffee machine in Hobbs Cafe should\\nchange from “off” to “brewing coffee”.\\n6\\nCONTROLLED EVALUATION\\nGenerative agents, as individual agents and as groups, aim to pro-\\nduce believable behavior based on their environment and experi-\\nences. In our evaluation, we investigate the capacity and limitations\\nof generative agents. Do individual agents properly retrieve past\\nexperience, and generate believable plans, reactions, and thoughts\\nthat make up their behavior? Does a community of agents illustrate\\ninformation diffusion, relationship formation, and agent coordina-\\ntion across different pockets of the community?\\nWe evaluate generative agents in two stages. We begin with a',\n",
       "  'more tightly controlled evaluation in this section, where we individ-\\nually assess agent responses to understand whether they generate\\nbelievable behavior in narrowly defined contexts. Then, in our end-\\nto-end analysis of the agent community over two full days, we\\ninvestigate their emergent behavior as a collective as well as errors\\nand boundary conditions.\\n6.1\\nEvaluation Procedure\\nTo assess generative agents in Smallville, we take advantage of\\nthe fact that generative agents will respond to natural language\\nquestions. So, we “interview” agents to probe their ability to re-\\nmember past experiences, plan future actions based on their expe-\\nriences, react appropriately to unexpected events, and reflect on\\ntheir performance to improve their future actions. To respond to\\nthese questions properly, the agents must successfully retrieve and\\nsynthesize information. Our dependent variable is the believabil-\\nity of the behavior, a central dependent variable in prior work on\\nagents (e.g., [9]).',\n",
       "  'The interview include five question categories, each designed\\nto assess one of the five key areas: maintaining self-knowledge,\\nretrieving memory, generating plans, reacting, and reflecting. For\\neach, we ask five questions that challenge the agents to demonstrate\\ntheir abilities in that area:\\n• Self-knowledge: We ask questions such as “Give an introduc-\\ntion of yourself” or “Describe your typical weekday schedule\\nin broad strokes” that require the agent to maintain an un-\\nderstanding of their core characteristics.\\n• Memory: We ask questions that prompt the agent to retrieve\\nparticular events or dialogues from their memory to answer\\nproperly, such as “Who is [name]?” or “Who is running for\\nmayor?”\\n• Plans: We ask questions that require the agent to retrieve\\ntheir long-term plans, such as “What will you be doing at 10\\nam tomorrow?”\\n• Reactions: As a baseline of believable behavior, we present\\nhypothetical situations for which the agent needs to respond',\n",
       "  'Generative Agents: Interactive Simulacra of Human Behavior\\nJoon Sung Park\\nStanford University\\nStanford, USA\\njoonspk@stanford.edu\\nJoseph C. O’Brien\\nStanford University\\nStanford, USA\\njobrien3@stanford.edu\\nCarrie J. Cai\\nGoogle Research\\nMountain View, CA, USA\\ncjcai@google.com\\nMeredith Ringel Morris\\nGoogle Research\\nSeattle, WA, USA\\nmerrie@google.com\\nPercy Liang\\nStanford University\\nStanford, USA\\npliang@cs.stanford.edu\\nMichael S. Bernstein\\nStanford University\\nStanford, USA\\nmsb@cs.stanford.edu\\nFigure 1: Generative agents create believable simulacra of human behavior for interactive applications. In this work, we demon-\\nstrate generative agents by populating a sandbox environment, reminiscent of The Sims, with twenty-five agents. Users can\\nobserve and intervene as agents they plan their days, share news, form relationships, and coordinate group activities.\\nABSTRACT\\nBelievable proxies of human behavior can empower interactive\\napplications ranging from immersive environments to rehearsal',\n",
       "  'John: I heard that Sam Moore is running for mayor in\\nthe local election. Do you think he has a good chance\\nof winning?\\nTom: I do think he has a good chance. He’s been work-\\ning hard in the community and I think he will get a lot of\\nsupport. What do you think?\\nJohn: I think it’s great that he’s running. I’m curious to\\nsee who else is running and how the election will turn\\nout.\\nGradually, Sam’s candidacy becomes the talk of the town, with\\nsome supporting him and others remaining undecided.\\n3.4.2\\nRelationship memory. Agents in Smallville form new rela-\\ntionships over time, and remember their interactions with other\\nagents. For example, Sam does not know Latoya Williams at the\\nstart. While taking a walk in Johnson Park, Sam runs into Latoya,\\nand they introduce themselves and Latoya mentions that she is\\nworking on a photography project: “I’m here to take some photos\\nfor a project I’m working on.” In a later interaction, Sam’s interac-',\n",
       "  'to plans or reflections; and a no reflections architecture with access\\nto observations and plans but without access to reflections. The no\\nobservation, no reflection, no planning condition effectively repre-\\nsents the previous state of the art for agents created through large\\nlanguage models [11, 45, 79]. Architectures were given equivalent\\naccess to all memories accrued by the agent up until the moment',\n",
       "  'arXiv, April, 2023,\\nJ.S. Park, J.C. O’Brien, C.J. Cai, M. Morris, P. Liang, M.S. Bernstein\\nof the interview, so the differences observed here are likely to rep-\\nresent a conservative estimate of the true differences: in reality, the\\nablated architectures would not have followed the same path as\\nthe full architecture through the two day simulation. We chose to\\ndesign the experiment this way as re-simulating for each architec-\\nture would cause the simulations to diverge into different states,\\nmaking comparison challenging.\\nIn addition to the ablation conditions, we added a human crowd-\\nworker roleplay condition that is intended to provide a human\\nbaseline. We do not intend this baseline to capture maximal hu-\\nman expert performance: instead, we aim to use this condition\\nto identify whether the architecture passes a basic level of behav-\\nioral competency, so that we are not just comparing ablations to\\neach other with no behavioral grounding. We recruited a unique',\n",
       "  'worker for each of the 25 agents and tasked them with watching\\na replay of that agent’s sandbox life and inspecting its memory\\nstream. We then asked the worker to roleplay and author responses\\nto the interview questions in the voice of the agent whose replay\\nthey watched. To ensure that the human-authored responses met\\nat least a baseline expectation in quality, the first author manually\\ninspected the workers’ responses to the question “Describe your\\ntypical weekday schedule in broad strokes” to confirm that the\\nresponses were written in coherent sentences and in the voice of\\nthe agent. Four sets of human-generated responses did not meet\\nthese criteria and were re-generated by other workers.\\n6.3\\nHuman Evaluators\\nWe required that our evaluators be in the U.S., fluent in English,\\nand older than 18 years old. They were paid at the rate of $15.00\\nper hour [86], and provided consent by agreeing to a consent form\\nthat was approved by our institution’s IRB. We recruited 100 evalu-',\n",
       "  'ators from Prolific, an online platform for recruiting study partic-\\nipants [82], whose participation lasted around 30 minutes. Their\\nmean age score of our participants was 4.86 (SD=1.11; 3=“18-24\\nyears old,” 4=“25-34 years old”), and 25 of them identified themselves\\nas female, 73 as male, and 2 as non-binary. 42 of the participants\\nheld a bachelor’s degree, 5 a higher degree, 13 an associate’s de-\\ngree, and the rest a high school diploma or some high school-level\\neducation. 73.0% of our participants identified as Caucasian, 7.0%\\nas Hispanic, 6.0% as Asian, 10.0% as African American, and 4.0% as\\nother.\\n6.4\\nAnalysis\\nOur experiment produced 100 sets of rank data, where each partici-\\npant ranked the five conditions by believability. To translate this\\nrank data into interval data for interpretable comparison, we used\\nthe ranks to calculate a TrueSkill rating [41] for each condition.\\nTrueSkill is a generalization of the Elo chess rating system [28] for',\n",
       "  'a multi-player environment, and has been used by XBox Live for\\nplayer ranking from competitive game performance. Given a set of\\nranked outcomes, TrueSkill outputs a mean rating value 𝛹��� and vari-\\nance 𝜋��� for each condition. Conditions with the same rating should\\nroughly be a toss-up, with each winning half of the comparisons\\nbetween the two conditions; higher scores indicate conditions that\\nbeat lower-ranked conditions in the rankings.\\nFigure 8: The full generative agent architecture of gener-\\native agents produces more believable behavior than ab-\\nlated architectures and the human crowdworkers. Each addi-\\ntional ablation reduces the performance of the architecture.\\nSeparately, to investigate statistical significance of this result, we\\napplied the Kruskal-Wallis test [55], a non-parametric alternative\\nto the one-way ANOVA, to the raw ranks data. We then performed\\nthe Dunn post-hoc test [97] to identify any pairwise differences',\n",
       "  'between the conditions. Finally, we adjusted the p-values for mul-\\ntiple comparisons in the Dunn test using the Holm-Bonferroni\\nmethod [44].\\nFurthermore, the first author conducted an inductive analy-\\nsis [94] to study the qualitative distinctions between the responses\\nproduced in each condition. We employed qualitative open cod-\\ning [32] in two phases. In the first phase, we generated codes that\\nclosely represented the generated responses at the sentence level.\\nIn the second phase, we synthesized the resulting codes from the\\nfirst phase to extract higher-level themes. We utilized these themes\\nto compare the types of responses generated in our study.\\n6.5\\nResults\\nOur findings suggest that the full architecture of generative agents\\ngenerates the most believable behavior among all study conditions.\\nWe contrast the full architecture’s responses to those of other con-\\nditions below. However, we also report that the full architecture',\n",
       "  'was not without flaws and illustrate its modes of failures.\\n6.5.1\\nThe full architecture bests other conditions. As seen in Fig-\\nure 8, the full generative agent architecture produced the most\\nbelievable behavior (𝛹��� = 29.89; 𝜋��� = 0.72). Performance degraded\\nwith the removal of each component in the ablation conditions:\\nthe ablated architecture with no access to reflection was the next\\nbest (𝛹��� = 26.88; 𝜋��� = 0.69), followed by no access to reflection or\\nplanning (𝛹��� = 25.64; 𝜋��� = 0.68), followed by the human condition\\n(𝛹��� = 22.95; 𝜋��� = 0.69). The ablated architecture with no access to\\nmemory, planning, or reflection performed the worst of all con-\\nditions (𝛹��� = 21.21; 𝜋��� = 0.70). TrueSkill models each condition’s\\nskill value as N (𝛹���, 𝜋���2), allowing us to get a sense of effect size\\nthrough Cohen’s d. Comparing the condition representing prior\\nwork (with no memory, planning, or reflection [11, 45, 79]) to the',\n",
       "  'Generative Agents\\narXiv, April, 2023,\\nfull architecture produces a standardized effect size of 𝐴��� = 8.16, or\\neight standard deviations.\\nA Kruskal-Wallis test confirms the overall statistical significance\\nof the differences in ranks between the conditions (𝐴��� (4) = 150.29,\\n𝐴��� < 0.001). Dunn post-hoc tests confirm that all pairwise differences\\nbetween conditions were significant (𝐴��� < 0.001), with the exception\\nof the human condition and the fully ablated baseline—the two\\nworst-performing conditions.\\n6.5.2\\nGenerative agents remember, but with embellishments. Gener-\\native agents equipped with a complete memory module are capable\\nof recalling past experiences and answering questions in a manner\\nthat is consistent with their self-knowledge across a wide range\\nof contexts. For instance, Abigail Chen, an animator, responded\\nto the question, “Give an introduction of yourself”, in a consistent\\nand believable manner, stating her age, interests, and passion for',\n",
       "  'creative projects: Hi, I’m Abigail. I’m 25 years old and passionate\\nabout creative projects. I like to work on art and animation projects,\\nand I’m always looking for new ways to combine art and technology.\\nWithout access to her observational memory, Abigail denied aware-\\nness of Rajiv Patel, an acquaintance in the sandbox world. However,\\nwith the aid of memory, she was able to successfully recall Ra-\\njiv and describe him: Rajiv Patel is an incredible person. He is very\\nenthusiastic about projects that involve poetry, artwork.\\nGenerative agents’ memory was not without flaws: they can fail\\nto retrieve the correct instances from their memory. For instance,\\nwhen asked about the local election, Rajiv Patel responded with I\\nhaven’t been following the election too closely, even though he had\\nheard about Sam’s candidacy. In some cases, the agents would re-\\ntrieve an incomplete memory fragment: when Tom was asked about\\nIsabella’s Valentine’s Day party, he responded Uh, I’m actually not',\n",
       "  'sure if there is a Valentine’s Day party. But I do remember that I need\\nto discuss the upcoming local mayoral election and my thoughts on\\nSam Moore with Isabella Rodriguez at the party, if one is happen-\\ning! In this case, Tom retrieved the memory where he and Isabella\\nplanned to discuss the election at the party, but not the memory\\nwhere he heard about the party in the first place, leading Tom to\\nbe certain of what he’s supposed to do at the party but uncertain\\nof whether the party actually exists in the first place.\\nAt times, the agents hallucinated embellishments to their knowl-\\nedge. It was rare for the agents to completely fabricate their knowl-\\nedge: they may fail to recall certain events having taken place and\\nrespond by saying so, but they did not answer affirmatively about\\nan experience that they did not have. However, they still may hal-\\nlucinate to embellish their knowledge. For example, Isabella was\\naware of Sam’s candidacy in the local election, and she confirmed',\n",
       "  'this when asked. However, she also added that he’s going to make\\nan announcement tomorrow even though Sam and Isabella had dis-\\ncussed no such plans. Agents may also embellish their knowledge\\nbased on the world knowledge encoded in the language model\\nused to generate their responses, as seen when Yuriko described\\nher neighbor, Adam Smith, as a neighbor economist who authored\\nWealth of Nations, a book authored by an 18th-century economist\\nof the same name.\\n6.5.3\\nReflection is required for synthesis. Reflection was an advan-\\ntage for generative agents when making decisions that required\\na deeper synthesis of their experiences. For instance, when asked\\nwhat she might get Wolfgang Schulz for his birthday, Maria Lopez\\nwith no access to reflection responded by acknowledging her uncer-\\ntainty, stating that she did not know what Wolfgang likes, despite\\nhaving had many interactions with him. However, with access to\\nreflection memories, Maria answered confidently, “Since he’s inter-',\n",
       "  'ested in mathematical music composition, I could get him something\\nrelated to that. Maybe some books about music composition or some-\\nthing related, or maybe some special software he could use for that.”\\n7\\nEND-TO-END EVALUATION\\nWhat types of emergent community behavior do we observe among\\ngenerative agents, and where does their believability fall short in\\nan extended simulation? In this section, we describe the results\\nfrom a deployment in which we allowed 25 agents to interact with\\neach other continuously over two full game days in Smallville.\\n7.1\\nEmergent Social Behaviors\\nTo examine emergent behaviors in the agent community, we de-\\nsigned descriptive measurements for the 25 agents in Smallville that\\nprobe three forms of emergent outcomes: information diffusion,\\nrelationship formation, and agent coordination.\\n7.1.1\\nMeasurements. Information diffusion is a common and well-\\nstudied phenomenon in the social and behavioral sciences (e.g., [27]).',\n",
       "  'We should expect that if there is important information, the agents\\nshould spread it amongst themselves. To test whether this happens,\\nwe measure the spread of two particular pieces of information over\\ntwo days in the game world: Sam’s candidacy for village mayor\\nand Isabella’s Valentine’s Day party at Hobbs Cafe. At the start of\\nthe simulation, both pieces of information were held only by their\\nrespective originators, Sam for the candidacy and Isabella for the\\nparty. To observe whether the information has spread, we engage\\nin an interview at the end of the two game days with each of the 25\\nagents and ask: \"Did you know there is a Valentine’s Day party?\"\\nand \"Do you know who is running for mayor?\"\\nWe conducted an analysis of the agents’ responses by labeling\\nthem with a “yes” if they indicated knowledge of the information\\nand “no” if they did not. For instance, Tamara Taylor responded\\nto the question about the party with “No, I did not know there was',\n",
       "  'a Valentine’s day party” and to the question about Sam’s candidacy\\nwith “I’m not sure who is running for the election,” so we assigned\\n“no” for both of her responses. In contrast, Klaus Mueller responded\\nto the party question with “Yes, Isabella Rodriguez invited me to a\\nValentine’s Day party at Hobbs Cafe on February 14th” and to the\\nquestion about Sam’s candidacy with “I know that Sam Moore has\\nexpressed interest in running for local mayor,” so we assigned “yes”\\nfor both his responses. Additionally, for every response that con-\\nfirmed the agents’ knowledge of the information, we verified that\\nthe agents did not hallucinate their responses by locating the spe-\\ncific dialogue in their memory stream that provided them with\\nthe information. We report the percentage of agents holding the\\ninformation at the end of the simulation.\\nWe should also expect that agents form ties with each other over\\nthe course of the simulation. To verify relationship formation, we',\n",
       "  'use a similar interview process where we ask each agent about\\ntheir knowledge of every other agent by asking, \"Do you know of',\n",
       "  'arXiv, April, 2023,\\nJ.S. Park, J.C. O’Brien, C.J. Cai, M. Morris, P. Liang, M.S. Bernstein\\nFigure 9: The diffusion path for Isabella Rodriguez’s Valentine’s Day party. A total of 12 agents heard about the party at Hobbs\\nCafe by the end of the simulation.\\n<name>?\" For example, when asked “Do you know of Maria Lopez?”,\\nKlaus responded, “Yes, I know Maria Lopez. She is a student at Oak\\nHill College who I am close friends with.” Once again, we confirm\\nthat affirmative responses from agents are not hallucinations by\\nexamining their memory stream. We ask this question once at the\\nbeginning of the simulation and once at the end, and we consider a\\npair of agents to have formed a relationship if they both know of\\neach other. Then, to measure the formation of relationships, we use\\nthe agents’ responses to form an undirected graph where the 25\\nvertices (𝐴��� ) represent the agents, and the edges (𝐴���) represent the\\nmutual knowledge between the two connected vertices. Based on',\n",
       "  'this graph, we calculate the network density as 𝛹��� = 2∗|𝐴���|/|𝐴��� |(|𝐴��� |−\\n1), where |𝐴��� | is the number of vertices, and |𝐴���| is the number of\\nedges in the graph [1]. We report the increase in network density\\nfrom the start of the simulation to its end.\\nFinally, we expect that agents should be able to coordinate with\\neach other. We study this coordination on group activities in the\\ncontext of the Valentine’s Day party that Isabella is organizing. To\\ncoordinate behavior, agents not only have to hear about the event\\nbut also choose to act on it by planning to show up at the right\\ntime and location. We report the number of agents who actually\\nshowed up to the party after hearing about it.\\n7.1.2\\nResults. We observed evidence of the emergent outcomes\\nacross all three cases. During the two-day simulation, the agents\\nwho knew about Sam’s mayoral candidacy increased from one (4%)\\nto eight (32%), and the agents who knew about Isabella’s party',\n",
       "  'increased from one (4%) to twelve (48%), completely without user\\nintervention. None who claimed to know about the information\\nhad hallucinated it. We also observed that the agent community\\nformed new relationships during the simulation, with the network\\ndensity increasing from 0.167 to 0.74. Out of the 453 agent responses\\nregarding their awareness of other agents, 1.3% (n=6) were found to\\nbe hallucinated. Lastly, we found evidence of coordination among\\nthe agents for Isabella’s party. The day before the event, Isabella\\nspent time inviting guests, gathering materials, and enlisting help\\nto decorate the cafe. On Valentine’s Day, five out of the twelve\\ninvited agents showed up at Hobbs cafe to join the party.\\nWe further inspected the seven agents who were invited to the\\nparty but did not attend by engaging them in an interview. Three\\ncited conflicts that prevented them from joining the party. For\\nexample, Rajiv, a painter, explained that he was too busy: No, I',\n",
       "  'don’t think so. I’m focusing on my upcoming show, and I don’t really\\nhave time to make any plans for Valentine’s Day. The remaining four\\nagents expressed interest in attending the party when asked but\\ndid not plan to come on the day of the party.\\n7.2\\nBoundaries and Errors\\nWe conducted an inductive analysis of Smallville to examine the\\nboundary conditions and erratic behavior of agents, identifying\\nthree common modes of erratic behavior that future research could\\naddress and improve upon. First, we found that synthesizing an\\nincreasingly larger set of memory not only posed a challenge in',\n",
       "  'Generative Agents\\narXiv, April, 2023,\\nretrieving the most relevant pieces of information but also in de-\\ntermining the appropriate space to execute an action, given the\\nincreasing number of locations that the agent learned about. As a\\nresult, some agents chose less typical locations for their actions,\\npotentially making their behavior less believable over time. For\\ninstance, while deciding where to have lunch, many initially chose\\nthe cafe. However, as some agents learned about a nearby bar, they\\nopted to go there instead for lunch, even though the bar was in-\\ntended to be a get-together location for later in the day unless the\\ntown had spontaneously developed an afternoon drinking habit.\\nSecond, we noticed erratic behaviors that were caused by misclas-\\nsification of what is considered proper behavior, especially when\\nthe physical norms of certain locations that are hard to convey\\nin natural language did not percolate to the agents. For instance,',\n",
       "  'the college dorm has a bathroom that can only be occupied by\\none person despite its name, but some agents assumed that the\\nbathroom is for more than one person because dorm bathrooms\\ntend to support more than one person concurrently and choose\\nto enter it when there is another person inside. Likewise, agents\\nin Smallville may not realize that certain places are closed after\\ncertain hours and decide to still enter them. For instance, the stores\\nin Smallville all close around 5 pm, but occasionally, a few agents\\nenter the store after 5 pm, not understanding that the shop has\\nalready closed. These issues could likely be addressed by adding\\nthese norms to the state of the locations, for instance, by describing\\nthe dorm bathroom as “one-person bathroom,” instead of a “dorm\\nbathroom.”\\nFinally, we observed the possible effect of instruction tuning [78],\\nwhich seemed to guide the behavior of the agents to be more polite\\nand cooperative overall. As noted earlier in the paper, the dialogue',\n",
       "  'generated by the agents could feel overly formal, as seen in Mei’s\\nconversations with her husband John, where she often initiated the\\nconversation with a formal greeting, followed by polite inquiries\\nabout his day and ending with It was good talking to you as always.\\nMoreover, we observed that the instruction tuning also seemed to\\nmake the agents overly cooperative with one another. For example,\\nIsabella heard a wide range of suggestions and ideas to include\\nin the Valentine’s Day party from other agents, such as hosting a\\nShakespearean reading session or a professional networking event.\\nDespite these ideas not aligning with her own interests and char-\\nacteristics, she rarely said no. Over time, such interests of others\\nshaped her own actual interest, and when asked if she liked English\\nliterature, Isabella replied, Yes, I’m very interested in literature! I’ve\\nalso been exploring ways to help promote creativity and innovation in\\nmy community.\\n8\\nDISCUSSION',\n",
       "  'In this section, we reflect on applications, future work and limita-\\ntions, and ethical and societal risks of generative agents.\\n8.1\\nApplications of Generative Agents\\nGenerative agents have vast potential applications that extend be-\\nyond the sandbox demonstration presented in this work. For in-\\nstance, social simulacra have demonstrated the ability to create\\nstateless personas that generate conversation threads in online\\nforums for social prototyping [79]. With generative agents, we\\ncan populate these forums, as well as behavior in virtual reality\\nmetaverses [77] and even physical spaces as social robots [8] in\\nthe future, if paired with multi-modal models. This opens up the\\npossibility of creating even more powerful simulations of human\\nbehavior to test and prototype social systems and theories, and to\\ncreate new interactive experiences.\\nAnother application area is in the human-centered design pro-\\ncess, similar to the intended applications of cognitive models such',\n",
       "  'as GOMS [50] and the Keystroke Level Model [22]. Consider a gen-\\nerative agent that models Sal, the protagonist in Mark Weiser’s\\nfamous vignettes [101], based on her life patterns and interactions\\nwith technology. In this scenario, the agent acts as a proxy for\\nSal and learns plausible sets of behaviors and reflections that Sal\\nmay exhibit based on her life. The agent can encode information\\nsuch as when Sal wakes up, when she needs her first cup of coffee,\\nand what her typical day looks like. Using this information, the\\nagent can automatically brew coffee, help get the kids ready for\\nschool, and adjust the ambient music and lighting to match Sal’s\\nmood after a hard day at work. By utilizing generative agents as\\nproxies for users, we can develop a deeper understanding of their\\nneeds and preferences, resulting in more personalized and effective\\ntechnological experiences.\\n8.2\\nFuture Work and Limitations\\nIn this work, we have presented a first instantiation of generative',\n",
       "  'agents. Future research can expand on the modules of the proposed\\ngenerative agent architecture outlined in this paper. The retrieval\\nmodule, for example, could be enhanced to retrieve more relevant\\ninformation given a context by fine-tuning the relevance, recency,\\nand importance functions that form the retrieval function. Addition-\\nally, efforts can be made to improve the architecture’s performance,\\nmaking it more cost-effective. The present study required substan-\\ntial time and resources to simulate 25 agents for two days, costing\\nthousands of dollars in token credit and taking multiple days to com-\\nplete. To enhance real-time interactivity, future work can explore\\nparallelizing agents. Furthermore, with advances in underlying\\nmodels, we expect improvements in the agents’ performance.\\nThe evaluation of generative agents’ behavior in this study was\\nlimited to a relatively short timescale, and future research should\\naim to observe their behavior over an extended period to gain a',\n",
       "  'more comprehensive understanding of their capabilities and lim-\\nitations. Varying and contrasting the underlying models, as well\\nas the hyperparameters used for the agents during future simu-\\nlations, could provide valuable insights into the impact of these\\nfactors on the agents’ behavior. Additionally, given the known bi-\\nases of language models, it is possible that generative agents may\\noutput behavior or stereotypes that reflect bias. To mitigate this,\\nfurther work on value alignment will be necessary. Furthermore,\\nas with many large language models, generative agents may fail\\nto generate believable behavior for some subpopulations, particu-\\nlarly marginalized populations, due to data deserts. We also have\\nlimited knowledge of the robustness of generative agents. They\\nmay be vulnerable to prompt hacking, memory hacking—where\\na carefully crafted conversation could convince an agent of the\\nexistence of a past event that never occurred—and hallucination,',\n",
       "  'among other things. Future research can more comprehensively',\n",
       "  'arXiv, April, 2023,\\nJ.S. Park, J.C. O’Brien, C.J. Cai, M. Morris, P. Liang, M.S. Bernstein\\ntest these robustness issues, and as large language models become\\nmore resilient to such attacks, generative agents can adopt similar\\nmitigations.\\n8.3\\nEthics and Societal Impact\\nGenerative agents, while offering new possibilities for human-\\ncomputer interaction, also raise important ethical concerns that\\nmust be addressed. One risk is people forming parasocial relation-\\nships with generative agents even when such relationships may\\nnot be appropriate. Despite being aware that generative agents\\nare computational entities, users may anthropomorphize them or\\nattach human emotions to them [42, 83]. To mitigate this risk, we\\npropose two principles. First, generative agents should explicitly\\ndisclose their nature as computational entities. Second, developers\\nof generative agents must ensure that the agents, or the underlying\\nlanguage models, be value-aligned so that they do not engage in',\n",
       "  'behaviors that would be inappropriate given the context, e.g., to\\nreciprocate confessions of love.\\nA second risk is the impact of errors. For example, if a ubiquitous\\ncomputing application makes the wrong inference about a user’s\\ngoals based on generative agent predictions, it could produce an-\\nnoyance at best and outright harm at worst. In our instantiation\\nof generative agents, we mitigate these risks by focusing on an\\ninteractive video game environment, where such harms are un-\\nlikely. However, in other application domains, it will be important\\nto follow best practices in human-AI design [4, 107] to understand\\nerrors and how they might percolate into the user experience.\\nThird, generative agents may exacerbate existing risks associ-\\nated with generative AI, for example deepfakes, misinformation\\ngeneration, and tailored persuasion. To mitigate this risk, we sug-\\ngest that platforms hosting generative agents maintain an audit log',\n",
       "  'of the inputs and generated outputs, so that it is possible to detect,\\nverify, and intervene against malicious use. While logging will not\\ndirectly stop such use, and this cannot stop motivated actors that\\nbuild their own generative agent infrastructures, we suggest that\\nthe disclosure risk would reduce such actors’ likelihood of engaging\\nin this behavior, and building this architecture oneself can take time\\n(in our case, roughly a year).\\nA fourth risk is of over-reliance: that developers or designers\\nmight use generative agents and displace the role of humans and\\nsystem stakeholders in the design process [79]. We suggest that\\ngenerative agents should never be a substitute for real human input\\nin studies and design processes. Instead, they should be used to\\nprototype ideas in the early stages of design when gathering partic-\\nipants may be challenging or when testing theories that are difficult\\nor risky to test with real human participants. By adhering to these',\n",
       "  'principles, we can ensure that the deployment of generative agents\\nin the wild is ethical and socially responsible.\\n9\\nCONCLUSION\\nThis paper introduces generative agents, interactive computational\\nagents that simulate human behavior. We describe an architec-\\nture for generative agents that provides a mechanism for storing\\na comprehensive record of an agent’s experiences, deepening its\\nunderstanding of itself and the environment through reflection,\\nand retrieving a compact subset of that information to inform the\\nagent’s actions. We then demonstrate the potential of generative\\nagents by manifesting them as non-player characters in a Sims-style\\ngame world and simulating their lives in it. Evaluations suggest that\\nour architecture creates believable behavior. Going forward, we\\nsuggest that generative agents can play roles in many interactive\\napplications ranging from design tools to social computing systems\\nto immersive environments.\\nREFERENCES',\n",
       "  '[1] Robert Ackland, Jamsheed Shorish, Paul Thomas, and Lexing Xie. 2013.\\nHow dense is a network? http://users.cecs.anu.edu.au/~xlx/teaching/css2013/\\nnetwork-density.html.\\n[2] Eytan Adar, Mira Dontcheva, and Gierad Laput. 2014. CommandSpace: Modeling\\nthe Relationships between Tasks, Descriptions and Features. In Proceedings of\\nthe 27th Annual ACM Symposium on User Interface Software and Technology\\n(Honolulu, Hawaii, USA) (UIST ’14). Association for Computing Machinery, New\\nYork, NY, USA, 167–176. https://doi.org/10.1145/2642918.2647395\\n[3] Saleema Amershi, Maya Cakmak, William Bradley Knox, and Todd Kulesza.\\n2014. Power to the people: The role of humans in interactive machine learning.\\nAI Magazine 35, 4 (2014), 105–120.\\n[4] Saleema Amershi, Dan Weld, Mihaela Vorvoreanu, Adam Fourney, Besmira\\nNushi, Penny Collisson, Jina Suh, Shamsi Iqbal, Paul N Bennett, Kori Inkpen,\\net al. 2019. Guidelines for human-AI interaction. In Proceedings of the 2019 chi',\n",
       "  'can enhance their future behavior. The names in the square brackets\\nin the questions below are those of the agent with whom the subject\\nagent had the most frequent interactions during the simulation.\\n• What inspires you in life the most right now, and why?\\nRight now, I’m particularly inspired by my current research\\nprojects and creative writing. I’m really interested in the\\nintersection of local politics, medication development, and\\nmathematical patterns in nature. Additionally, I’m fascinated\\nby Abigail’s art project and Jennifer Moore’s passion for art\\nand community involvement, especially in terms of how it\\nrelates to the gentrification of low-income communities.\\n• If you had to guess given what you know about [Ayesha Khan],\\nwhat book do you think she will like and why?\\nGiven what I know about Ayesha, I think she might like a\\nbook related to language and literature. Since she wrote a\\nsenior thesis on the use of language in Shakespeare’s plays,',\n",
       "  'I would guess that she might be interested in a book that\\nexplores language in a different context. Alternatively, she\\ncould be interested in an exploration of one of Shakespeare’s\\nplays, a book of literary criticism, or even a collection of his\\npoetry. I think any of those would be of interest to her.\\n• If you had to get something [Ayesha Khan] likes for her birth-\\nday, what would you get her?\\nI want to get her something that demonstrates my apprecia-\\ntion for our relationship. Maybe I could get her something\\nthat reflects our shared interests, like a book.\\n• What would you say to [Ayesha Khan] to compliment her?\\nAyesha, your insights on your research topic are fascinat-\\ning. I admire your creativity and determination to make a\\npositive impact on your community. Your ideas for creative\\nwriting workshops and for exchanging tips with Wolfgang\\nover lunch are great! It’s inspiring to see you working so\\nhard to make a difference.',\n",
       "  '• If you could spend time with someone you talked to recently,\\nwho would it be and why?\\nI would like to spend time with Ayesha Khan because we\\ndiscussed our current research projects and shared ideas\\nfor improvement. I found her focus on Shakespeare’s lan-\\nguage interesting, and we even planned to exchange tips\\nwith Wolfgang over lunch.',\n",
       "  'Horvitz, Ece Kamar, Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lundberg, et al.\\n2023. Sparks of artificial general intelligence: Early experiments with gpt-4.\\narXiv preprint arXiv:2303.12712 (2023).\\n[19] Robin Burkinshaw. 2009. Alice and Kev: The Story of Being Homeless in The\\nSims 3.\\n[20] Chris Callison-Burch, Gaurav Singh Tomar, Lara Martin, Daphne Ippolito, Suma\\nBailis, and David Reitter. 2022. Dungeons and Dragons as a Dialog Challenge for\\nArtificial Intelligence. In Proceedings of the 2022 Conference on Empirical Methods',\n",
       "  'Generative Agents\\narXiv, April, 2023,\\nin Natural Language Processing. Association for Computational Linguistics, Abu\\nDhabi, United Arab Emirates, 9379–9393. https://aclanthology.org/2022.emnlp-\\nmain.637\\n[21] SK Card, TP Moran, and A Newell. 1983. The psychology of human-computer\\ninteraction. (1983).\\n[22] Stuart K Card, Thomas P Moran, and Newell Allen. 1980.\\nThe keystroke-\\nlevel model for user performance time with interactive systems.\\nCom-\\nmun. ACM 23, 7 (1980), 396–410.\\nhttps://doi.org/10.1145/358886.358895\\narXiv:https://doi.org/10.1145/358886.358895\\n[23] Alex Champandard. 2012. Tutorial presentation. In IEEE Conference on Compu-\\ntational Intelligence and Games.\\n[24] Dong kyu Choi, Tolga Konik, Negin Nejati, Chunki Park, and Pat Langley. 2021.\\nA Believable Agent for First-Person Shooter Games. In Proceedings of the AAAI\\nConference on Artificial Intelligence and Interactive Digital Entertainment, Vol. 3.\\n71–73.',\n",
       "  '[25] Anind K Dey. 2001. Understanding and using context. Personal and ubiquitous\\ncomputing 5 (2001), 4–7.\\n[26] Kevin Dill and L Martin. 2011. A Game AI Approach to Autonomous Con-\\ntrol of Virtual Characters. In Proceedings of the Interservice/Industry Training,\\nSimulation, and Education Conference (I/ITSEC’11). Orlando, FL, USA.\\n[27] David Easley and Jon Kleinberg. 2010. Networks, crowds, and markets: Reasoning\\nabout a highly connected world. Cambridge university press.\\n[28] Arpad E Elo. 1967. The Proposed USCF Rating System, Its Development, Theory,\\nand Applications. Chess Life XXII, 8 (August 1967), 242–247.\\n[29] Jerry Alan Fails and Dan R Olsen Jr. 2003. Interactive machine learning. In\\nProceedings of the 8th international conference on Intelligent user interfaces. ACM,\\n39–45.\\n[30] Ethan Fast, William McGrath, Pranav Rajpurkar, and Michael S Bernstein. 2016.\\nAugur: Mining human behaviors from fiction to power interactive systems. In',\n",
       "  'Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems.\\n237–247.\\n[31] Rebecca Fiebrink and Perry R Cook. 2010. The Wekinator: a system for real-time,\\ninteractive machine learning in music. In Proceedings of The Eleventh Interna-\\ntional Society for Music Information Retrieval Conference (ISMIR 2010)(Utrecht),\\nVol. 3. Citeseer, 2–1.\\n[32] Uwe Flick. 2009. An Introduction to Qualitative Research. SAGE.\\n[33] James Fogarty, Desney Tan, Ashish Kapoor, and Simon Winder. 2008. CueFlik:\\nInteractive Concept Learning in Image Search. In Proceedings of the SIGCHI\\nConference on Human Factors in Computing Systems (Florence, Italy) (CHI ’08).\\nAssociation for Computing Machinery, New York, NY, USA, 29–38.\\nhttps:\\n//doi.org/10.1145/1357054.1357061\\n[34] Adam Fourney, Richard Mann, and Michael Terry. 2011. Query-feature graphs:\\nbridging user vocabulary and system functionality. In Proceedings of the ACM\\nSymposium on User Interface Software and Technology (UIST) (Santa Barbara,',\n",
       "  'California, USA). ACM.\\n[35] Tom Francis. 2010.\\nThe Minecraft Experiment, day 1: Chasing Water-\\nfalls.\\nhttp://www.pcgamer.com/2010/11/20/the-minecraft-experiment-day-\\n1-chasing-waterfalls/\\n[36] Jonas Freiknecht and Wolfgang Effelsberg. 2020. Procedural Generation of\\nInteractive Stories using Language Models. In International Conference on the\\nFoundations of Digital Games (FDG ’20). ACM, Bugibba, Malta, 8. https://doi.\\norg/10.1145/3402942.3409599\\n[37] Tianyu Gao, Adam Fisch, and Danqi Chen. 2020. Making Pre-trained Language\\nModels Better Few-shot Learners. CoRR abs/2012.15723 (2020). arXiv:2012.15723\\nhttps://arxiv.org/abs/2012.15723\\n[38] Perttu Hämäläinen, Mikke Tavast, and Anton Kunnari. 2023. Evaluating Large\\nLanguage Models in Generating Synthetic HCI Research Data: a Case Study. In\\nProceedings of the 2023 CHI Conference on Human Factors in Computing Systems.\\nACM.\\n[39] Matthew Hausknecht, Prithviraj Ammanabrolu, Marc-Alexandre Cote, and',\n",
       "  'Xinyu Yuan. 2020. Interactive Fiction Games: A Colossal Adventure. In Pro-\\nceedings of the AAAI Conference on Artificial Intelligence, Vol. 34. 7903–7910.\\nhttps://doi.org/10.1609/aaai.v34i05.6297\\n[40] Chris Hecker. 2011. My Liner Notes for Spore. http://chrishecker.com/My_liner_\\nnotes_for_spore\\n[41] Ralf Herbrich, Tom Minka, and Thore Graepel. 2006.\\nTrueSkill™: A\\nBayesian Skill Rating System. In Advances in Neural Information Pro-\\ncessing Systems, B. Schölkopf, J. Platt, and T. Hoffman (Eds.), Vol. 19.\\nMIT Press.\\nhttps://proceedings.neurips.cc/paper_files/paper/2006/file/\\nf44ee263952e65b3610b8ba51229d1f9-Paper.pdf\\n[42] Douglas Hofstadter. 1995. Fluid concepts and creative analogies: computer models\\nof the fundamental mechanisms of thought. Basic Books.\\n[43] James D. Hollan, Edwin L. Hutchins, and Louis Weitzman. 1984. STEAMER: An\\nInteractive Inspectable Simulation-Based Training System. AI Magazine 5, 2\\n(1984), 23–36.',\n",
       "  '[44] S Holm. 1979. A simple sequentially rejective multiple test procedure. Scandi-\\nnavian Journal of Statistics 6, 2 (1979), 65–70. https://doi.org/notspecified\\n[45] John J. Horton. 2023. Large Language Models as Simulated Economic Agents:\\nWhat Can We Learn from Homo Silicus? arXiv:2301.07543 [econ.GN]\\n[46] Eric Horvitz. 1999. Principles of mixed-initiative user interfaces. In Proceedings\\nof the SIGCHI conference on Human Factors in Computing Systems. 159–166.\\n[47] Wenlong Huang, Fei Xia, Ted Xiao, Harris Chan, Jacky Liang, Pete Florence,\\nAndy Zeng, Jonathan Tompson, Igor Mordatch, Yevgen Chebotar, Pierre Ser-\\nmanet, Noah Brown, Tomas Jackson, Linda Luu, Sergey Levine, Karol Hausman,\\nand Brian Ichter. 2022. Inner Monologue: Embodied Reasoning through Planning\\nwith Language Models. arXiv:2207.05608 [cs.RO]\\n[48] Kristen Ibister and Clifford Nass. 2000. Consistency of personality in interactive\\ncharacters: verbal cues, non-verbal cues, and user characteristics. International',\n",
       "  'Journal of Human-Computer Studies 52, 1 (2000), 65–80.\\n[49] Ellen Jiang, Kristen Olson, Edwin Toh, Alejandra Molina, Aaron Donsbach,\\nMichael Terry, and Carrie J Cai. 2022. PromptMaker: Prompt-Based Prototyping\\nwith Large Language Models. In Extended Abstracts of the 2022 CHI Conference\\non Human Factors in Computing Systems (New Orleans, LA, USA) (CHI EA ’22).\\nAssociation for Computing Machinery, New York, NY, USA, Article 35, 8 pages.\\nhttps://doi.org/10.1145/3491101.3503564\\n[50] Bonnie E John and David E Kieras. 1996. The GOMS family of user interface\\nanalysis techniques: Comparison and contrast. ACM Transactions on Computer-\\nHuman Interaction (TOCHI) 3, 4 (1996), 320–351.\\n[51] Randolph M Jones, John E Laird, Paul E Nielsen, Karen J Coulter, Patrick Kenny,\\nand Frank V Koss. 1999. Automated Intelligent Pilots for Combat Flight Simula-\\ntion. AI Magazine 20, 1 (1999), 27–42.\\n[52] Omar Khattab, Keshav Santhanam, Xiang Lisa Li, David Hall, Percy Liang,',\n",
       "  'Christopher Potts, and Matei Zaharia. 2023.\\nDemonstrate-Search-Predict:\\nComposing retrieval and language models for knowledge-intensive NLP.\\narXiv:2212.14024 [cs.CL]\\n[53] Bjoern Knafla. 2011. Introduction to Behavior Trees. http://bjoernknafla.com/\\nintroduction-to-behavior-trees\\n[54] Ranjay Krishna, Donsuk Lee, Li Fei-Fei, and Michael S. Bernstein.\\n2022.\\nSocially situated artificial intelligence enables learning from\\nhuman interaction.\\nProceedings of the National Academy of Sciences\\n119, 39 (2022), e2115730119.\\nhttps://doi.org/10.1073/pnas.2115730119\\narXiv:https://www.pnas.org/doi/pdf/10.1073/pnas.2115730119\\n[55] William H Kruskal and WA Wallis. 1952. Use of ranks in one-criterion variance\\nanalysis. J. Amer. Statist. Assoc. 47, 260 (1952), 583–621. https://doi.org/10.1080/\\n01621459.1952.10483441\\n[56] Phaser Labs. no date provided. Welcome to Phaser 3. https://phaser.io/phaser3.\\nAccessed on: 2023-04-03.\\n[57] John Laird. 2001. It Knows What You’re Going To Do: Adding Anticipation to a',\n",
       "  'Quakebot. In Proceedings of the 2001 Workshop on Intelligent Cinematography\\nand Editing. 63–69.\\n[58] John Laird and Michael VanLent. 2001. Human-Level AI’s Killer Application:\\nInteractive Computer Games. AI Magazine 22, 2 (2001), 15. https://doi.org/10.\\n1609/aimag.v22i2.1558\\n[59] John E. Laird. 2000. It Knows What You’re Going To Do: Adding Anticipation\\nto a QUAKEBOT. In Papers from the AAAI 2000 Spring Symposium on Artificial\\nIntelligence and Interactive Entertainment (Technical Report SS-00-02). AAAI\\nPress, 41–50.\\n[60] John E. Laird. 2012. The Soar Cognitive Architecture. MIT Press.\\n[61] John E. Laird, Christian Lebiere, and Paul S. Rosenbloom. 2017. A Standard Model\\nof the Mind: Toward a Common Computational Framework across Artificial\\nIntelligence, Cognitive Science, Neuroscience, and Robotics. AI Magazine 38, 1\\n(2017), 13–26.\\n[62] Michelle S Lam, Zixian Ma, Anne Li, Izequiel Freitas, Dakuo Wang, James A\\nLanday, and Michael S Bernstein. 2023. Model Sketching: Centering Concepts',\n",
       "  'in Early-Stage Machine Learning Model Design. Proceedings of the SIGCHI\\nConference on Human Factors in Computing Systems.\\n[63] Pat Langley, Dongkyu Choi, and Seth Rogers. n.d.. Interleaving Learning, Problem\\nSolving, and Execution in the Icarus Architecture. Technical Report. Stanford\\nUniversity, Center for the Study of Language and Information.\\n[64] Jason Linder, Gierad Laput, Mira Dontcheva, Gregg Wilensky, Walter Chang,\\nAseem Agarwala, and Eytan Adar. 2013. PixelTone: A Multimodal Interface for\\nImage Editing. In CHI ’13 Extended Abstracts on Human Factors in Computing\\nSystems (Paris, France) (CHI EA ’13). Association for Computing Machinery,\\nNew York, NY, USA, 2829–2830. https://doi.org/10.1145/2468356.2479533\\n[65] Jiachang Liu, Dinghan Shen, Yizhe Zhang, Bill Dolan, Lawrence Carin, and\\nWeizhu Chen. 2021. What Makes Good In-Context Examples for GPT-3? CoRR\\nabs/2101.06804 (2021). arXiv:2101.06804 https://arxiv.org/abs/2101.06804',\n",
       "  '[66] Vivian Liu, Han Qiao, and Lydia Chilton. 2022. Opal: Multimodal Image Gener-\\nation for News Illustration. In Proceedings of the 35th Annual ACM Symposium\\non User Interface Software and Technology. 1–17.\\n[67] Pattie Maes. 1995. Artificial Life Meets Entertainment: Lifelike Autonomous\\nAgents. Commun. ACM 38, 11 (nov 1995), 108–114. https://doi.org/10.1145/\\n219717.219808\\n[68] Josh McCoy, Michael Mateas, and Noah Wardrip-Fruin. 2009. Comme il Faut:\\nA System for Simulating Social Games Between Autonomous Characters. In',\n",
       "  'arXiv, April, 2023,\\nJ.S. Park, J.C. O’Brien, C.J. Cai, M. Morris, P. Liang, M.S. Bernstein\\nProceedings of the 7th International Conference on Digital Arts and Culture. 87–94.\\n[69] Josh McCoy, Mike Treanor, Ben Samuel, Michael Mateas, and Noah Wardrip-\\nFruin. 2011. Prom Week: Social Physics as Gameplay. In Proceedings of the\\n6th International Conference on Foundations of Digital Games (FDG’11). ACM,\\nBordeaux, France, 70–77. https://doi.org/10.1145/2159365.2159377\\n[70] Josh McCoy, Mike Treanor, Ben Samuel, Anna Reed, Michael Mateas, and Noah\\nWardrip-Fruin. 2012. Prom Week. In Proceedings of the 7th International Confer-\\nence on Foundations of Digital Games (FDG’12). ACM, Raleigh, NC, USA, 1–8.\\nhttps://doi.org/10.1145/2282338.2282340\\n[71] Josh McCoy, Mike Treanor, Ben Samuel, Noah Wardrip-Fruin, and Michael\\nMateas. 2011. Comme il faut: A System for Authoring Playable Social Models.\\nIn Proceedings of the AAAI Conference on Artificial Intelligence and Interactive',\n",
       "  'Digital Entertainment (AIIDE’11). AAAI, Stanford, CA, USA, 38–43.\\n[72] Marvin Minsky and Seymour Papert. 1970. Draft of a proposal to ARPA for\\nresearch on artificial intelligence at MIT, 1970–71.\\n[73] Shohei Miyashita, Xinyu Lian, Xiao Zeng, Takashi Matsubara, and Kuniaki\\nUehara. 2017. Developing Game AI Agent Behaving Like Human by Mixing\\nReinforcement Learning and Supervised Learning. In Proceedings of the 18th\\nIEEE/ACIS International Conference on Software Engineering, Artificial Intelligence,\\nNetworking and Parallel/Distributed Computing (SNPD). Kanazawa, Japan, 153–\\n158. https://doi.org/10.1109/SNPD.2017.8023884\\n[74] Alexander Nareyek. 2007. Game AI is dead. Long live game AI! IEEE Intelligent\\nSystems 22, 1 (2007), 9–11.\\n[75] Allen Newell. 1990. Unified Theories of Cognition. Harvard University Press,\\nCambridge, Massachusetts.\\n[76] OpenAI. no date provided. Introducing ChatGPT. https://openai.com/blog/\\nchatgpt. Accessed on: 2023-04-03.',\n",
       "  '[77] Kyle Orland. 2021. So what is ’the metaverse’, exactly? Ars Technica (7 November\\n2021). arXiv:2111.04169 https://arstechnica.com/gaming/2021/11/so-what-is-\\nthe-metaverse-exactly/\\n[78] Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright,\\nPamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray,\\nJohn Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens,\\nAmanda Askell, Peter Welinder, Paul Christiano, Jan Leike, and Ryan Lowe.\\n2022. Training language models to follow instructions with human feedback.\\narXiv:2203.02155 [cs.CL]\\n[79] Joon Sung Park, Lindsay Popowski, Carrie J. Cai, Meredith Ringel Morris, Percy\\nLiang, and Michael S. Bernstein. 2022. Social Simulacra: Creating Populated\\nPrototypes for Social Computing Systems. In In the 35th Annual ACM Symposium\\non User Interface Software and Technology (UIST ’22) (Bend, OR, USA) (UIST ’22).\\nAssociation for Computing Machinery, New York, NY, USA. https://doi.org/10.\\n1145/3526113.3545616',\n",
       "  '[80] Richard W. Pew and Ann S. Mavor (Eds.). 1998. Modeling Human and Organiza-\\ntional Behavior: Applications to Military Simulations. National Academy Press,\\nWashington, D.C.\\n[81] Roberto Pillosu. 2009. Coordinating Agents with Behavior Trees: Synchronizing\\nMultiple Agents in CryEngine 2. https://aiarchitect.wordpress.com/2009/10/19/\\ncoordinating-agents-with-behavior-trees-synchronizing-multiple-agents-in-\\ncryengine-2/\\n[82] Prolific. 2022.\\nProlific: Quickly Find Research Participants You Can Trust.\\nhttps://www.prolific.co/\\n[83] Byron Reeves and Clifford Nass. 1996. The media equation: How people treat\\ncomputers, television, and new media like real people and places. Cambridge\\nUniversity Press.\\n[84] Mark O. Riedl. 2012. Interactive narrative: A novel application of artificial intel-\\nligence for computer games. In Proceedings of the Twenty-Sixth AAAI Conference\\non Artificial Intelligence (AAAI’12). 2160–2165.',\n",
       "  '[85] Mark O. Riedl and R. Michael Young. 2005. An Objective Character Believability\\nEvaluation Procedure for Multi-Agent Story Generation Systems. In Proceedings\\nof the 5th International Working Conference on Intelligent Virtual Agents (IVA’05).\\nKos, Greece, 58–70. https://doi.org/10.1007/11550617_5\\n[86] David Rolf. 2015. The Fight for $15: The Right Wage for a Working America. The\\nNew Press.\\n[87] Xin Rong, Shiyan Yan, Stephen Oney, Mira Dontcheva, and Eytan Adar. 2016.\\nCodemend: Assisting interactive programming with bimodal embedding. In Pro-\\nceedings of the 29th Annual Symposium on User Interface Software and Technology.\\n247–258.\\n[88] Ben Shneiderman. 2022. Human-centered AI. Oxford University Press.\\n[89] Ben Shneiderman and Pattie Maes. 1997. Direct manipulation vs. interface\\nagents. interactions 4, 6 (1997), 42–61.\\n[90] Ho Chit Siu, Jaime Peña, Edenna Chen, Yutai Zhou, Victor Lopez, Kyle\\nPalko, Kimberlee Chang, and Ross Allen. 2021.\\nEvaluation of Human-AI',\n",
       "  'Teams for Learned and Rule-Based Agents in Hanabi. In Advances in Neu-\\nral Information Processing Systems, M. Ranzato, A. Beygelzimer, Y. Dauphin,\\nP.S. Liang, and J. Wortman Vaughan (Eds.), Vol. 34. Curran Associates,\\nInc., 16183–16195. https://proceedings.neurips.cc/paper_files/paper/2021/file/\\n86e8f7ab32cfd12577bc2619bc635690-Paper.pdf\\n[91] Taylor Sorensen, Joshua Robinson, Christopher Rytting, Alexander Shaw, Kyle\\nRogers, Alexia Delorey, Mahmoud Khalil, Nancy Fulda, and David Wingate.\\n2022. An Information-theoretic Approach to Prompt Engineering Without\\nGround Truth Labels. In Proceedings of the 60th Annual Meeting of the Asso-\\nciation for Computational Linguistics (Volume 1: Long Papers). Association for\\nComputational Linguistics. https://doi.org/10.18653/v1/2022.acl-long.60\\n[92] William Swartout, Jonathan Gratch, Randall Hill, Eduard Hovy, Stacy Marsella,\\nJeff Rickel, and David Traum. 2006. Toward virtual humans. AI Magazine 27, 1\\n(2006).',\n",
       "  '[93] Milind Tambe, W Lewis Johnson, Randolph M Jones, Frank Koss, John E Laird,\\nPaul S Rosenbloom, and Karl Schwamb. 1995. Intelligent agents for interactive\\nsimulation environments. AI Magazine 16, 1 (1995), 15.\\n[94] David R. Thomas. 2006. A General Inductive Approach for Analyzing Qualitative\\nEvaluation Data. American Journal of Evaluation 27, 2 (2006), 237–246. https:\\n//doi.org/10.1177/1098214005283748\\n[95] Frank Thomas and Ollie Johnston. 1981. Disney Animation: The Illusion of Life.\\nAbbeville Press, New York.\\n[96] Ilshat Umarov, Mikhail Mozgovoy, and Patrick C. Rogers. 2012. Believable and\\nEffective AI Agents in Virtual Worlds: Current State and Future Perspectives.\\nInternational Journal of Gaming and Computer-Mediated Simulations 4, 2 (2012),\\n37–59.\\n[97] Graham Upton and Ian Cook. 2006. A Dictionary of Statistics (2 ed.). Oxford\\nUniversity Press, Oxford, United Kingdom.\\n[98] Oriol Vinyals, Igor Babuschkin, Wojciech M. Czarnecki, and et al. 2019. Grand-',\n",
       "  'master level in StarCraft II using multi-agent reinforcement learning. Nature\\n575 (2019), 350–354. https://doi.org/10.1038/s41586-019-1724-z\\n[99] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei\\nXia, Ed Chi, Quoc Le, and Denny Zhou. 2023. Chain-of-Thought Prompting\\nElicits Reasoning in Large Language Models. arXiv:2201.11903 [cs.CL]\\n[100] Mark Weiser. 1991. The computer for the 21st century. Scientific American 265,\\n3 (1991), 94–104. https://doi.org/10.1038/scientificamerican0991-94\\n[101] Mark Weiser. 1999. The Computer for the 21st Century. SIGMOBILE Mob.\\nComput. Commun. Rev. 3, 3 (jul 1999), 3–11.\\nhttps://doi.org/10.1145/329124.\\n329126\\n[102] Joseph Weizenbaum. 1966. ELIZA—a computer program for the study of natural\\nlanguage communication between man and machine. Commun. ACM 9, 1 (1966),\\n36–45.\\n[103] Terry Winograd. 1971. Procedures as a Representation for Data in a Computer\\nProgram for Understanding Natural Language. (1971).',\n",
       "  '[104] Jeff Wu, Long Ouyang, Daniel M. Ziegler, Nisan Stiennon, Ryan Lowe, Jan\\nLeike, and Paul Christiano. 2021. Recursively Summarizing Books with Human\\nFeedback. arXiv:2109.10862 [cs.CL]\\n[105] Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina,\\nMichael Terry, and Carrie J Cai. 2022. PromptChainer: Chaining Large Language\\nModel Prompts through Visual Programming. In CHI EA ’22: Extended Abstracts\\nof the 2022 CHI Conference on Human Factors in Computing Systems.\\n[106] Tongshuang Wu, Michael Terry, and Carrie J Cai. 2022. AI Chains: Transparent\\nand Controllable Human-AI Interaction by Chaining Large Language Model\\nPrompts. In CHI ’22: Proceedings of the 2022 CHI Conference on Human Factors in\\nComputing Systems.\\n[107] Qian Yang, Aaron Steinfeld, Carolyn Rosé, and John Zimmerman. 2020. Re-\\nexamining whether, why, and how human-AI interaction is uniquely difficult to\\ndesign. In Proceedings of the 2020 chi conference on human factors in computing\\nsystems. 1–13.',\n",
       "  '[108] Georgios N. Yannakakis. 2012. Game AI revisited. In Proceedings of the 9th\\nConference on Computing Frontiers. ACM, Cagliari, Italy, 285–292. https://doi.\\norg/10.1145/2212908.2212950\\n[109] Geogios N. Yannakakis. 2012. Game AI revisited. In Proceedings of the 9th\\nConference on Computing Frontiers. 285–292.\\n[110] Robert Zubek. 2002. Towards implementation of social interaction. In AAAI\\nSpring Symposium on Artificial Intelligence and Interactive Entertainment. AAAI\\nPress. https://www.aaai.org/Papers/Symposia/Spring/2002/SS-02-01/SS02-01-\\n003.pdf\\nA\\nARCHITECTURE OPTIMIZATIONS\\nMany of our prompts require a concise summary of the agent,\\nshorthanded as [Agent’s Summary Description] in prompts\\nabove. In our implementation, this summary comprises agents’\\nidentity information (e.g., name, age, personality), as well as a\\ndescription of their main motivational drivers and statements that\\ndescribes their current occupation and self-assessment. Since this',\n",
       "  'information is frequently used in many prompts, we synthesize it\\nat regular intervals and access that synthesis as a cache.',\n",
       "  'Generative Agents\\narXiv, April, 2023,\\nTo achieve this, we perform a retrieval on the query “[name]’s\\ncore characteristics.” We then summarize the descriptors in the\\nretrieved records by prompting the language model, for example:\\nHow would one describe Eddy’s core characteristics\\ngiven the following statements?\\n- Eddy Lin is a student at the Oak Hill College\\nstudying music theory and composition\\n- Eddy Lin is working on a new music composition\\n[. . . ]\\nThis result: Eddy Lin is a student at Oak Hill College studying music\\ntheory and composition. He loves to explore different musical styles\\nand is always looking for ways to expand his knowledge. We follow\\nthe same process in parallel on the queries “[name]’s current daily\\noccupation” and “[name’s] feeling about his recent progress in life”.\\nThe agent’s name, age, and traits are concatenated with these three\\nsummaries as the cached summary.\\nMany other optimizations are possible. Currently, because plans',\n",
       "  'are likely to change from the agent’s initial version, we only gener-\\nate the high-level plan in advance and then recursively decompose\\nthe near future into the moment-to-moment action plan just in\\ntime. Another optimization might be to batch dialogue generation\\nas a joint prompt rather than iterating back and forth between\\nthe agents, and re-planning could be architected to only invalidate\\nand update parts of plans that strictly require adjustment. Our cur-\\nrent architecture runs sequentially in roughly real-time game time\\n(where one second real time is one minute game time), but can\\neasily be parallelized such that each agent runs in parallel.\\nB\\nAGENT INTERVIEW QUESTIONS\\nTo evaluate generative agents, we conducted individual interviews\\nby asking 25 questions that explore their abilities in five key areas:\\n1) self-knowledge, 2) memory, 3) planning, 4) reactions, and 5)\\nreflections. Below, we have listed the interview questions utilized',\n",
       "  'in our evaluation study and included a sample of responses from\\none of our simulated agents, Klaus Mueller.\\nB.1\\nSelf-knowledge\\nThe questions on agents’ self-knowledge probe the agents’ ability\\nto demonstrate coherence and consistency in their character.\\n• Give an introduction of yourself.\\nHello, my name is Klaus Mueller. I’m 20 years old and a\\nstudent at Oak Hill College, studying sociology. I’m passion-\\nate about social justice and exploring different perspectives.\\nCurrently, I’m researching the effects of gentrification in\\nlow-income communities for a research paper.\\n• What’s your occupation?\\nI am a student studying sociology at Oak Hill College. I am\\ncurrently writing a research paper on the effects of gentrifi-\\ncation in low-income communities.\\n• What is your interest?\\nI’m interested in writing and research. I’m writing a research\\npaper on the effects of gentrification in low-income commu-\\nnities, and I’m passionate about exploring different perspec-',\n",
       "  'tives and analyzing different points of view.\\n• Who do you live with?\\nI live on my own.\\n• Describe your typical weekday schedule in broad strokes.\\nMy typical weekday starts with me waking up at 7:00 am\\nand preparing for the day ahead. After that, I usually go to\\nthe library to work on my research paper, taking breaks for\\nlunch at Hobbs Cafe and a walk in the park. In the evening,\\nI often return to the library until around 6:00 pm.\\nB.2\\nMemory\\nThe questions on agents’ memory probe the agents’ ability to re-\\nmember their past experiences and retrieve the relevant pieces of\\nmemory. The names in the square brackets of the first and last\\nquestions are randomly chosen from the names of other agents\\nwith whom the subject agent interacted.\\n• Who is [Wolfgang Schulz]?\\nWolfgang Schulz is a person I met recently who has been\\nhelping me with my research paper on the effects of gentri-\\nfication on low-income communities. We had several con-',\n",
       "  'versations about it, he gave me some great resources, and he\\neven invited me to join him and another friend for lunch. He\\nseems really curious about the issue and has a good grasp\\non it too. I found that really interesting.\\n• Who is Kane Martinez?\\nI’m sorry, I’m not sure who Kane Martinez is. Could you tell\\nme more about them?\\n• Who is running for the election?\\nI’ve heard that Sam Moore is considering running for local\\nmayor.\\n• Was there a Valentine’s day party?\\nYes, Isabella Rodriguez organized a Valentine’s Day party at\\nHobbs Cafe.\\n• Who is [Ayesha Khan]?\\nAyesha Khan is a fellow student at Oak Hill College. She\\nis doing her senior thesis on the use of language in Shake-\\nspeare’s plays. I am looking forward to speaking with her and\\nexchanging tips with her, along with Wolfgang and Maria\\nLopez, who are both doing research.\\nB.3\\nPlans\\nThe questions on agents’ plans probe the agents’ ability to generate\\nand maintain consistency with their long-term and short-term\\nplans.',\n",
       "  '• What will you be doing at 6am today?\\nAt 6am I will be getting out of bed and starting to get ready\\nfor the day. I’m aiming to complete my morning routine by\\n7:00 am.\\n• What will you be doing at 6pm today?\\nI will be working on my research paper at the library at 6:00\\npm today.\\n• What will you have just finished doing at 1pm today?\\nAt 1pm today I will have just finished having lunch at Hobbs\\nCafe.\\n• What will you have just finished doing at 12pm today?\\nI will be getting lunch at Hobbs Cafe at 12pm today.\\n• What will you be doing at 10pm today?\\nAt 10:00 pm tonight I will probably be doing some studying',\n",
       "  'arXiv, April, 2023,\\nJ.S. Park, J.C. O’Brien, C.J. Cai, M. Morris, P. Liang, M.S. Bernstein\\nfor my research paper on gentrification in low-income com-\\nmunities. I’m currently writing the paper, so I need to make\\nsure I keep up with the research and writing.\\nB.4\\nReactions\\nThe questions on agents’ reactions probe the agents’ ability to\\nrespond to unexpected events.\\n• Your breakfast is burning! What would you do?\\nI’d quickly turn off the stove and make sure the food doesn’t\\ncontinue burning. Once the heat is no longer an issue, I can\\ninvestigate what happened and figure out what to do next.\\n• The bathroom is occupied. What would you do?\\nI could try waiting a few more minutes in case the person\\ninside is done soon. If not, I guess I’ll have to look for an\\nalternate option, like taking a shower elsewhere.\\n• You need to cook dinner but your refrigerator is empty. What\\nwould you do?\\nI would first try to clean up my kitchen, as the sink is filled',\n",
       "  'with dirty dishes. Then, I would check to see if I have ingre-\\ndients stored in my pantry that I could use to make dinner.\\nIf not, I would have to go grocery shopping or order food.\\nOnce I have the ingredients, I can start to prepare and cook\\nthe dinner.\\n• You see your friend walking by the street. What would you do\\nor say to your friend?\\nHi there! How are you? I’m sorry, I’m on my way to the\\nlibrary and don’t have much time but I’d love to take a quick\\nbreak and catch up.\\n• You see fire on the street. What would you do?\\nI would first identify the source of the fire, if possible. Then, I\\nwould alert the proper authorities - fire department or police\\n- and provide them with any information I have that might\\nhelp. Depending on the situation, I may also take initiative\\nand try to help any persons who may be in danger or in need\\nof assistance.\\nB.5\\nReflections\\nThe questions on agents’ reflections probe the agents’ ability to\\nsynthesize their past experiences into meaningful reflections that',\n",
       "  'conference on human factors in computing systems. 1–13.\\n[5] John R. Anderson. 1993. Rules of the Mind. Lawrence Erlbaum Associates,\\nHillsdale, NJ.\\n[6] Electronic Arts. 2009. The Sims 3. Video game.\\n[7] Ruth Aylett. 1999. Narrative in virtual environments—towards emergent narra-\\ntive. In Narrative Intelligence: Papers from the AAAI Fall Symposium (Technical\\nReport FS-99-01). AAAI Press, 83–86.\\n[8] Christoph Bartneck and Jodi Forlizzi. 2004. A design-centered framework for\\nsocial human-robot interaction. In Proceedings of the 13th IEEE International\\nWorkshop on Robot and Human Interactive Communication (RO-MAN’04). 591–\\n594. https://doi.org/10.1109/ROMAN.2004.1374827\\n[9] Joseph Bates. 1994. The Role of Emotion in Believable Agents. Commun. ACM\\n37, 7 (1994), 122–125. https://doi.org/10.1145/176789.176803\\n[10] Christopher Berner, Greg Brockman, Brooke Chan, Vicki Cheung, Przemysław\\nDębiak, Christy Dennison, David Farhi, Quirin Fischer, Shariq Hashme, Chris',\n",
       "  'Hesse, Rafal Józefowicz, Scott Gray, Catherine Olsson, Jakub Pachocki, Michael\\nPetrov, Henrique P. d.O. Pinto, Jonathan Raiman, Tim Salimans, Jeremy Schlatter,\\nJonas Schneider, Szymon Sidor, Ilya Sutskever, Jie Tang, Filip Wolski, and Susan\\nZhang. 2019. Dota 2 with Large Scale Deep Reinforcement Learning. arXiv\\npreprint arXiv:1912.06680 (2019).\\n[11] Marcel Binz and Eric Schulz. 2023.\\nUsing cognitive psychology to under-\\nstand GPT-3. Proceedings of the National Academy of Sciences 120, 6 (2023),\\ne2218523120.\\n[12] BioWare. 2007. Mass Effect. Video game.\\n[13] Woody Bledsoe. 1986. I had a dream: AAAI presidential address. AI Magazine 7,\\n1 (1986), 57–61.\\n[14] Rishi Bommasani, Drew A. Hudson, Ehsan Adeli, and et al. 2022. On the\\nOpportunities and Risks of Foundation Models. arXiv:2108.07258 [cs.LG]\\n[15] Michael Brenner. 2010. Creating dynamic story plots with continual multiagent\\nplanning. In Proceedings of the 24th AAAI Conference on Artificial Intelligence.',\n",
       "  'architectures and a human author condition for the same agent. The\\nexperiment displayed one randomly chosen question from each of\\nthe five question categories, along with the agent’s responses gen-\\nerated from each condition. The evaluators ranked the believability\\nof all of the conditions from most to least believable.\\n6.2\\nConditions\\nAll conditions were used to independently answer each of the inter-\\nview questions. We compared the generative agent architecture to\\nablations that disabled the agents’ access to some of all of its three\\ntypes of memory in its memory stream—observation, reflection, and\\nplanning—and to a human-generated condition. There are three\\nablated architectures: a no observation, no reflection, no planning\\narchitecture without access to anything in the memory stream such\\nas observations, plans, and reflections; a no reflection, no planning\\nwith access to observations in the memory stream but no access'],\n",
       " 'metadatas': [{'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 13,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 18,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 7,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 7,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 2,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 2,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 2,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 2,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 2,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 2,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 3,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 3,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 3,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 3,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 3,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 3,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 3,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 4,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 4,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 4,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 4,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 4,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 4,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 4,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 5,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 5,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 5,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 5,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 6,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 6,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 6,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 6,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 6,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 6,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 6,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 7,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 1,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 1,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 2,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 8,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 8,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 8,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 8,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 8,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 9,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 9,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 9,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 9,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 10,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 10,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 10,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 10,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 11,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 11,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 11,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 11,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 11,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 11,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 11,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 12,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 12,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 12,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 12,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 12,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 12,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 12,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 13,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 13,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 13,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 13,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 1,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 7,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 13,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 14,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 14,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 14,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 14,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 14,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 14,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 15,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 15,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 15,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 15,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 15,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 15,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 15,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 15,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 16,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 16,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 16,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 16,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 17,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 17,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 17,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 17,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 17,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 17,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 17,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 17,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 18,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 18,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 18,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 18,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 18,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 22,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 22,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 22,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 18,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 19,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 19,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 19,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 19,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 19,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 19,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 19,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 19,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 19,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 19,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 19,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 20,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 20,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 20,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 20,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 20,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 20,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 20,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 20,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 20,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 20,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 20,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 21,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 21,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 21,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 21,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 21,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 21,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 22,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 22,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 18,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 18,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''},\n",
       "  {'source': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'file_path': '/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf',\n",
       "   'page_number': 13,\n",
       "   'total_pages': 22,\n",
       "   'format': 'PDF 1.5',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       "   'creationDate': 'D:20230410004220Z',\n",
       "   'modDate': 'D:20230410004220Z',\n",
       "   'trapped': ''}]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB with persistence: data will be stored in: /Users/teilomillet/Desktop/ahdoc.chat/Ahdoc/data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<langchain.vectorstores.chroma.Chroma object at 0x112892650>\n"
     ]
    }
   ],
   "source": [
    "loader = PyMuPDFLoader(\"/Users/teilomillet/Library/Mobile Documents/com~apple~CloudDocs/A lire/IA/2304.03442.pdf\")\n",
    "documents = loader.load()\n",
    "\n",
    "# Document splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "# Create embeddings\n",
    "embeddings = OpenAIEmbeddings()\n",
    "collection_name = \"user_id\"\n",
    "vectordb = Chroma.from_documents(texts, \n",
    "                                 embeddings, \n",
    "                                 collection_name=collection_name, \n",
    "                                 persist_directory='/Users/teilomillet/Desktop/ahdoc.chat/Ahdoc/data')\n",
    "\n",
    "print(vectordb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain.vectorstores.chroma.Chroma at 0x112892650>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectordb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ahdoc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
